{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8f9326",
   "metadata": {},
   "source": [
    "# Resultados PROJECOES\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a c√©lula **CONFIGURA√á√ïES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbf258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURA√á√ïES (edite se necess√°rio)\n",
    "# A pasta raiz do projeto (por padr√£o, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a93a8-0664-44bb-b8ad-8c0fd1e9aec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Consolidar Vaz√µes Simuladas por Sub-bacia (MGB + CLIMBra)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Este script percorre a pasta com resultados simulados do MGB para 19 GCMs \n",
    "# em 9 sub-bacias, consolida os arquivos de sa√≠da (SIM_MC_*.TXT) e organiza os \n",
    "# dados por sub-bacia.\n",
    "#\n",
    "# Para cada sub-bacia, √© criado um √∫nico arquivo .csv contendo a s√©rie temporal \n",
    "# di√°ria de 2015 a 2100, com colunas para cada GCM, al√©m das colunas de data: \n",
    "# 'dia', 'mes' e 'ano'. O nome do arquivo inclui o c√≥digo e o nome da esta√ß√£o.\n",
    "#\n",
    "# Observa√ß√£o: Os arquivos simulados foram originalmente gerados com datas \n",
    "# regredidas em 80 anos (ex: 2020 ‚Üí 1940). Este script adiciona novamente os \n",
    "# 80 anos √† coluna 'ano', restaurando a data original.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Caminhos ===\n",
    "PASTA_ENTRADA = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\")\n",
    "PASTA_SAIDA   = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\")\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "\n",
    "PASTA_SAIDA_DIARIOS = PASTA_SAIDA / \"diarios\"\n",
    "PASTA_SAIDA_DIARIOS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Caminho do arquivo de mapeamento ===\n",
    "CAMINHO_MAPEAMENTO = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Esta√ß√µes_mini.csv\")\n",
    "\n",
    "# === Leitura do mapeamento c√≥digo_mini ‚Üí nome_estacao ===\n",
    "df_mapeamento = pd.read_csv(CAMINHO_MAPEAMENTO, sep=\";\")\n",
    "\n",
    "# === Dicion√°rio onde cada sub-bacia conter√° os dados dos GCMs ===\n",
    "dados_subbacias = defaultdict(list)\n",
    "\n",
    "# === Percorrer todos os modelos ===\n",
    "for modelo_path in PASTA_ENTRADA.iterdir():\n",
    "    if not modelo_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    nome_modelo = modelo_path.name\n",
    "    output_path = modelo_path / \"Output\"\n",
    "\n",
    "    if not output_path.exists():\n",
    "        continue\n",
    "\n",
    "    for arquivo in output_path.glob(\"SIM_MC_*.TXT\"):\n",
    "        subbacia = arquivo.stem.split(\"_\")[-1]  # ex: '792'\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(arquivo, delim_whitespace=True, names=[\"dia\", \"mes\", \"ano\", nome_modelo])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao ler {arquivo.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Corrige o ano regredido\n",
    "        df[\"ano\"] = df[\"ano\"] + 80\n",
    "\n",
    "        dados_subbacias[subbacia].append(df)\n",
    "\n",
    "# === Para cada sub-bacia, consolidar e salvar ===\n",
    "for subbacia, lista_df in dados_subbacias.items():\n",
    "    df_base = lista_df[0][[\"dia\", \"mes\", \"ano\"]].copy()\n",
    "\n",
    "    for df in lista_df:\n",
    "        nome_coluna = df.columns[-1]\n",
    "        df_base[nome_coluna] = df[nome_coluna].values\n",
    "\n",
    "    # Obter nome da esta√ß√£o (se existir no mapeamento)\n",
    "    linha = df_mapeamento[df_mapeamento[\"codigo_mini\"].astype(str) == subbacia]\n",
    "\n",
    "    if not linha.empty:\n",
    "        codigo_estacao = str(linha[\"estacao_obs\"].values[0])\n",
    "        nome_estacao   = linha[\"nome_estacao\"].values[0]\n",
    "    else:\n",
    "        codigo_estacao = f\"SUB{subbacia}\"\n",
    "        nome_estacao   = \"Desconhecida\"\n",
    "\n",
    "    nome_arquivo = f\"{codigo_estacao}.csv\"\n",
    "    caminho_saida = PASTA_SAIDA_DIARIOS / nome_arquivo\n",
    "    df_base.to_csv(caminho_saida, index=False, sep=';')\n",
    "    print(f\"‚úîÔ∏è Sub-bacia {subbacia} ({nome_estacao}) salva com {df_base.shape[1]-3} modelos: {caminho_saida.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031584c-bf7c-4e49-a28b-7fcd486c3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Consolidar Vaz√µes Anuais com M√©dia Multimodelo (MGB + CLIMBra)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Este script percorre os arquivos di√°rios organizados por sub-bacia, contendo\n",
    "# 19 GCMs (2015‚Äì2100), e calcula a m√©dia anual por modelo.\n",
    "#\n",
    "# Em seguida, calcula a m√©dia multimodelo para cada ano e salva os resultados\n",
    "# em um novo CSV por sub-bacia com o sufixo '_anual.csv'.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Caminhos ===\n",
    "PASTA_BASE         = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\")\n",
    "PASTA_DIARIOS      = PASTA_BASE / \"diarios\"\n",
    "PASTA_ANUAIS       = PASTA_BASE / \"anuais\"\n",
    "PASTA_ANUAIS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CAMINHO_MAPEAMENTO = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Esta√ß√µes_mini.csv\")\n",
    "df_mapeamento = pd.read_csv(CAMINHO_MAPEAMENTO, sep=\";\")\n",
    "\n",
    "# === Dicion√°rio de c√≥digo_mini ‚Üí (estacao_obs, nome_estacao) ===\n",
    "dict_mapeamento = {\n",
    "    str(row[\"estacao_obs\"]): row[\"nome_estacao\"]\n",
    "    for _, row in df_mapeamento.iterrows()\n",
    "}\n",
    "\n",
    "# === Processar cada arquivo di√°rio ===\n",
    "for caminho_csv in PASTA_DIARIOS.glob(\"*.csv\"):\n",
    "    nome_arquivo = caminho_csv.stem  # ex: '65295000'\n",
    "    codigo_estacao = nome_arquivo  # Assume nome do arquivo como c√≥digo da esta√ß√£o\n",
    "\n",
    "    # Verifica se a esta√ß√£o est√° no mapeamento\n",
    "    nome_estacao = dict_mapeamento.get(codigo_estacao, \"Desconhecida\")\n",
    "\n",
    "    # L√™ o CSV\n",
    "    df = pd.read_csv(caminho_csv, sep=';')\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    # Cria coluna de data e extrai ano\n",
    "    df['data'] = pd.to_datetime(dict(year=df['ano'], month=df['mes'], day=df['dia']), errors='coerce')\n",
    "    df = df.dropna(subset=['data'])\n",
    "    df['ano'] = df['data'].dt.year\n",
    "\n",
    "    # Identifica colunas de modelos (exclui data)\n",
    "    col_modelos = [col for col in df.columns if col not in ['dia', 'mes', 'data', 'ano']]\n",
    "\n",
    "    # M√©dia anual por modelo\n",
    "    df_anual = df.groupby('ano')[col_modelos].mean().reset_index()\n",
    "\n",
    "    # M√©dia multimodelo\n",
    "    df_anual['media_multimodelo'] = df_anual[col_modelos].mean(axis=1)\n",
    "\n",
    "    # Salvar com mesmo nome, sufixo _anual.csv\n",
    "    nome_saida = f\"{codigo_estacao}_anual.csv\"\n",
    "    caminho_saida = PASTA_ANUAIS / nome_saida\n",
    "    df_anual.to_csv(caminho_saida, index=False, sep=';')\n",
    "\n",
    "    print(f\"üìò Esta√ß√£o {codigo_estacao} ({nome_estacao}) ‚Äî S√©rie anual salva: {nome_saida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f034c-6b36-4f69-9b04-f637aa819ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Plotar S√©ries Anuais com M√©dia Multimodelo e Intervalos de Incerteza\n",
    "# ------------------------------------------------------------------------------\n",
    "# Gr√°fico 1: Linhas de todos os GCMs (cinza) + M√©dia Multimodelo (destacada) + Reta de Tend√™ncia (Sen)\n",
    "# Gr√°fico 2: M√©dia Multimodelo + Faixas de Incerteza (P10‚ÄìP90 e M√≠n‚ÄìM√°x)\n",
    "#              + Reta de Tend√™ncia com box de slope e p-valor do ensemble\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "import pymannkendall as mk\n",
    "\n",
    "# Caminhos\n",
    "PASTA_DADOS = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\\anuais\")\n",
    "PASTA_SAIDA = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\") / \"graficos_anuais_\"\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "\n",
    "# Loop pelas sub-bacias\n",
    "for caminho_csv in PASTA_DADOS.glob(\"*_anual.csv\"):\n",
    "    subbacia = caminho_csv.stem.replace(\"_anual\", \"\")\n",
    "    df = pd.read_csv(caminho_csv, sep=';')\n",
    "\n",
    "    col_modelos = [col for col in df.columns if col not in ['ano', 'media_multimodelo']]\n",
    "\n",
    "    if not col_modelos:\n",
    "        print(f\"‚ö†Ô∏è Nenhum modelo encontrado em {caminho_csv.name}. Pulando...\")\n",
    "        continue\n",
    "\n",
    "    # C√°lculo da reta de tend√™ncia (ensemble)\n",
    "    x = df['ano']\n",
    "    y = df['media_multimodelo']\n",
    "    res_mk = mk.hamed_rao_modification_test(y)\n",
    "    reg = linregress(x, y)\n",
    "    slope = reg.slope\n",
    "    intercept = reg.intercept\n",
    "    linha_tendencia = slope * x + intercept\n",
    "    p_valor = res_mk.p\n",
    "\n",
    "    # Texto da caixa informativa\n",
    "    texto_box = f\"Slope = {slope:.2f} m¬≥/s/ano\\np-valor = {p_valor:.4f}\"\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # GR√ÅFICO 1 ‚Äî Todos os modelos (cinza) + M√©dia multimodelo destacada + reta\n",
    "    # -------------------------------------------------------------------\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for modelo in col_modelos:\n",
    "        plt.plot(df['ano'], df[modelo], color='lightgray', linewidth=1)\n",
    "    plt.plot(df['ano'], y, color='black', linewidth=2, label='M√©dia Multimodelo')\n",
    "    plt.plot(df['ano'], linha_tendencia, color='red', linestyle='--', label='Tend√™ncia')\n",
    "    plt.title(f\"S√©rie Anual - Esta√ß√£o {subbacia}\")\n",
    "    plt.xlabel(\"Ano\")\n",
    "    plt.ylabel(\"Vaz√£o m√©dia anual (m¬≥/s)\")\n",
    "    plt.legend()\n",
    "    plt.text(0.98, 0.95, texto_box, transform=plt.gca().transAxes,\n",
    "             fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "             bbox=dict(boxstyle=\"round\", facecolor='white', edgecolor='gray'))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PASTA_SAIDA / f\"{subbacia}_todos_modelos_media.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # GR√ÅFICO 2 ‚Äî M√©dia multimodelo + faixa P10‚ÄìP90 e Min‚ÄìMax + reta\n",
    "    # -------------------------------------------------------------------\n",
    "    df['p10'] = df[col_modelos].quantile(0.10, axis=1)\n",
    "    df['p90'] = df[col_modelos].quantile(0.90, axis=1)\n",
    "    df['min'] = df[col_modelos].min(axis=1)\n",
    "    df['max'] = df[col_modelos].max(axis=1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.fill_between(df['ano'], df['min'], df['max'], color='gray', alpha=0.2, label=\"Intervalo M√≠n‚ÄìM√°x\")\n",
    "    plt.fill_between(df['ano'], df['p10'], df['p90'], color='blue', alpha=0.2, label=\"Intervalo P10‚ÄìP90\")\n",
    "    plt.plot(df['ano'], y, color='black', linewidth=2, label='M√©dia Multimodelo')\n",
    "    plt.plot(df['ano'], linha_tendencia, color='red', linestyle='--', label='Tend√™ncia')\n",
    "    plt.title(f\"Incerteza Multimodelo - Esta√ß√£o {subbacia}\")\n",
    "    plt.xlabel(\"Ano\")\n",
    "    plt.ylabel(\"Vaz√£o m√©dia anual (m¬≥/s)\")\n",
    "    plt.legend()\n",
    "    plt.text(0.98, 0.95, texto_box, transform=plt.gca().transAxes,\n",
    "             fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "             bbox=dict(boxstyle=\"round\", facecolor='white', edgecolor='gray'))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PASTA_SAIDA / f\"{subbacia}_media_intervalos.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"‚úîÔ∏è Gr√°ficos salvos para esta√ß√£o {subbacia} em: {PASTA_SAIDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32645a-4a1b-4233-90f5-b9b947952124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gera√ß√£o de s√©ries (ensemble mean/median + P10‚ÄìP90), estat√≠sticas e tabelas\n",
    "para todas as esta√ß√µes anuais (arquivos *_anual.csv) em SSP2-4.5 e SSP5-8.5.\n",
    "\n",
    "ENTRADAS (pastas):\n",
    "- E:\\IGUA√áU_OTTO\\8_Resultados_ssp245\\anuais\\*.csv\n",
    "- E:\\IGUA√áU_OTTO\\8_Resultados_ssp585\\anuais\\*.csv\n",
    "\n",
    "SA√çDAS:\n",
    "1) Figuras (PNG) por esta√ß√£o (no estilo 2 pain√©is empilhados: SSP2-4.5 e SSP5-8.5),\n",
    "   com linhas de m√©dia e mediana do ensemble e faixa de incerteza P10‚ÄìP90:\n",
    "   - OUT_DIR\\Figuras\\serie_ensemble_<estacao>.png\n",
    "\n",
    "2) Excel consolidado (pronto para disserta√ß√£o):\n",
    "   - OUT_DIR\\estatisticas_ensemble_todas_estacoes.xlsx\n",
    "   com abas:\n",
    "   - resumo_horizontes\n",
    "   - estatisticas_series\n",
    "   - lista_estacoes\n",
    "\n",
    "3) CSVs consolidados:\n",
    "   - OUT_DIR\\resumo_horizontes_todas_estacoes.csv\n",
    "   - OUT_DIR\\estatisticas_series_todas_estacoes.csv\n",
    "   - OUT_DIR\\lista_estacoes_todas_estacoes.csv\n",
    "\n",
    "OBSERVA√á√ÉO METODOL√ìGICA:\n",
    "- \"ensemble_mean\" √© lido da coluna 'media_multimodelo' (m√©dia anual multimodelo).\n",
    "- \"ensemble_median\" √© a mediana entre os modelos (colunas dos modelos), ano a ano.\n",
    "- P10 e P90 s√£o percentis (10% e 90%) entre os modelos, ano a ano.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------\n",
    "DIR_SSP245 = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\\anuais\")\n",
    "DIR_SSP585 = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp585 - Clima\\8_Resultados_ssp585\\anuais\")\n",
    "\n",
    "OUT_DIR = Path(r\"E:\\IGUA√áU_OTTO\\9_Figuras_e_Tabelas_Ensemble_AB2\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_FIG_DIR = OUT_DIR / \"Figuras\"\n",
    "OUT_FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_XLSX = OUT_DIR / \"estatisticas_ensemble_todas_estacoes.xlsx\"\n",
    "OUT_CSV_RESUMO = OUT_DIR / \"resumo_horizontes_todas_estacoes.csv\"\n",
    "OUT_CSV_STATS = OUT_DIR / \"estatisticas_series_todas_estacoes.csv\"\n",
    "OUT_CSV_LISTA = OUT_DIR / \"lista_estacoes_todas_estacoes.csv\"\n",
    "\n",
    "SEP = \";\"\n",
    "\n",
    "HORIZONTES = {\n",
    "    \"2015-2040\": (2015, 2040),\n",
    "    \"2041-2070\": (2041, 2070),\n",
    "    \"2071-2100\": (2071, 2100),\n",
    "    \"2015-2100\": (2015, 2100),\n",
    "}\n",
    "\n",
    "COL_ANO = \"ano\"\n",
    "COL_MEAN = \"media_multimodelo\"  # j√° vem no arquivo\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# FUN√á√ïES\n",
    "# -------------------------------------------------------\n",
    "def extrair_codigo_estacao(path: Path) -> str:\n",
    "    m = re.match(r\"(\\d+)_anual\", path.stem)\n",
    "    return m.group(1) if m else path.stem\n",
    "\n",
    "def listar_arquivos_por_estacao(dir_csv: Path) -> dict[str, Path]:\n",
    "    \"\"\"Retorna dict {estacao: path_csv} para todos os *_anual.csv na pasta.\"\"\"\n",
    "    d: dict[str, Path] = {}\n",
    "    for p in sorted(dir_csv.glob(\"*_anual.csv\")):\n",
    "        est = extrair_codigo_estacao(p)\n",
    "        d[est] = p\n",
    "    return d\n",
    "\n",
    "def ler_csv_anual(path_csv: Path) -> tuple[pd.DataFrame, list[str]]:\n",
    "    \"\"\"\n",
    "    L√™ o CSV anual e retorna (df, cols_modelos).\n",
    "    df cont√©m:\n",
    "      ano, ensemble_mean, ensemble_median, p10, p90\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_csv, sep=SEP)\n",
    "\n",
    "    if COL_ANO not in df.columns:\n",
    "        raise ValueError(f\"{path_csv.name}: n√£o encontrei coluna '{COL_ANO}'. Colunas: {list(df.columns)}\")\n",
    "    if COL_MEAN not in df.columns:\n",
    "        raise ValueError(f\"{path_csv.name}: n√£o encontrei coluna '{COL_MEAN}'. Colunas: {list(df.columns)}\")\n",
    "\n",
    "    df[COL_ANO] = pd.to_numeric(df[COL_ANO], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    cols_modelos = [c for c in df.columns if c not in {COL_ANO, COL_MEAN}]\n",
    "    if len(cols_modelos) == 0:\n",
    "        raise ValueError(f\"{path_csv.name}: n√£o encontrei colunas de modelos (al√©m de 'ano' e 'media_multimodelo').\")\n",
    "\n",
    "    df[cols_modelos] = df[cols_modelos].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    df[\"ensemble_mean\"] = pd.to_numeric(df[COL_MEAN], errors=\"coerce\")\n",
    "    df[\"ensemble_median\"] = df[cols_modelos].median(axis=1, skipna=True)\n",
    "    df[\"p10\"] = df[cols_modelos].quantile(0.10, axis=1, interpolation=\"linear\")\n",
    "    df[\"p90\"] = df[cols_modelos].quantile(0.90, axis=1, interpolation=\"linear\")\n",
    "\n",
    "    df = df.dropna(subset=[COL_ANO]).sort_values(COL_ANO).reset_index(drop=True)\n",
    "    return df, cols_modelos\n",
    "\n",
    "def recortar_periodo(df: pd.DataFrame, ano_ini: int, ano_fim: int) -> pd.DataFrame:\n",
    "    return df[(df[COL_ANO] >= ano_ini) & (df[COL_ANO] <= ano_fim)].copy()\n",
    "\n",
    "def estatisticas_series(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Estat√≠sticas b√°sicas das s√©ries anuais (mean vs median do ensemble).\"\"\"\n",
    "    x = df[\"ensemble_mean\"].to_numpy(dtype=float)\n",
    "    y = df[\"ensemble_median\"].to_numpy(dtype=float)\n",
    "\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    if len(x) == 0:\n",
    "        return {\n",
    "            \"n\": 0,\n",
    "            \"std_mean\": np.nan,\n",
    "            \"std_median\": np.nan,\n",
    "            \"var_mean\": np.nan,\n",
    "            \"var_median\": np.nan,\n",
    "            \"cov_mean_median\": np.nan,\n",
    "            \"corr_mean_median\": np.nan,\n",
    "            \"cv_mean\": np.nan,\n",
    "            \"cv_median\": np.nan,\n",
    "        }\n",
    "\n",
    "    std_mean = float(np.std(x, ddof=1)) if len(x) > 1 else 0.0\n",
    "    std_median = float(np.std(y, ddof=1)) if len(y) > 1 else 0.0\n",
    "    var_mean = float(np.var(x, ddof=1)) if len(x) > 1 else 0.0\n",
    "    var_median = float(np.var(y, ddof=1)) if len(y) > 1 else 0.0\n",
    "\n",
    "    if len(x) > 1:\n",
    "        cov = float(np.cov(x, y, ddof=1)[0, 1])\n",
    "        corr = float(np.corrcoef(x, y)[0, 1])\n",
    "    else:\n",
    "        cov, corr = 0.0, 1.0\n",
    "\n",
    "    mean_x = float(np.mean(x))\n",
    "    mean_y = float(np.mean(y))\n",
    "    cv_mean = float(std_mean / mean_x) if np.isfinite(mean_x) and mean_x != 0 else np.nan\n",
    "    cv_median = float(std_median / mean_y) if np.isfinite(mean_y) and mean_y != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"n\": int(len(x)),\n",
    "        \"std_mean\": std_mean,\n",
    "        \"std_median\": std_median,\n",
    "        \"var_mean\": var_mean,\n",
    "        \"var_median\": var_median,\n",
    "        \"cov_mean_median\": cov,\n",
    "        \"corr_mean_median\": corr,\n",
    "        \"cv_mean\": cv_mean,\n",
    "        \"cv_median\": cv_median,\n",
    "    }\n",
    "\n",
    "def resumo_horizontes(df: pd.DataFrame, horizontes: dict) -> list[dict]:\n",
    "    \"\"\"\n",
    "    M√©tricas por horizonte:\n",
    "    - mean e median do ensemble_mean\n",
    "    - mean e median do ensemble_median\n",
    "    - mean do P10 e do P90 no horizonte\n",
    "    \"\"\"\n",
    "    rows: list[dict] = []\n",
    "    for nome, (a0, a1) in horizontes.items():\n",
    "        d = recortar_periodo(df, a0, a1)\n",
    "        if len(d) == 0:\n",
    "            rows.append({\n",
    "                \"horizonte\": nome,\n",
    "                \"ano_ini\": a0,\n",
    "                \"ano_fim\": a1,\n",
    "                \"n_anos\": 0,\n",
    "                \"mean_ensemble_mean\": np.nan,\n",
    "                \"median_ensemble_mean\": np.nan,\n",
    "                \"mean_ensemble_median\": np.nan,\n",
    "                \"median_ensemble_median\": np.nan,\n",
    "                \"mean_p10\": np.nan,\n",
    "                \"mean_p90\": np.nan,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"horizonte\": nome,\n",
    "            \"ano_ini\": a0,\n",
    "            \"ano_fim\": a1,\n",
    "            \"n_anos\": int(len(d)),\n",
    "            \"mean_ensemble_mean\": float(d[\"ensemble_mean\"].mean()),\n",
    "            \"median_ensemble_mean\": float(d[\"ensemble_mean\"].median()),\n",
    "            \"mean_ensemble_median\": float(d[\"ensemble_median\"].mean()),\n",
    "            \"median_ensemble_median\": float(d[\"ensemble_median\"].median()),\n",
    "            \"mean_p10\": float(d[\"p10\"].mean()),\n",
    "            \"mean_p90\": float(d[\"p90\"].mean()),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def plotar_estacao_2paineis_com_faixa(df245: pd.DataFrame, df585: pd.DataFrame, estacao: str, out_png: Path) -> None:\n",
    "    \"\"\"\n",
    "    Figura por esta√ß√£o, com 2 pain√©is empilhados (estilo do exemplo):\n",
    "      - Painel 1: SSP2-4.5 (m√©dia, mediana e faixa P10‚ÄìP90)\n",
    "      - Painel 2: SSP5-8.5 (m√©dia, mediana e faixa P10‚ÄìP90)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 8), dpi=300, sharex=True)\n",
    "\n",
    "    # Painel SSP2-4.5\n",
    "    ax = axes[0]\n",
    "    ax.fill_between(df245[COL_ANO], df245[\"p10\"], df245[\"p90\"], alpha=0.20, label=\"P10‚ÄìP90\")\n",
    "    ax.plot(df245[COL_ANO], df245[\"ensemble_mean\"], linewidth=2, label=\"Ensemble ‚Äì m√©dia anual\")\n",
    "    ax.plot(df245[COL_ANO], df245[\"ensemble_median\"], linewidth=2, label=\"Ensemble ‚Äì mediana anual\")\n",
    "    ax.set_title(f\"SSP2-4.5 ({estacao})\")\n",
    "    ax.set_ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\n",
    "    ax.legend(loc=\"upper left\", fontsize=9)\n",
    "\n",
    "    # Painel SSP5-8.5\n",
    "    ax = axes[1]\n",
    "    ax.fill_between(df585[COL_ANO], df585[\"p10\"], df585[\"p90\"], alpha=0.20, label=\"P10‚ÄìP90\")\n",
    "    ax.plot(df585[COL_ANO], df585[\"ensemble_mean\"], linewidth=2, label=\"Ensemble ‚Äì m√©dia anual\")\n",
    "    ax.plot(df585[COL_ANO], df585[\"ensemble_median\"], linewidth=2, label=\"Ensemble ‚Äì mediana anual\")\n",
    "    ax.set_title(f\"SSP5-8.5 ({estacao})\")\n",
    "    ax.set_xlabel(\"Ano\")\n",
    "    ax.set_ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\n",
    "    ax.legend(loc=\"upper left\", fontsize=9)\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"S√©rie temporal do ensemble ‚Äì compara√ß√£o entre m√©dia e mediana (vaz√µes anuais)\",\n",
    "        fontsize=14, fontweight=\"bold\", y=0.98\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# MAIN\n",
    "# -------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    arqs_245 = listar_arquivos_por_estacao(DIR_SSP245)\n",
    "    arqs_585 = listar_arquivos_por_estacao(DIR_SSP585)\n",
    "\n",
    "    estacoes = sorted(set(arqs_245.keys()) & set(arqs_585.keys()))\n",
    "    if not estacoes:\n",
    "        raise RuntimeError(\"N√£o encontrei esta√ß√µes em comum entre SSP2-4.5 e SSP5-8.5.\")\n",
    "\n",
    "    print(f\"Esta√ß√µes em comum: {len(estacoes)}\")\n",
    "\n",
    "    resumo_rows: list[dict] = []\n",
    "    stats_rows: list[dict] = []\n",
    "    lista_rows: list[dict] = []\n",
    "\n",
    "    for estacao in estacoes:\n",
    "        p245 = arqs_245[estacao]\n",
    "        p585 = arqs_585[estacao]\n",
    "\n",
    "        df245, cols245 = ler_csv_anual(p245)\n",
    "        df585, cols585 = ler_csv_anual(p585)\n",
    "\n",
    "        # Figura no estilo 2 pain√©is (como seu exemplo)\n",
    "        out_png = OUT_FIG_DIR / f\"serie_ensemble_{estacao}.png\"\n",
    "        plotar_estacao_2paineis_com_faixa(df245, df585, estacao, out_png)\n",
    "\n",
    "        # Estat√≠sticas por cen√°rio\n",
    "        stats245 = estatisticas_series(df245)\n",
    "        stats585 = estatisticas_series(df585)\n",
    "        stats_rows.append({\"cenario\": \"SSP2-4.5\", \"estacao\": estacao, **stats245})\n",
    "        stats_rows.append({\"cenario\": \"SSP5-8.5\", \"estacao\": estacao, **stats585})\n",
    "\n",
    "        # Resumo por horizontes\n",
    "        for row in resumo_horizontes(df245, HORIZONTES):\n",
    "            resumo_rows.append({\"cenario\": \"SSP2-4.5\", \"estacao\": estacao, **row})\n",
    "        for row in resumo_horizontes(df585, HORIZONTES):\n",
    "            resumo_rows.append({\"cenario\": \"SSP5-8.5\", \"estacao\": estacao, **row})\n",
    "\n",
    "        # Auditoria\n",
    "        lista_rows.append({\n",
    "            \"estacao\": estacao,\n",
    "            \"arquivo_ssp245\": str(p245),\n",
    "            \"arquivo_ssp585\": str(p585),\n",
    "            \"n_modelos_cols_ssp245\": int(len(cols245)),\n",
    "            \"n_modelos_cols_ssp585\": int(len(cols585)),\n",
    "            \"ano_min_ssp245\": int(df245[COL_ANO].min()),\n",
    "            \"ano_max_ssp245\": int(df245[COL_ANO].max()),\n",
    "            \"ano_min_ssp585\": int(df585[COL_ANO].min()),\n",
    "            \"ano_max_ssp585\": int(df585[COL_ANO].max()),\n",
    "        })\n",
    "\n",
    "    # Consolida DataFrames finais\n",
    "    df_resumo = pd.DataFrame(resumo_rows)\n",
    "    df_stats = pd.DataFrame(stats_rows)\n",
    "    df_lista = pd.DataFrame(lista_rows)\n",
    "\n",
    "    ordem_h = pd.CategoricalDtype([\"2015-2040\", \"2041-2070\", \"2071-2100\", \"2015-2100\"], ordered=True)\n",
    "    df_resumo[\"horizonte\"] = df_resumo[\"horizonte\"].astype(ordem_h)\n",
    "    df_resumo = df_resumo.sort_values([\"cenario\", \"estacao\", \"horizonte\"]).reset_index(drop=True)\n",
    "\n",
    "    df_stats = df_stats.sort_values([\"cenario\", \"estacao\"]).reset_index(drop=True)\n",
    "    df_lista = df_lista.sort_values([\"estacao\"]).reset_index(drop=True)\n",
    "\n",
    "    # Exporta CSVs\n",
    "    df_resumo.to_csv(OUT_CSV_RESUMO, index=False, encoding=\"utf-8-sig\")\n",
    "    df_stats.to_csv(OUT_CSV_STATS, index=False, encoding=\"utf-8-sig\")\n",
    "    df_lista.to_csv(OUT_CSV_LISTA, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Exporta Excel (3 abas)\n",
    "    with pd.ExcelWriter(OUT_XLSX, engine=\"openpyxl\") as writer:\n",
    "        df_resumo.to_excel(writer, sheet_name=\"resumo_horizontes\", index=False)\n",
    "        df_stats.to_excel(writer, sheet_name=\"estatisticas_series\", index=False)\n",
    "        df_lista.to_excel(writer, sheet_name=\"lista_estacoes\", index=False)\n",
    "\n",
    "    print(\"\\n‚úÖ Conclu√≠do com sucesso!\")\n",
    "    print(\"Figuras (PNG):\", OUT_FIG_DIR)\n",
    "    print(\"Excel final:\", OUT_XLSX)\n",
    "    print(\"CSV resumo:\", OUT_CSV_RESUMO)\n",
    "    print(\"CSV estat√≠sticas:\", OUT_CSV_STATS)\n",
    "    print(\"CSV lista:\", OUT_CSV_LISTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b9c11-f6f9-4145-aeb6-e5139a97f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Consolidar Vaz√µes Anuais com M√©dia Multimodelo (MGB + CLIMBra)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Agora, al√©m da vaz√£o m√©dia anual, calcula tamb√©m:\n",
    "#  - vaz√£o m√°xima anual\n",
    "#  - vaz√£o m√≠nima anual\n",
    "#  - percentil 10% anual\n",
    "#  - percentil 90% anual\n",
    "#\n",
    "# Para cada modelo, ano a ano, a partir da s√©rie di√°ria.\n",
    "# Em seguida, calcula a m√©dia multimodelo das M√âDIAS anuais.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Caminhos ===\n",
    "PASTA_BASE         = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\")\n",
    "PASTA_DIARIOS      = PASTA_BASE / \"diarios\"\n",
    "PASTA_ANUAIS       = PASTA_BASE / \"anuais_est\"\n",
    "PASTA_ANUAIS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CAMINHO_MAPEAMENTO = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Esta√ß√µes_mini.csv\")\n",
    "df_mapeamento = pd.read_csv(CAMINHO_MAPEAMENTO, sep=\";\")\n",
    "\n",
    "# === Dicion√°rio de c√≥digo_mini ‚Üí (estacao_obs, nome_estacao) ===\n",
    "dict_mapeamento = {\n",
    "    str(row[\"estacao_obs\"]): row[\"nome_estacao\"]\n",
    "    for _, row in df_mapeamento.iterrows()\n",
    "}\n",
    "\n",
    "# Fun√ß√µes auxiliares para os quantis\n",
    "def q10(x):\n",
    "    return x.quantile(0.10)\n",
    "\n",
    "def q90(x):\n",
    "    return x.quantile(0.90)\n",
    "\n",
    "# === Processar cada arquivo di√°rio ===\n",
    "for caminho_csv in PASTA_DIARIOS.glob(\"*.csv\"):\n",
    "    nome_arquivo = caminho_csv.stem  # ex: '65295000'\n",
    "    codigo_estacao = nome_arquivo    # Assume nome do arquivo como c√≥digo da esta√ß√£o\n",
    "\n",
    "    # Verifica se a esta√ß√£o est√° no mapeamento\n",
    "    nome_estacao = dict_mapeamento.get(codigo_estacao, \"Desconhecida\")\n",
    "\n",
    "    # L√™ o CSV\n",
    "    df = pd.read_csv(caminho_csv, sep=';')\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    # Cria coluna de data e extrai ano\n",
    "    df['data'] = pd.to_datetime(\n",
    "        dict(year=df['ano'], month=df['mes'], day=df['dia']),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    df = df.dropna(subset=['data'])\n",
    "    df['ano'] = df['data'].dt.year\n",
    "\n",
    "    # Identifica colunas de modelos (exclui data/ano/dia/mes)\n",
    "    col_modelos = [col for col in df.columns if col not in ['dia', 'mes', 'data', 'ano']]\n",
    "\n",
    "    # Estat√≠sticas anuais por modelo: m√©dia, m√°x, m√≠n, p10 e p90\n",
    "    df_anual = df.groupby('ano')[col_modelos].agg(['mean', 'max', 'min', q10, q90])\n",
    "\n",
    "    # Flatten do MultiIndex de colunas: modelo_estatistica\n",
    "    df_anual.columns = [\n",
    "        f\"{modelo}_{estat}\" for (modelo, estat) in df_anual.columns.to_list()\n",
    "    ]\n",
    "    df_anual = df_anual.reset_index()\n",
    "\n",
    "    # M√©dia multimodelo das M√âDIAS anuais (mantendo sua l√≥gica original)\n",
    "    cols_medias = [c for c in df_anual.columns if c.endswith('_mean')]\n",
    "    df_anual['media_multimodelo'] = df_anual[cols_medias].mean(axis=1)\n",
    "\n",
    "    # Salvar com mesmo nome, sufixo _anual.csv\n",
    "    nome_saida = f\"{codigo_estacao}_anual.csv\"\n",
    "    caminho_saida = PASTA_ANUAIS / nome_saida\n",
    "    df_anual.to_csv(caminho_saida, index=False, sep=';')\n",
    "\n",
    "    print(f\"üìò Esta√ß√£o {codigo_estacao} ({nome_estacao}) ‚Äî S√©rie anual salva: {nome_saida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72bbe2-5c81-4c54-b79b-176743e7b9ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Plotar S√©ries Anuais para V√°rias Estat√≠sticas (MGB + CLIMBra)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Para cada sub-bacia e para cada estat√≠stica (mean, max, min, q10, q90):\n",
    "#\n",
    "#   Gr√°fico 1: Linhas de todos os GCMs (cinza) + M√©dia Multimodelo (destacada) + Reta de Tend√™ncia\n",
    "#   Gr√°fico 2: M√©dia Multimodelo + Faixas de Incerteza (P10‚ÄìP90 e M√≠n‚ÄìM√°x) + Reta de Tend√™ncia\n",
    "#\n",
    "# Os CSVs anuais t√™m o formato:\n",
    "#   ano,\n",
    "#   MODELO_mean, MODELO_max, MODELO_min, MODELO_q10, MODELO_q90,\n",
    "#   media_multimodelo (para a m√©dia; opcionalmente recalculada)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "import pymannkendall as mk\n",
    "\n",
    "# Caminhos\n",
    "PASTA_DADOS = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\\anuais_est\")\n",
    "PASTA_SAIDA = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\") / \"graficos_anuais_est\"\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "\n",
    "# Dicion√°rio para r√≥tulos bonitos no eixo Y e no t√≠tulo\n",
    "ROTULO_METRICA = {\n",
    "    \"mean\": \"Vaz√£o m√©dia anual (m¬≥/s)\",\n",
    "    \"max\":  \"Vaz√£o m√°xima anual (m¬≥/s)\",\n",
    "    \"min\":  \"Vaz√£o m√≠nima anual (m¬≥/s)\",\n",
    "    \"q10\":  \"Vaz√£o anual - P10 (m¬≥/s)\",\n",
    "    \"q90\":  \"Vaz√£o anual - P90 (m¬≥/s)\",\n",
    "}\n",
    "\n",
    "TITULO_METRICA = {\n",
    "    \"mean\": \"m√©dia\",\n",
    "    \"max\":  \"m√°xima\",\n",
    "    \"min\":  \"m√≠nima\",\n",
    "    \"q10\":  \"P10\",\n",
    "    \"q90\":  \"P90\",\n",
    "}\n",
    "\n",
    "# M√©tricas dispon√≠veis nos arquivos\n",
    "METRICAS = [\"mean\", \"max\", \"min\", \"q10\", \"q90\"]\n",
    "\n",
    "# Loop pelas sub-bacias\n",
    "for caminho_csv in PASTA_DADOS.glob(\"*_anual.csv\"):\n",
    "    subbacia = caminho_csv.stem.replace(\"_anual\", \"\")\n",
    "    df = pd.read_csv(caminho_csv, sep=';')\n",
    "\n",
    "    if 'ano' not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Coluna 'ano' n√£o encontrada em {caminho_csv.name}. Pulando...\")\n",
    "        continue\n",
    "\n",
    "    anos = df['ano']\n",
    "\n",
    "    # Para cada m√©trica (mean, max, min, q10, q90), gerar dois gr√°ficos\n",
    "    for metrica in METRICAS:\n",
    "        # Seleciona apenas as colunas dessa m√©trica: *_mean, *_max, etc.\n",
    "        col_metricas = [c for c in df.columns if c.endswith(f\"_{metrica}\")]\n",
    "\n",
    "        if len(col_metricas) == 0:\n",
    "            print(f\"‚ö†Ô∏è Nenhuma coluna com a m√©trica '{metrica}' em {caminho_csv.name}. Pulando m√©trica...\")\n",
    "            continue\n",
    "\n",
    "        # --- S√©rie ensemble (m√©dia multimodelo daquela m√©trica) ---\n",
    "        # Se for a m√©dia e j√° existir 'media_multimodelo', aproveita; sen√£o, recalcula\n",
    "        if metrica == \"mean\" and \"media_multimodelo\" in df.columns:\n",
    "            y_ensemble = df[\"media_multimodelo\"].copy()\n",
    "        else:\n",
    "            y_ensemble = df[col_metricas].mean(axis=1)\n",
    "\n",
    "        # Teste de tend√™ncia (Mann-Kendall + regress√£o linear) para essa m√©trica\n",
    "        res_mk = mk.hamed_rao_modification_test(y_ensemble)\n",
    "        reg = linregress(anos, y_ensemble)\n",
    "        slope = reg.slope\n",
    "        intercept = reg.intercept\n",
    "        linha_tendencia = slope * anos + intercept\n",
    "        p_valor = res_mk.p\n",
    "\n",
    "        texto_box = (\n",
    "            f\"M√©trica: {TITULO_METRICA.get(metrica, metrica)}\\n\"\n",
    "            f\"Slope = {slope:.2f} m¬≥/s/ano\\n\"\n",
    "            f\"p-valor = {p_valor:.4f}\"\n",
    "        )\n",
    "\n",
    "       #  # -------------------------------------------------------------------\n",
    "       #  # GR√ÅFICO 1 ‚Äî Todos os modelos (cinza) + M√©dia multimodelo (metric) + reta\n",
    "       #  # -------------------------------------------------------------------\n",
    "       # plt.figure(figsize=(12, 6))\n",
    "        for col in col_metricas:\n",
    "            plt.plot(anos, df[col], color='lightgray', linewidth=1)\n",
    "\n",
    "        plt.plot(anos, y_ensemble, color='black', linewidth=2,\n",
    "                 label=f\"M√©dia Multimodelo ({TITULO_METRICA.get(metrica, metrica)})\")\n",
    "        plt.plot(anos, linha_tendencia, color='red', linestyle='--', label='Tend√™ncia')\n",
    "\n",
    "        plt.title(f\"S√©rie Anual {TITULO_METRICA.get(metrica, metrica)} - Esta√ß√£o {subbacia}\")\n",
    "        plt.xlabel(\"Ano\")\n",
    "        plt.ylabel(ROTULO_METRICA.get(metrica, \"Vaz√£o (m¬≥/s)\"))\n",
    "        plt.legend()\n",
    "        plt.text(\n",
    "            0.98, 0.95, texto_box, transform=plt.gca().transAxes,\n",
    "            fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round\", facecolor='white', edgecolor='gray')\n",
    "        )\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        nome_fig1 = f\"{subbacia}_{metrica}_todos_modelos_media.png\"\n",
    "        plt.savefig(PASTA_SAIDA / nome_fig1, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # GR√ÅFICO 2 ‚Äî Ensemble + faixa P10‚ÄìP90 e Min‚ÄìMax entre modelos (para a m√©trica)\n",
    "        # -------------------------------------------------------------------\n",
    "        # Aqui, os intervalos s√£o para a m√©trica selecionada (por ex., max entre modelos,\n",
    "        # P10 entre modelos, etc.).\n",
    "        p10 = df[col_metricas].quantile(0.10, axis=1)\n",
    "        p90 = df[col_metricas].quantile(0.90, axis=1)\n",
    "        vmin = df[col_metricas].min(axis=1)\n",
    "        vmax = df[col_metricas].max(axis=1)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.fill_between(anos, vmin, vmax, alpha=0.2, label=\"Intervalo M√≠n‚ÄìM√°x\")\n",
    "        plt.fill_between(anos, p10, p90, alpha=0.2, label=\"Intervalo P10‚ÄìP90\")\n",
    "        plt.plot(anos, y_ensemble, color='black', linewidth=2,\n",
    "                 label=f\"M√©dia Multimodelo ({TITULO_METRICA.get(metrica, metrica)})\")\n",
    "        plt.plot(anos, linha_tendencia, color='red', linestyle='--', label='Tend√™ncia')\n",
    "\n",
    "        plt.title(f\"Incerteza Multimodelo ({TITULO_METRICA.get(metrica, metrica)}) - Esta√ß√£o {subbacia}\")\n",
    "        plt.xlabel(\"Ano\")\n",
    "        plt.ylabel(ROTULO_METRICA.get(metrica, \"Vaz√£o (m¬≥/s)\"))\n",
    "        plt.legend()\n",
    "        plt.text(\n",
    "            0.98, 0.95, texto_box, transform=plt.gca().transAxes,\n",
    "            fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round\", facecolor='white', edgecolor='gray')\n",
    "        )\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        nome_fig2 = f\"{subbacia}_{metrica}_media_intervalos.png\"\n",
    "        plt.savefig(PASTA_SAIDA / nome_fig2, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"‚úîÔ∏è Gr√°ficos ({metrica}) salvos para esta√ß√£o {subbacia} em: {PASTA_SAIDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ffb31-e537-4c29-9011-5ed788963985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho da pasta de entrada\n",
    "PASTA_DADOS = Path(r\"C:\\Users\\Matheus Marinho\\Desktop\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Input\")\n",
    "\n",
    "# Lista para armazenar as m√©dias por esta√ß√£o\n",
    "medias = []\n",
    "\n",
    "# Itera sobre os arquivos CSV\n",
    "for caminho_csv in sorted(PASTA_DADOS.glob(\"*.csv\")):\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            caminho_csv,\n",
    "            sep=';',\n",
    "            header=None,\n",
    "            names=[\"dia\", \"mes\", \"ano\", \"valor\"],\n",
    "            dtype=str\n",
    "        )\n",
    "\n",
    "        # Converte valor diretamente, pois j√° est√° com ponto como separador decimal\n",
    "        df[\"valor\"] = pd.to_numeric(df[\"valor\"], errors=\"coerce\")\n",
    "\n",
    "        # Valores -1 s√£o considerados como nulos\n",
    "        df.loc[df[\"valor\"] == -1, \"valor\"] = pd.NA\n",
    "\n",
    "        # Filtra apenas anos entre 1980 e 2010\n",
    "        df[\"ano\"] = pd.to_numeric(df[\"ano\"], errors='coerce')\n",
    "        df_base = df[(df[\"ano\"] >= 1980) & (df[\"ano\"] <= 2023)]\n",
    "\n",
    "        media = df_base[\"valor\"].mean(skipna=True)\n",
    "\n",
    "        medias.append({\n",
    "            \"estacao_obs\": caminho_csv.stem,\n",
    "            \"media_base\": round(media, 2)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao processar {caminho_csv.name}: {e}\")\n",
    "\n",
    "# Exibir resultado\n",
    "df_resultado = pd.DataFrame(medias)\n",
    "print(df_resultado)\n",
    "\n",
    "# Salvar como CSV (separador ponto e v√≠rgula)\n",
    "df_resultado.to_csv(PASTA_DADOS / \"media_periodo_base.csv\", sep=';', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167dd5c-1faf-40a1-8a3b-c9f51c7463c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Analise de Tend√™ncia Hidrol√≥gica Multimodelo - MGB + CLIMBra (CMIP6)\n",
    "# Autor: Matheus Marinho\n",
    "# Objetivo:\n",
    "#   - Avaliar tend√™ncias de vaz√µes anuais simuladas pelo modelo MGB,\n",
    "#     com base em 19 modelos clim√°ticos CMIP6 (cen√°rio SSP5-8.5) do conjunto CLIMBra.\n",
    "#\n",
    "# Metodologia:\n",
    "#   - Aplica√ß√£o do Teste de Mann-Kendall Modificado (Hamed e Rao, 1998)\n",
    "#   - Estimativa da inclina√ß√£o de Theil-Sen para magnitude da tend√™ncia\n",
    "#   - Avalia√ß√£o por horizonte temporal: Curto (2015‚Äì2040), M√©dio (2041‚Äì2070),\n",
    "#     Longo (2071‚Äì2100) e Total (2015‚Äì2100)\n",
    "#   - Classifica√ß√£o de concord√¢ncia entre modelos com base em:\n",
    "#       ‚Ä¢ p-valor < 0.05 (signific√¢ncia estat√≠stica)\n",
    "#       ‚Ä¢ varia√ß√£o relativa ‚â• 10% em rela√ß√£o √† m√©dia hist√≥rica (1980‚Äì2023)\n",
    "#\n",
    "# Sa√≠das:\n",
    "#   - resumo_tendencias_multimodelo.csv:\n",
    "#       Tabela s√≠ntese por sub-bacia e per√≠odo com m√©tricas agregadas e estat√≠sticas do ensemble\n",
    "#   - Detalhado_por_modelo/{sub_bacia}_{periodo}.csv:\n",
    "#       Tend√™ncia individual por modelo: slope, p-valor, varia√ß√£o relativa, signific√¢ncia\n",
    "#\n",
    "# Requisitos:\n",
    "#   - Python 3.x\n",
    "#   - Pacotes: pandas, numpy, pymannkendall, scipy\n",
    "#\n",
    "# Data de execu√ß√£o: Junho de 2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "PASTA_ANUAIS = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245/anuais\")\n",
    "PASTA_SAIDA = PASTA_ANUAIS.parent / \"Concordancia\"\n",
    "PASTA_DETALHADO = PASTA_SAIDA / \"Detalhado_por_modelo\"\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "PASTA_DETALHADO.mkdir(exist_ok=True)\n",
    "\n",
    "# Leitura da m√©dia hist√≥rica (1980‚Äì2023)\n",
    "media_base = pd.read_csv(\n",
    "    r\"E:/IGUA√áU_OTTO/3_Esta√ß√µes FLU/Input/media_periodo_base.csv\",\n",
    "    sep=';', dtype={\"estacao_obs\": str}\n",
    ")\n",
    "media_base[\"estacao_obs\"] = media_base[\"estacao_obs\"].str.strip()\n",
    "\n",
    "# Per√≠odos de an√°lise\n",
    "PERIODOS = {\n",
    "    \"Curto\": (2015, 2040),\n",
    "    \"M√©dio\": (2041, 2070),\n",
    "    \"Longo\": (2071, 2100),\n",
    "    \"Total\": (2015, 2100),\n",
    "}\n",
    "\n",
    "# Loop principal por sub-bacia\n",
    "tabela_final = []\n",
    "\n",
    "for caminho in PASTA_ANUAIS.glob(\"*.csv\"):\n",
    "    nome_sb = caminho.stem.replace(\"_anual\", \"\").strip()\n",
    "\n",
    "    df = pd.read_csv(caminho, sep=\";\")\n",
    "    if \"ano\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Arquivo {caminho.name} n√£o possui coluna 'ano'. Pulando...\")\n",
    "        continue\n",
    "    df = df.set_index(\"ano\")\n",
    "\n",
    "    # Identifica colunas de modelos (exclui 'media_multimodelo')\n",
    "    col_modelos = [col for col in df.columns if col != \"media_multimodelo\"]\n",
    "\n",
    "    linha = media_base.loc[media_base[\"estacao_obs\"] == nome_sb]\n",
    "    if linha.empty:\n",
    "        print(f\"‚ö†Ô∏è M√©dia hist√≥rica n√£o encontrada para sub-bacia {nome_sb}. Pulando...\")\n",
    "        continue\n",
    "    media_hist = linha[\"media_base\"].values[0]\n",
    "\n",
    "    for nome_periodo, (ini, fim) in PERIODOS.items():\n",
    "        df_per = df.loc[ini:fim, col_modelos]\n",
    "        resultados_modelos = []\n",
    "\n",
    "        total = 0\n",
    "        positivos = 0\n",
    "        negativos = 0\n",
    "        significativos = 0\n",
    "\n",
    "        for modelo in df_per.columns:\n",
    "            serie = df_per[modelo].dropna()\n",
    "            if len(serie) < 10:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                resultado = mk.hamed_rao_modification_test(serie)\n",
    "                slope = linregress(serie.index, serie.values).slope\n",
    "                var_relativa = (slope * len(serie)) / media_hist\n",
    "                significancia = resultado.p < 0.05 and abs(var_relativa) >= 0.10\n",
    "\n",
    "                if significancia:\n",
    "                    significativos += 1\n",
    "                    if slope > 0:\n",
    "                        positivos += 1\n",
    "                    else:\n",
    "                        negativos += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "                resultados_modelos.append({\n",
    "                    \"modelo\": modelo,\n",
    "                    \"slope\": round(slope, 4),\n",
    "                    \"p_valor\": round(resultado.p, 4),\n",
    "                    \"var_relativa_%\": round(var_relativa * 100, 2),\n",
    "                    \"significativo\": significancia,\n",
    "                    \"sinal\": \"positivo\" if slope > 0 else \"negativo\"\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERRO] {modelo} - {nome_sb} ({nome_periodo}): {e}\")\n",
    "\n",
    "        # Salvar resultados individuais\n",
    "        df_result_ind = pd.DataFrame(resultados_modelos)\n",
    "        df_result_ind.to_csv(PASTA_DETALHADO / f\"{nome_sb}_{nome_periodo}.csv\", sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "        # Ensemble multimodelo (coluna media_multimodelo)\n",
    "        df_ens = df.loc[ini:fim, \"media_multimodelo\"].dropna()\n",
    "        ens_result = mk.hamed_rao_modification_test(df_ens)\n",
    "        ens_slope = linregress(df_ens.index, df_ens.values).slope\n",
    "        ens_intercept = linregress(df_ens.index, df_ens.values).intercept\n",
    "        ens_var_relativa = (ens_slope * len(df_ens)) / media_hist\n",
    "        ens_significativo = ens_result.p < 0.05 and abs(ens_var_relativa) >= 0.10\n",
    "        ens_sinal = \"positivo\" if ens_slope > 0 else \"negativo\"\n",
    "\n",
    "        # Classifica√ß√£o da concord√¢ncia\n",
    "        prop = significativos / total if total > 0 else 0\n",
    "        if prop >= 0.66:\n",
    "            classe = \"robusta\"\n",
    "        elif prop >= 0.5:\n",
    "            classe = \"moderada\"\n",
    "        else:\n",
    "            classe = \"sem consenso\"\n",
    "\n",
    "        sinal = \"aumento\" if positivos > negativos else (\"redu√ß√£o\" if negativos > positivos else \"neutro\")\n",
    "\n",
    "        tabela_final.append({\n",
    "            \"sub_bacia\": nome_sb,\n",
    "            \"periodo\": nome_periodo,\n",
    "            \"modelos_total\": total,\n",
    "            \"significativos\": significativos,\n",
    "            \"positivos\": positivos,\n",
    "            \"negativos\": negativos,\n",
    "            \"concordancia_%\": round(prop * 100, 1),\n",
    "            \"classe_sinal\": f\"{sinal} {classe}\",\n",
    "            \"ensemble_trend\": ens_result.trend,\n",
    "            \"ensemble_p\": round(ens_result.p, 4),\n",
    "            \"ensemble_slope\": round(ens_slope, 4),\n",
    "            \"ensemble_intercept\": round(ens_intercept, 2),\n",
    "            \"ensemble_var_relativa_%\": round(ens_var_relativa * 100, 2),\n",
    "            \"ensemble_significativo\": ens_significativo,\n",
    "            \"ensemble_sinal\": ens_sinal\n",
    "        })\n",
    "\n",
    "# Exporta resumo final\n",
    "pd.DataFrame(tabela_final).to_csv(\n",
    "    PASTA_SAIDA / \"resumo_tendencias_multimodelo.csv\",\n",
    "    sep=';', index=False, encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úîÔ∏è An√°lise completa salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553bc48-c5b7-49a0-8e43-d46a737bc8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Analise de Tend√™ncia Hidrol√≥gica Multimodelo - MGB + CLIMBra (CMIP6)\n",
    "# Autor: Matheus Marinho\n",
    "# Objetivo:\n",
    "#   - Avaliar tend√™ncias de vaz√µes anuais simuladas pelo modelo MGB,\n",
    "#     com base em 19 modelos clim√°ticos CMIP6 (cen√°rio SSP5-8.5) do conjunto CLIMBra.\n",
    "#\n",
    "# Agora:\n",
    "#   - A an√°lise √© feita separadamente para as estat√≠sticas anuais:\n",
    "#       ‚Ä¢ vaz√£o m√≠nima (min)\n",
    "#       ‚Ä¢ vaz√£o m√©dia (mean)\n",
    "#       ‚Ä¢ vaz√£o m√°xima (max)\n",
    "#       ‚Ä¢ P10 (q10)\n",
    "#       ‚Ä¢ P90 (q90)\n",
    "#\n",
    "# Metodologia:\n",
    "#   - Aplica√ß√£o do Teste de Mann-Kendall Modificado (Hamed e Rao, 1998)\n",
    "#   - Estimativa da inclina√ß√£o de Theil-Sen / regress√£o linear (slope)\n",
    "#   - Avalia√ß√£o por horizonte temporal: Curto (2015‚Äì2040), M√©dio (2041‚Äì2070),\n",
    "#     Longo (2071‚Äì2100) e Total (2015‚Äì2100)\n",
    "#   - Classifica√ß√£o de concord√¢ncia entre modelos com base em:\n",
    "#       ‚Ä¢ p-valor < 0.05 (signific√¢ncia estat√≠stica)\n",
    "#       ‚Ä¢ varia√ß√£o relativa ‚â• 10% em rela√ß√£o √† m√©dia hist√≥rica (1980‚Äì2023)\n",
    "#\n",
    "# Sa√≠das:\n",
    "#   - resumo_tendencias_multimodelo_metricas.csv:\n",
    "#       Tabela s√≠ntese por sub-bacia, per√≠odo e vari√°vel (min, mean, max, q10, q90)\n",
    "#   - Detalhado_por_modelo/{sub_bacia}_{variavel}_{periodo}.csv:\n",
    "#       Tend√™ncia individual por modelo: slope, p-valor, varia√ß√£o relativa, signific√¢ncia\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "PASTA_ANUAIS = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\\anuais_est\")\n",
    "PASTA_SAIDA = PASTA_ANUAIS.parent / \"Concordancia_est\"\n",
    "PASTA_DETALHADO = PASTA_SAIDA / \"Detalhado_por_modelo\"\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "PASTA_DETALHADO.mkdir(exist_ok=True)\n",
    "\n",
    "# Leitura da m√©dia hist√≥rica (1980‚Äì2023)\n",
    "media_base = pd.read_csv(\n",
    "    r\"E:/IGUA√áU_OTTO/3_Esta√ß√µes FLU/Input/media_periodo_base.csv\",\n",
    "    sep=';', dtype={\"estacao_obs\": str}\n",
    ")\n",
    "media_base[\"estacao_obs\"] = media_base[\"estacao_obs\"].str.strip()\n",
    "\n",
    "# Per√≠odos de an√°lise\n",
    "PERIODOS = {\n",
    "    \"Curto\": (2015, 2040),\n",
    "    \"M√©dio\": (2041, 2070),\n",
    "    \"Longo\": (2071, 2100),\n",
    "    \"Total\": (2015, 2100),\n",
    "}\n",
    "\n",
    "# Vari√°veis (estat√≠sticas anuais) a analisar\n",
    "VARIAVEIS = [\"min\", \"mean\", \"max\", \"q10\", \"q90\"]\n",
    "NOME_VARIAVEL = {\n",
    "    \"min\": \"m√≠nima\",\n",
    "    \"mean\": \"m√©dia\",\n",
    "    \"max\": \"m√°xima\",\n",
    "    \"q10\": \"P10\",\n",
    "    \"q90\": \"P90\",\n",
    "}\n",
    "\n",
    "# Tabela resumo final (todas as sub-bacias, per√≠odos e vari√°veis)\n",
    "tabela_final = []\n",
    "\n",
    "# Loop principal por sub-bacia\n",
    "for caminho in PASTA_ANUAIS.glob(\"*.csv\"):\n",
    "    nome_sb = caminho.stem.replace(\"_anual\", \"\").strip()\n",
    "\n",
    "    df = pd.read_csv(caminho, sep=\";\")\n",
    "    if \"ano\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Arquivo {caminho.name} n√£o possui coluna 'ano'. Pulando...\")\n",
    "        continue\n",
    "\n",
    "    df = df.set_index(\"ano\")\n",
    "\n",
    "    # M√©dia hist√≥rica da sub-bacia\n",
    "    linha = media_base.loc[media_base[\"estacao_obs\"] == nome_sb]\n",
    "    if linha.empty:\n",
    "        print(f\"‚ö†Ô∏è M√©dia hist√≥rica n√£o encontrada para sub-bacia {nome_sb}. Pulando...\")\n",
    "        continue\n",
    "    media_hist = linha[\"media_base\"].values[0]\n",
    "\n",
    "    # Loop por vari√°vel (min, mean, max, q10, q90)\n",
    "    for var in VARIAVEIS:\n",
    "        # Colunas dos modelos correspondentes a essa vari√°vel (ex: modelo1_mean, modelo2_mean, ...)\n",
    "        col_modelos_var = [c for c in df.columns if c.endswith(f\"_{var}\")]\n",
    "        if len(col_modelos_var) == 0:\n",
    "            print(f\"‚ö†Ô∏è Nenhuma coluna encontrada para vari√°vel '{var}' em {caminho.name}. Pulando vari√°vel...\")\n",
    "            continue\n",
    "\n",
    "        # Loop por per√≠odo (Curto, M√©dio, Longo, Total)\n",
    "        for nome_periodo, (ini, fim) in PERIODOS.items():\n",
    "            df_per = df.loc[ini:fim, col_modelos_var]\n",
    "\n",
    "            resultados_modelos = []\n",
    "\n",
    "            total = 0\n",
    "            positivos = 0\n",
    "            negativos = 0\n",
    "            significativos = 0\n",
    "\n",
    "            # --- An√°lise modelo a modelo ---\n",
    "            for modelo in df_per.columns:\n",
    "                serie = df_per[modelo].dropna()\n",
    "                if len(serie) < 10:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Teste de Mann-Kendall modificado\n",
    "                    resultado = mk.hamed_rao_modification_test(serie)\n",
    "\n",
    "                    # Regress√£o linear (slope em unidades de vaz√£o / ano)\n",
    "                    reg = linregress(serie.index.values, serie.values)\n",
    "                    slope = reg.slope\n",
    "\n",
    "                    # Varia√ß√£o relativa ao longo do per√≠odo, em rela√ß√£o √† m√©dia hist√≥rica\n",
    "                    var_relativa = (slope * len(serie)) / media_hist  # fra√ß√£o da m√©dia hist√≥rica\n",
    "                    significancia = (resultado.p < 0.05) and (abs(var_relativa) >= 0.10)\n",
    "\n",
    "                    if significancia:\n",
    "                        significativos += 1\n",
    "                        if slope > 0:\n",
    "                            positivos += 1\n",
    "                        else:\n",
    "                            negativos += 1\n",
    "\n",
    "                    total += 1\n",
    "\n",
    "                    resultados_modelos.append({\n",
    "                        \"sub_bacia\": nome_sb,\n",
    "                        \"periodo\": nome_periodo,\n",
    "                        \"variavel\": NOME_VARIAVEL[var],\n",
    "                        \"modelo\": modelo,\n",
    "                        \"slope\": round(slope, 4),\n",
    "                        \"p_valor\": round(resultado.p, 4),\n",
    "                        \"tau\": round(resultado.Tau, 4),\n",
    "                        \"var_relativa_%\": round(var_relativa * 100, 2),\n",
    "                        \"significativo\": significancia,\n",
    "                        \"sinal\": \"positivo\" if slope > 0 else \"negativo\"\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERRO] {modelo} - {nome_sb} ({nome_periodo}, {var}): {e}\")\n",
    "\n",
    "            # Salvar resultados individuais (se houver modelos analisados)\n",
    "            df_result_ind = pd.DataFrame(resultados_modelos)\n",
    "            if not df_result_ind.empty:\n",
    "                nome_detalhe = f\"{nome_sb}_{var}_{nome_periodo}.csv\"\n",
    "                df_result_ind.to_csv(\n",
    "                    PASTA_DETALHADO / nome_detalhe,\n",
    "                    sep=';', index=False, encoding='utf-8-sig'\n",
    "                )\n",
    "\n",
    "            # --- Ensemble multimodelo para a vari√°vel ---\n",
    "            df_ens = df_per.mean(axis=1).dropna()\n",
    "            if len(df_ens) >= 10:\n",
    "                ens_result = mk.hamed_rao_modification_test(df_ens)\n",
    "                reg_ens = linregress(df_ens.index.values, df_ens.values)\n",
    "                ens_slope = reg_ens.slope\n",
    "                ens_intercept = reg_ens.intercept\n",
    "                ens_var_relativa = (ens_slope * len(df_ens)) / media_hist\n",
    "                ens_significativo = (ens_result.p < 0.05) and (abs(ens_var_relativa) >= 0.10)\n",
    "                ens_sinal = \"positivo\" if ens_slope > 0 else \"negativo\"\n",
    "            else:\n",
    "                # Caso extremo de poucos anos\n",
    "                ens_result = None\n",
    "                ens_slope = np.nan\n",
    "                ens_intercept = np.nan\n",
    "                ens_var_relativa = np.nan\n",
    "                ens_significativo = False\n",
    "                ens_sinal = \"indefinido\"\n",
    "\n",
    "            # Classifica√ß√£o da concord√¢ncia entre modelos\n",
    "            prop = significativos / total if total > 0 else 0\n",
    "            if prop >= 0.66:\n",
    "                classe = \"robusta\"\n",
    "            elif prop >= 0.5:\n",
    "                classe = \"moderada\"\n",
    "            else:\n",
    "                classe = \"sem consenso\"\n",
    "\n",
    "            if positivos > negativos:\n",
    "                sinal_conjunto = \"aumento\"\n",
    "            elif negativos > positivos:\n",
    "                sinal_conjunto = \"redu√ß√£o\"\n",
    "            else:\n",
    "                sinal_conjunto = \"neutro\"\n",
    "\n",
    "            tabela_final.append({\n",
    "                \"sub_bacia\": nome_sb,\n",
    "                \"periodo\": nome_periodo,\n",
    "                \"variavel\": NOME_VARIAVEL[var],\n",
    "                \"modelos_total\": total,\n",
    "                \"significativos\": significativos,\n",
    "                \"positivos\": positivos,\n",
    "                \"negativos\": negativos,\n",
    "                \"concordancia_%\": round(prop * 100, 1),\n",
    "                \"classe_sinal\": f\"{sinal_conjunto} {classe}\",\n",
    "                \"ensemble_trend\": ens_result.trend if ens_result is not None else \"NA\",\n",
    "                \"ensemble_p\": round(ens_result.p, 4) if ens_result is not None else np.nan,\n",
    "                \"ensemble_tau\": round(ens_result.Tau, 4) if ens_result is not None else np.nan,\n",
    "                \"ensemble_slope\": round(ens_slope, 4) if not np.isnan(ens_slope) else np.nan,\n",
    "                \"ensemble_intercept\": round(ens_intercept, 2) if not np.isnan(ens_intercept) else np.nan,\n",
    "                \"ensemble_var_relativa_%\": round(ens_var_relativa * 100, 2) if not np.isnan(ens_var_relativa) else np.nan,\n",
    "                \"ensemble_significativo\": ens_significativo,\n",
    "                \"ensemble_sinal\": ens_sinal\n",
    "            })\n",
    "\n",
    "# Exporta resumo final (todas as vari√°veis e per√≠odos)\n",
    "pd.DataFrame(tabela_final).to_csv(\n",
    "    PASTA_SAIDA / \"resumo_tendencias_multimodelo_metricas.csv\",\n",
    "    sep=';', index=False, encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úîÔ∏è An√°lise completa (min, m√©dia, max, P10, P90) salva com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a3ee0-7553-46fd-ab20-ed3ab88d0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Compara√ß√£o entre Cen√°rios SSP2-4.5 e SSP5-8.5 com Incerteza Multimodelo\n",
    "# ------------------------------------------------------------------------------\n",
    "# Este script gera gr√°ficos comparando os dois cen√°rios de emiss√£o para cada\n",
    "# sub-bacia, com as seguintes camadas:\n",
    "#   - M√©dia multimodelo de cada cen√°rio\n",
    "#   - Faixas de incerteza (P10‚ÄìP90) para cada cen√°rio\n",
    "#   - Retas de tend√™ncia (Sen) para as m√©dias multimodelo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "import pymannkendall as mk\n",
    "\n",
    "# Pastas de entrada\n",
    "PASTA_SSP245 = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245/anuais\")\n",
    "PASTA_SSP585 = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp585 - Clima\\8_Resultados_ssp585/anuais\")\n",
    "PASTA_SAIDA = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp585 - Clima\\8_Resultados_ssp585/Comparacao_Cenarios\")\n",
    "PASTA_SAIDA.mkdir(exist_ok=True)\n",
    "\n",
    "# Lista de sub-bacias baseada nos arquivos SSP2-4.5\n",
    "for caminho_245 in PASTA_SSP245.glob(\"*_anual.csv\"):\n",
    "    nome_sb = caminho_245.stem.replace(\"_anual\", \"\")\n",
    "    caminho_585 = PASTA_SSP585 / f\"{nome_sb}_anual.csv\"\n",
    "\n",
    "    if not caminho_585.exists():\n",
    "        print(f\"‚ö†Ô∏è Arquivo ausente para SSP5-8.5: {nome_sb}\")\n",
    "        continue\n",
    "\n",
    "    # Leitura dos dois cen√°rios\n",
    "    df_245 = pd.read_csv(caminho_245, sep=';')\n",
    "    df_585 = pd.read_csv(caminho_585, sep=';')\n",
    "\n",
    "    # Valida√ß√£o\n",
    "    if 'ano' not in df_245.columns or 'media_multimodelo' not in df_245.columns:\n",
    "        print(f\"‚ö†Ô∏è Dados incompletos em SSP2-4.5: {nome_sb}\")\n",
    "        continue\n",
    "    if 'ano' not in df_585.columns or 'media_multimodelo' not in df_585.columns:\n",
    "        print(f\"‚ö†Ô∏è Dados incompletos em SSP5-8.5: {nome_sb}\")\n",
    "        continue\n",
    "\n",
    "    anos = df_245['ano']\n",
    "\n",
    "    # Incerteza SSP2-4.5\n",
    "    col_mod_245 = [col for col in df_245.columns if col not in ['ano', 'media_multimodelo']]\n",
    "    df_245['p10'] = df_245[col_mod_245].quantile(0.10, axis=1)\n",
    "    df_245['p90'] = df_245[col_mod_245].quantile(0.90, axis=1)\n",
    "\n",
    "    # Incerteza SSP5-8.5\n",
    "    col_mod_585 = [col for col in df_585.columns if col not in ['ano', 'media_multimodelo']]\n",
    "    df_585['p10'] = df_585[col_mod_585].quantile(0.10, axis=1)\n",
    "    df_585['p90'] = df_585[col_mod_585].quantile(0.90, axis=1)\n",
    "\n",
    "    # Tend√™ncia SSP2-4.5\n",
    "    x = anos\n",
    "    y_245 = df_245['media_multimodelo']\n",
    "    mk_245 = mk.hamed_rao_modification_test(y_245)\n",
    "    reg_245 = linregress(x, y_245)\n",
    "    linha_245 = reg_245.slope * x + reg_245.intercept\n",
    "\n",
    "    # Tend√™ncia SSP5-8.5\n",
    "    y_585 = df_585['media_multimodelo']\n",
    "    mk_585 = mk.hamed_rao_modification_test(y_585)\n",
    "    reg_585 = linregress(x, y_585)\n",
    "    linha_585 = reg_585.slope * x + reg_585.intercept\n",
    "\n",
    "    # Plotagem\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.fill_between(x, df_245['p10'], df_245['p90'], color='blue', alpha=0.2, label='SSP2-4.5: P10‚ÄìP90')\n",
    "    plt.fill_between(x, df_585['p10'], df_585['p90'], color='red', alpha=0.2, label='SSP5-8.5: P10‚ÄìP90')\n",
    "    plt.plot(x, y_245, color='blue', linewidth=2, label='M√©dia SSP2-4.5')\n",
    "    plt.plot(x, y_585, color='red', linewidth=2, label='M√©dia SSP5-8.5')\n",
    "    plt.plot(x, linha_245, color='blue', linestyle='--', label='Tend√™ncia SSP2-4.5')\n",
    "    plt.plot(x, linha_585, color='red', linestyle='--', label='Tend√™ncia SSP5-8.5')\n",
    "\n",
    "    # T√≠tulo e legenda\n",
    "    plt.title(f\"Compara√ß√£o de Cen√°rios - Esta√ß√£o {nome_sb}\")\n",
    "    plt.xlabel(\"Ano\")\n",
    "    plt.ylabel(\"Vaz√£o m√©dia anual (m¬≥/s)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salva\n",
    "    plt.savefig(PASTA_SAIDA / f\"{nome_sb}_comparacao_cenarios.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"‚úîÔ∏è Gr√°fico salvo para esta√ß√£o {nome_sb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63359eb4-fbf7-4500-8980-70aebd802897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Avalia√ß√£o dos Resultados do MGB com Modelos CLIMBra/CMIP6\n",
    "#\n",
    "# Para cada esta√ß√£o gera:\n",
    "#   1) Distribui√ß√µes das vaz√µes m√©dias mensais (cada modelo x observado)\n",
    "#      -> 1 figura POR MODELO, estilo violin + boxplot (como exemplo enviado)\n",
    "#   2) Distribui√ß√µes das vaz√µes m√©dias mensais (m√©dia dos modelos x observado)\n",
    "#   3) Curvas de perman√™ncia di√°ria (FDC) para cada modelo x observado\n",
    "#   4) FDC para cada modelo x observado desconsiderando p1 e p99\n",
    "#   5) FDC para a m√©dia dos modelos x observado (completa e sem extremos)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "# ================= CONFIGURA√á√ïES DE PASTA =====================================\n",
    "\n",
    "PASTA_DIARIOS = Path(r\"E:\\IGUA√áU_OTTO\\7_Proje√ß√µes_ssp245_clima\\8_Resultados_ssp245\\diarios\")\n",
    "PASTA_OBS     = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Input\\Observados\")\n",
    "\n",
    "PASTA_SAIDA   = PASTA_DIARIOS.parent / \"avaliacao_modelos\"\n",
    "PASTA_SAIDA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MES_LABELS = [\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\",\n",
    "              \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"]\n",
    "\n",
    "# ==================== FUN√á√ïES AUXILIARES ======================================\n",
    "\n",
    "def carregar_dados(estacao: str):\n",
    "    \"\"\"\n",
    "    L√™ os dados di√°rios de modelos e observados para uma esta√ß√£o.\n",
    "    - modelos: PASTA_DIARIOS / '{estacao}.csv'  (com cabe√ßalho)\n",
    "    - observado: PASTA_OBS / '{estacao}.csv'    (SEM cabe√ßalho, 4 colunas: dia;mes;ano;Qobs)\n",
    "    \"\"\"\n",
    "    # --- Simulado (modelos) ---\n",
    "    arq_mod = PASTA_DIARIOS / f\"{estacao}.csv\"\n",
    "    if not arq_mod.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo de modelos n√£o encontrado: {arq_mod}\")\n",
    "\n",
    "    df_mod = pd.read_csv(arq_mod, sep=';')\n",
    "    df_mod.columns = [c.strip() for c in df_mod.columns]\n",
    "\n",
    "    if not {\"dia\", \"mes\", \"ano\"}.issubset({c.lower() for c in df_mod.columns}):\n",
    "        raise ValueError(f\"Esperado colunas dia, mes, ano em {arq_mod}\")\n",
    "\n",
    "    col_dia_m = [c for c in df_mod.columns if c.lower() == \"dia\"][0]\n",
    "    col_mes_m = [c for c in df_mod.columns if c.lower() == \"mes\"][0]\n",
    "    col_ano_m = [c for c in df_mod.columns if c.lower() == \"ano\"][0]\n",
    "\n",
    "    df_mod[\"data\"] = pd.to_datetime(\n",
    "        dict(year=df_mod[col_ano_m], month=df_mod[col_mes_m], day=df_mod[col_dia_m]),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df_mod = df_mod.dropna(subset=[\"data\"]).set_index(\"data\").sort_index()\n",
    "\n",
    "    col_modelos = [c for c in df_mod.columns if c not in [col_dia_m, col_mes_m, col_ano_m]]\n",
    "\n",
    "    # --- Observado ---\n",
    "    arq_obs = PASTA_OBS / f\"{estacao}.csv\"\n",
    "    if not arq_obs.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo de observados n√£o encontrado: {arq_obs}\")\n",
    "\n",
    "    # sem cabe√ßalho: dia;mes;ano;Qobs\n",
    "    df_obs = pd.read_csv(arq_obs, sep=';', header=None)\n",
    "    if df_obs.shape[1] != 4:\n",
    "        raise ValueError(f\"Esperado 4 colunas (dia;mes;ano;Qobs) em {arq_obs}\")\n",
    "\n",
    "    df_obs.columns = [\"dia\", \"mes\", \"ano\", \"Qobs\"]\n",
    "\n",
    "    df_obs[\"data\"] = pd.to_datetime(\n",
    "        dict(year=df_obs[\"ano\"], month=df_obs[\"mes\"], day=df_obs[\"dia\"]),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df_obs = df_obs.dropna(subset=[\"data\"]).set_index(\"data\").sort_index()\n",
    "    df_obs = df_obs[[\"Qobs\"]]\n",
    "\n",
    "    # --- Merge (interse√ß√£o de datas) ---\n",
    "    df = df_mod[col_modelos].join(df_obs, how=\"inner\")\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"N√£o h√° datas em comum entre modelos e observado para a esta√ß√£o {estacao}.\")\n",
    "\n",
    "    df = df[[\"Qobs\"] + col_modelos]\n",
    "\n",
    "    return df, col_modelos\n",
    "\n",
    "def calcular_medias_mensais(df):\n",
    "    \"\"\"\n",
    "    M√©dias mensais a partir da s√©rie di√°ria.\n",
    "    Usa 'ME' (MonthEnd).\n",
    "    \"\"\"\n",
    "    mensal = df.resample(\"ME\").mean()\n",
    "    mensal[\"mes\"] = mensal.index.month\n",
    "    mensal[\"ano\"] = mensal.index.year\n",
    "    return mensal\n",
    "\n",
    "def curva_permanencia(serie, clip_percentis=None):\n",
    "    s = pd.Series(serie).dropna()\n",
    "\n",
    "    if clip_percentis is not None:\n",
    "        lo, hi = clip_percentis\n",
    "        q_lo = s.quantile(lo)\n",
    "        q_hi = s.quantile(hi)\n",
    "        s = s[(s >= q_lo) & (s <= q_hi)]\n",
    "\n",
    "    if len(s) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    vals = np.sort(s.values)[::-1]\n",
    "    n = len(vals)\n",
    "    exced = np.arange(1, n + 1) / (n + 1) * 100.0\n",
    "    return exced, vals\n",
    "\n",
    "# ==================== PLOTS: 1 ‚Äì VIOLIN POR MODELO (ESTILO FIGURA) ============\n",
    "\n",
    "def plot_violin_mensal_por_modelo(mensal, modelos, nome_estacao, pasta_saida):\n",
    "    \"\"\"\n",
    "    Para cada modelo gera uma figura:\n",
    "      - 12 violins coloridos (um por m√™s) das vaz√µes m√©dias mensais do modelo\n",
    "      - boxplots em preto/branco dentro dos violins\n",
    "      - pontos da mediana observada deslocados (compara√ß√£o modelo x obs)\n",
    "    \"\"\"\n",
    "    if mensal.empty:\n",
    "        print(f\"‚ö† Mensal vazio em {nome_estacao}; violins por modelo n√£o ser√£o gerados.\")\n",
    "        return\n",
    "\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "    for modelo in modelos:\n",
    "        # dados modelos/obs dessa esta√ß√£o\n",
    "        dados_modelo = []\n",
    "        med_obs = []\n",
    "        for m in range(1, 13):\n",
    "            vals_mod = mensal.loc[mensal[\"mes\"] == m, modelo].dropna().values\n",
    "            # garantir pelo menos 2 pontos pra KDE\n",
    "            if len(vals_mod) == 0:\n",
    "                vals_mod = np.array([0.001, 0.0011])\n",
    "            elif len(vals_mod) == 1:\n",
    "                v = float(vals_mod[0])\n",
    "                eps = abs(v) * 0.001 if v != 0 else 0.001\n",
    "                vals_mod = np.array([v - eps, v + eps])\n",
    "            dados_modelo.append(vals_mod)\n",
    "\n",
    "            med = mensal.loc[mensal[\"mes\"] == m, \"Qobs\"].median()\n",
    "            med_obs.append(med)\n",
    "\n",
    "        # limites y (modelo + obs)\n",
    "        all_vals = np.concatenate([np.concatenate(dados_modelo), np.array(med_obs, dtype=float)])\n",
    "        all_vals = all_vals[np.isfinite(all_vals)]\n",
    "        if all_vals.size == 0:\n",
    "            print(f\"‚ö† Sem dados v√°lidos para modelo {modelo} na esta√ß√£o {nome_estacao}.\")\n",
    "            continue\n",
    "        vmin = max(np.nanmin(all_vals), 0.01)\n",
    "        vmax = np.nanmax(all_vals) * 1.1\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "\n",
    "        pos = np.arange(1, 13)\n",
    "\n",
    "        # violins\n",
    "        parts = ax.violinplot(\n",
    "            dados_modelo,\n",
    "            positions=pos,\n",
    "            showmeans=False,\n",
    "            showextrema=False,\n",
    "            widths=0.9,\n",
    "        )\n",
    "\n",
    "        colors = [cmap(i % 20) for i in range(12)]\n",
    "        for i, pc in enumerate(parts[\"bodies\"]):\n",
    "            pc.set_facecolor(colors[i])\n",
    "            pc.set_edgecolor(\"none\")\n",
    "            pc.set_alpha(0.7)\n",
    "\n",
    "        # boxplots dentro dos violins\n",
    "        bp = ax.boxplot(\n",
    "            dados_modelo,\n",
    "            positions=pos,\n",
    "            widths=0.25,\n",
    "            patch_artist=True,\n",
    "            showfliers=False\n",
    "        )\n",
    "        for patch in bp[\"boxes\"]:\n",
    "            patch.set_facecolor(\"white\")\n",
    "            patch.set_edgecolor(\"black\")\n",
    "            patch.set_linewidth(1.0)\n",
    "        for whisker in bp[\"whiskers\"]:\n",
    "            whisker.set_color(\"black\")\n",
    "            whisker.set_linewidth(1.0)\n",
    "        for cap in bp[\"caps\"]:\n",
    "            cap.set_color(\"black\")\n",
    "            cap.set_linewidth(1.0)\n",
    "        for median in bp[\"medians\"]:\n",
    "            median.set_color(\"black\")\n",
    "            median.set_linewidth(1.0)\n",
    "\n",
    "        # mediana observada (ponto preto, deslocado ligeiramente)\n",
    "        ax.scatter(\n",
    "            pos + 0.25,\n",
    "            med_obs,\n",
    "            s=25,\n",
    "            c=\"black\",\n",
    "            zorder=3,\n",
    "            label=\"Mediana observada\"\n",
    "        )\n",
    "\n",
    "        ax.set_xticks(pos)\n",
    "        ax.set_xticklabels(MES_LABELS)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_ylim(vmin, vmax)\n",
    "        ax.set_ylabel(\"Vaz√£o M√©dia Mensal (m¬≥/s)\")\n",
    "        ax.set_title(f\"Distribui√ß√£o da Vaz√£o M√©dia Mensal - Modelo {modelo}\\nEsta√ß√£o {nome_estacao}\")\n",
    "        ax.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\n",
    "            pasta_saida / f\"{nome_estacao}_modelo_{modelo}_violin_mensal.png\",\n",
    "            dpi=300\n",
    "        )\n",
    "        plt.close(fig)\n",
    "\n",
    "# ==================== PLOTS: 2 ‚Äì VIOLIN ENSEMBLE ==============================\n",
    "\n",
    "def plot_violin_mensal_ensemble(mensal, modelos, nome_estacao, pasta_saida):\n",
    "    \"\"\"\n",
    "    Distribui√ß√£o das vaz√µes m√©dias mensais comparando a m√©dia dos modelos x observado.\n",
    "    \"\"\"\n",
    "    if mensal.empty:\n",
    "        print(f\"‚ö† Mensal vazio em {nome_estacao}; violin ensemble n√£o ser√° gerado.\")\n",
    "        return\n",
    "\n",
    "    mensal = mensal.copy()\n",
    "    mensal[\"ensemble_mean\"] = mensal[modelos].mean(axis=1)\n",
    "\n",
    "    vals = mensal[[\"Qobs\", \"ensemble_mean\"]].to_numpy().astype(float).ravel()\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    if vals.size == 0:\n",
    "        print(f\"‚ö† Sem dados v√°lidos para violin ensemble em {nome_estacao}.\")\n",
    "        return\n",
    "\n",
    "    vmin = max(np.nanmin(vals), 0.01)\n",
    "    vmax = np.nanmax(vals) * 1.1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "\n",
    "    dados_violin = []\n",
    "    med_obs = []\n",
    "    for m in range(1, 13):\n",
    "        vals_ens = mensal.loc[mensal[\"mes\"] == m, \"ensemble_mean\"].dropna().values\n",
    "        if len(vals_ens) == 0:\n",
    "            vals_ens = np.array([0.001, 0.0011])\n",
    "        elif len(vals_ens) == 1:\n",
    "            v = float(vals_ens[0])\n",
    "            eps = abs(v) * 0.001 if v != 0 else 0.001\n",
    "            vals_ens = np.array([v - eps, v + eps])\n",
    "        dados_violin.append(vals_ens)\n",
    "\n",
    "        med = mensal.loc[mensal[\"mes\"] == m, \"Qobs\"].median()\n",
    "        med_obs.append(med)\n",
    "\n",
    "    pos = np.arange(1, 13)\n",
    "\n",
    "    parts = ax.violinplot(\n",
    "        dados_violin,\n",
    "        positions=pos,\n",
    "        showmeans=False,\n",
    "        showextrema=False,\n",
    "        widths=0.9,\n",
    "    )\n",
    "\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "    for i, pc in enumerate(parts[\"bodies\"]):\n",
    "        pc.set_facecolor(cmap(i % 20))\n",
    "        pc.set_edgecolor(\"none\")\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    bp = ax.boxplot(\n",
    "        dados_violin,\n",
    "        positions=pos,\n",
    "        widths=0.25,\n",
    "        patch_artist=True,\n",
    "        showfliers=False\n",
    "    )\n",
    "    for patch in bp[\"boxes\"]:\n",
    "        patch.set_facecolor(\"white\")\n",
    "        patch.set_edgecolor(\"black\")\n",
    "        patch.set_linewidth(1.0)\n",
    "    for whisker in bp[\"whiskers\"]:\n",
    "        whisker.set_color(\"black\")\n",
    "        whisker.set_linewidth(1.0)\n",
    "    for cap in bp[\"caps\"]:\n",
    "        cap.set_color(\"black\")\n",
    "        cap.set_linewidth(1.0)\n",
    "    for median in bp[\"medians\"]:\n",
    "        median.set_color(\"black\")\n",
    "        median.set_linewidth(1.0)\n",
    "\n",
    "    ax.scatter(\n",
    "        pos + 0.25,\n",
    "        med_obs,\n",
    "        s=25,\n",
    "        c=\"black\",\n",
    "        zorder=3,\n",
    "        label=\"Mediana observada\"\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(MES_LABELS)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(vmin, vmax)\n",
    "    ax.set_ylabel(\"Vaz√£o M√©dia Mensal (m¬≥/s)\")\n",
    "    ax.set_xlabel(\"M√™s\")\n",
    "    ax.set_title(\n",
    "        f\"Distribui√ß√£o da Vaz√£o M√©dia Mensal\\nM√©dia dos modelos vs Observado - Esta√ß√£o {nome_estacao}\"\n",
    "    )\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\n",
    "        pasta_saida / f\"{nome_estacao}_ensemble_violin_mensal.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "# ==================== PLOTS: 3, 4, 5 ‚Äì FDCs ===================================\n",
    "\n",
    "def plot_fdc_por_modelo(df, modelos, nome_estacao, pasta_saida,\n",
    "                        clip_percentis=None, sufixo=\"\"):\n",
    "    \"\"\"\n",
    "    3 e 4) Curvas de perman√™ncia di√°rias para cada modelo comparando com o observado.\n",
    "    \"\"\"\n",
    "    n_models = len(modelos)\n",
    "    ncols = 4\n",
    "    nrows = math.ceil(n_models / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 3.5 * nrows),\n",
    "                             sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    x_obs, y_obs = curva_permanencia(df[\"Qobs\"], clip_percentis=clip_percentis)\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "    for i, modelo in enumerate(modelos):\n",
    "        ax = axes[i]\n",
    "        x_mod, y_mod = curva_permanencia(df[modelo], clip_percentis=clip_percentis)\n",
    "        if len(x_mod) == 0 or len(x_obs) == 0:\n",
    "            continue\n",
    "\n",
    "        ax.plot(x_mod, y_mod, color=cmap(i % 20), linewidth=1.5, label=modelo)\n",
    "        ax.plot(x_obs, y_obs, color=\"black\", linewidth=1.2, label=\"Obs\")\n",
    "\n",
    "        ax.set_title(modelo, fontsize=9)\n",
    "        ax.set_yscale(\"log\")\n",
    "        if i % ncols == 0:\n",
    "            ax.set_ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "        if i // ncols == nrows - 1:\n",
    "            ax.set_xlabel(\"Percentual de Exced√™ncia (%)\")\n",
    "\n",
    "    for j in range(n_models, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    if clip_percentis is None:\n",
    "        extra = \"\"\n",
    "    else:\n",
    "        lo, hi = clip_percentis\n",
    "        extra = f\" (desconsiderando p{int(lo*100)} e p{int(hi*100)})\"\n",
    "\n",
    "    fig.suptitle(f\"Curvas de Perman√™ncia Di√°ria - Modelos vs Observado\\n\"\n",
    "                 f\"Esta√ß√£o {nome_estacao}{extra}\",\n",
    "                 fontsize=12)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "\n",
    "    nome_fig = f\"{nome_estacao}_3_4_fdc_modelos_vs_obs{sufixo}.png\"\n",
    "    fig.savefig(pasta_saida / nome_fig, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_fdc_ensemble(df, modelos, nome_estacao, pasta_saida,\n",
    "                      clip_percentis=None, sufixo=\"\"):\n",
    "    \"\"\"\n",
    "    5) Curva de perman√™ncia di√°ria para a m√©dia dos modelos comparando com per√≠odo observado.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"ensemble_mean\"] = df[modelos].mean(axis=1)\n",
    "\n",
    "    x_obs, y_obs = curva_permanencia(df[\"Qobs\"], clip_percentis=clip_percentis)\n",
    "    x_ens, y_ens = curva_permanencia(df[\"ensemble_mean\"], clip_percentis=clip_percentis)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax.plot(x_ens, y_ens, color=\"tab:blue\", linewidth=2, label=\"M√©dia dos modelos\")\n",
    "    ax.plot(x_obs, y_obs, color=\"black\", linewidth=1.5, label=\"Obs\")\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Percentual de Exced√™ncia (%)\")\n",
    "    ax.set_ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "\n",
    "    if clip_percentis is None:\n",
    "        extra = \"\"\n",
    "    else:\n",
    "        lo, hi = clip_percentis\n",
    "        extra = f\" (desconsiderando p{int(lo*100)} e p{int(hi*100)})\"\n",
    "\n",
    "    ax.set_title(f\"Curva de Perman√™ncia Di√°ria - M√©dia dos modelos vs Observado\\n\"\n",
    "                 f\"Esta√ß√£o {nome_estacao}{extra}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    nome_fig = f\"{nome_estacao}_5_fdc_ensemble_vs_obs{sufixo}.png\"\n",
    "    fig.savefig(pasta_saida / nome_fig, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ==================== LOOP PRINCIPAL ==========================================\n",
    "\n",
    "for caminho_csv in PASTA_DIARIOS.glob(\"*.csv\"):\n",
    "    estacao = caminho_csv.stem\n",
    "    try:\n",
    "        df, modelos = carregar_dados(estacao)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Erro ao processar esta√ß√£o {estacao}: {e}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processando esta√ß√£o {estacao} ({len(modelos)} modelos)...\")\n",
    "\n",
    "    mensal = calcular_medias_mensais(df)\n",
    "\n",
    "    # 1) violins por modelo (estilo figura enviada)\n",
    "    plot_violin_mensal_por_modelo(mensal, modelos, estacao, PASTA_SAIDA)\n",
    "\n",
    "    # 2) violin ensemble x observado\n",
    "    plot_violin_mensal_ensemble(mensal, modelos, estacao, PASTA_SAIDA)\n",
    "\n",
    "    # 3 e 4) FDC por modelo\n",
    "    plot_fdc_por_modelo(df, modelos, estacao, PASTA_SAIDA,\n",
    "                        clip_percentis=None, sufixo=\"_completa\")\n",
    "\n",
    "    plot_fdc_por_modelo(df, modelos, estacao, PASTA_SAIDA,\n",
    "                        clip_percentis=(0.01, 0.99), sufixo=\"_p1_p99_removidos\")\n",
    "\n",
    "    # 5) FDC ensemble\n",
    "    plot_fdc_ensemble(df, modelos, estacao, PASTA_SAIDA,\n",
    "                      clip_percentis=None, sufixo=\"_completa\")\n",
    "    plot_fdc_ensemble(df, modelos, estacao, PASTA_SAIDA,\n",
    "                      clip_percentis=(0.01, 0.99), sufixo=\"_p1_p99_removidos\")\n",
    "\n",
    "    print(f\"‚úî Figuras geradas para {estacao} em {PASTA_SAIDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c7975-36d5-4627-8739-cf049c448f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
