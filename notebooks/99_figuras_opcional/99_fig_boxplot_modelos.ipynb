{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32751e7",
   "metadata": {},
   "source": [
    "# Boxplot Modelos\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a célula **CONFIGURAÇÕES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURAÇÕES (edite se necessário)\n",
    "# A pasta raiz do projeto (por padrão, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a38e19-e849-4a07-b42e-e171954ae6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Cálculo de ΔQ/Q (%) por modelo climático e por minibacia (robusto a extremos)\n",
    "================================================================================\n",
    "\n",
    "O que este script faz\n",
    "---------------------\n",
    "1) Lê o arquivo histórico (1980–2023) e calcula, por minibacia:\n",
    "   - Série anual: MÉDIA anual (diário -> anual por mean)\n",
    "   - Nível do período base (Q_pres): MEDIANA das médias anuais (robusta a anos extremos)\n",
    "\n",
    "2) Para cada arquivo de modelo (2015–2100), e para cada horizonte:\n",
    "   - Série anual: MÉDIA anual (diário -> anual por mean)\n",
    "   - Nível do horizonte (Q_fut): MEDIANA das médias anuais no horizonte\n",
    "   - ΔQ/Q (%) = (Q_fut - Q_pres) / Q_pres * 100\n",
    "\n",
    "3) Salva um CSV \"longo\" com:\n",
    "   ['modelo', 'horizonte', 'minibacia', 'delta_q_q']\n",
    "\n",
    "4) Gera boxplots por horizonte:\n",
    "   - Cada boxplot mostra a distribuição espacial (entre minibacias) de ΔQ/Q\n",
    "     para cada modelo climático.\n",
    "\n",
    "POR QUE \"MÉDIA ANUAL\" + \"MEDIANA ENTRE ANOS\"?\n",
    "---------------------------------------------\n",
    "- MÉDIA ANUAL preserva o conceito hidrológico de vazão média anual.\n",
    "- MEDIANA entre anos reduz a influência de anos muito extremos e fornece\n",
    "  um valor típico do período (robusto), ideal para comparações entre períodos.\n",
    "\n",
    "Observação importante\n",
    "---------------------\n",
    "Este script NÃO executa testes de tendência (MK/Sen). Ele apenas calcula ΔQ/Q\n",
    "para boxplots e para uso posterior em mapas/estatísticas.\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# CONFIGURAÇÕES\n",
    "# ---------------------------------------------------\n",
    "# pasta raiz dos resultados\n",
    "root_dir = Path(r\"E:\\RESULTADOS\\SSP5_85\")\n",
    "\n",
    "# pasta onde estão os arquivos de projeções futuras (modelos)\n",
    "base_dir = root_dir / \"Qtudo_Fut_Cenario 1\"\n",
    "\n",
    "# arquivo histórico/base (1980–2023)\n",
    "# ATENÇÃO: mantenha o nome correto do seu arquivo base\n",
    "obs_file = root_dir / \"Qtudo_Pres\" / \"Observado.txt\"\n",
    "\n",
    "# pasta de saída (CSV + figuras)\n",
    "output_root = root_dir / \"BoxPlot_Modelos\"\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# padrão para os arquivos de modelos\n",
    "model_pattern = \"*-ssp585.txt\"  # ajuste se necessário (ex.: \"*-ssp245.txt\")\n",
    "\n",
    "# período de referência (histórico)\n",
    "ref_start = \"1980-01-01\"\n",
    "ref_end   = \"2023-12-31\"\n",
    "\n",
    "# horizontes futuros\n",
    "horizons = {\n",
    "    \"2015-2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"2041-2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"2071-2100\": (\"2071-01-01\", \"2100-12-31\"),\n",
    "    \"2015-2100\": (\"2015-01-01\", \"2100-12-31\"),\n",
    "}\n",
    "\n",
    "# datas completas esperadas nos arquivos\n",
    "OBS_START, OBS_END = \"1980-01-01\", \"2023-12-31\"\n",
    "FUT_START, FUT_END = \"2015-01-01\", \"2100-12-31\"\n",
    "\n",
    "# proteção contra divisão por zero\n",
    "EPS = 1e-12\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# FUNÇÕES AUXILIARES\n",
    "# ---------------------------------------------------\n",
    "def limpar_nome_modelo(stem: str) -> str:\n",
    "    \"\"\"\n",
    "    Padroniza o nome do modelo para ficar limpo e consistente no CSV e nos gráficos.\n",
    "    Ajuste se você tiver outros padrões.\n",
    "    \"\"\"\n",
    "    s = stem\n",
    "    s = s.replace(\"-pr-\", \"_\").replace(\"-pr\", \"\").replace(\"pr_\", \"\")\n",
    "    return s\n",
    "\n",
    "def ler_serie_diaria_txt(\n",
    "    path: Path,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    n_cols_expected: int | None = None,\n",
    "    ajustar_1_linha_extra: str = \"fim\",  # \"fim\" (padrão) ou \"inicio\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lê arquivo .txt sem cabeçalho, separado por espaços, e cria índice diário [start, end].\n",
    "\n",
    "    Robustez:\n",
    "    - remove linhas totalmente vazias (ex.: newline extra)\n",
    "    - se houver exatamente 1 linha extra, corta do fim (padrão) ou do início\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, engine=\"python\")\n",
    "\n",
    "    # 1) remove linhas totalmente vazias (muito comum no fim)\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    # 2) checa colunas\n",
    "    if n_cols_expected is not None and df.shape[1] != n_cols_expected:\n",
    "        raise ValueError(\n",
    "            f\"{path.name}: número de colunas ({df.shape[1]}) difere do esperado ({n_cols_expected}).\"\n",
    "        )\n",
    "\n",
    "    # 3) índice esperado\n",
    "    idx = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    n_esp = len(idx)\n",
    "    n_obs = len(df)\n",
    "\n",
    "    # 4) ajusta se tiver 1 linha extra\n",
    "    if n_obs != n_esp:\n",
    "        if n_obs == n_esp + 1:\n",
    "            if ajustar_1_linha_extra.lower() == \"inicio\":\n",
    "                df = df.iloc[1:].reset_index(drop=True)   # corta primeira linha\n",
    "            else:\n",
    "                df = df.iloc[:-1].reset_index(drop=True)  # corta última linha (padrão)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"{path.name}: número de linhas ({n_obs}) não bate com período {start} a {end} \"\n",
    "                f\"({n_esp} dias).\"\n",
    "            )\n",
    "\n",
    "    df.index = idx\n",
    "    return df\n",
    "\n",
    "\n",
    "def diario_para_anual_media(df_diario: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    (MÉDIA) Diário -> Anual (média anual)\n",
    "    Retorna DataFrame anual (uma linha por ano).\n",
    "    \"\"\"\n",
    "    return df_diario.resample(\"YS\").mean()\n",
    "\n",
    "def nivel_periodo_por_mediana_anual(df_anual: pd.DataFrame, start: str, end: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    (MEDIANA) Nível do período:\n",
    "    - Filtra anos do intervalo [start, end]\n",
    "    - Calcula MEDIANA das médias anuais (por coluna/minibacia)\n",
    "    \"\"\"\n",
    "    y0 = pd.to_datetime(start).year\n",
    "    y1 = pd.to_datetime(end).year\n",
    "    sub = df_anual[(df_anual.index.year >= y0) & (df_anual.index.year <= y1)]\n",
    "    return sub.median(axis=0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) LER DADOS HISTÓRICOS (BASE) E CALCULAR Q_pres ROBUSTO\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n[ETAPA 1] Lendo histórico/base e calculando Q_pres (robusto)...\")\n",
    "\n",
    "# Lê diário base (1980–2023)\n",
    "obs = ler_serie_diaria_txt(obs_file, OBS_START, OBS_END)\n",
    "\n",
    "# Nomear colunas como mb_1..mb_N\n",
    "n_minibacias = obs.shape[1]\n",
    "obs.columns = [f\"mb_{i+1}\" for i in range(n_minibacias)]\n",
    "\n",
    "# (MÉDIA) Converte diário -> série anual (média anual)\n",
    "obs_anual = diario_para_anual_media(obs)\n",
    "\n",
    "# (MEDIANA) Calcula Q_pres como mediana das médias anuais no período base\n",
    "Q_pres = nivel_periodo_por_mediana_anual(obs_anual, ref_start, ref_end)\n",
    "\n",
    "# Proteção contra Q_pres = 0\n",
    "Q_pres_safe = Q_pres.copy()\n",
    "Q_pres_safe[np.abs(Q_pres_safe) < EPS] = np.nan\n",
    "\n",
    "print(f\"  Minibacias: {n_minibacias}\")\n",
    "print(f\"  Q_pres calculado como: MEDIANA das MÉDIAS anuais (1980–2023)\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) FUNÇÃO PARA PROCESSAR 1 MODELO E CALCULAR ΔQ/Q\n",
    "# ---------------------------------------------------\n",
    "def calcula_delta_q_q_modelo(model_file: Path, Q_pres_safe: pd.Series, horizons: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Para um arquivo de modelo (2015–2100):\n",
    "      - Lê série diária\n",
    "      - (MÉDIA) diário -> anual (média anual)\n",
    "      - (MEDIANA) nível por horizonte = mediana das médias anuais do horizonte\n",
    "      - ΔQ/Q (%) por minibacia e horizonte\n",
    "    Retorna DataFrame em formato longo.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ler_serie_diaria_txt(model_file, FUT_START, FUT_END, n_cols_expected=len(Q_pres_safe))\n",
    "    df.columns = Q_pres_safe.index  # mesmas minibacias do base\n",
    "\n",
    "    # (MÉDIA) diário -> anual\n",
    "    df_anual = diario_para_anual_media(df)\n",
    "\n",
    "    model_name = limpar_nome_modelo(model_file.stem)\n",
    "    registros = []\n",
    "\n",
    "    for horiz_name, (h_start, h_end) in horizons.items():\n",
    "        # (MEDIANA) nível do horizonte = mediana das médias anuais no horizonte\n",
    "        Q_fut = nivel_periodo_por_mediana_anual(df_anual, h_start, h_end)\n",
    "\n",
    "        # ΔQ/Q (%) (robusto, porque Q_fut e Q_pres foram calculados por mediana anual)\n",
    "        delta = (Q_fut - Q_pres_safe) / Q_pres_safe * 100.0\n",
    "\n",
    "        tmp = pd.DataFrame({\n",
    "            \"modelo\": model_name,\n",
    "            \"horizonte\": horiz_name,\n",
    "            \"minibacia\": delta.index,\n",
    "            \"delta_q_q\": delta.values\n",
    "        })\n",
    "        registros.append(tmp)\n",
    "\n",
    "    return pd.concat(registros, ignore_index=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) CALCULAR ΔQ/Q PARA TODOS OS MODELOS\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n[ETAPA 2] Processando modelos e calculando ΔQ/Q...\")\n",
    "\n",
    "all_results = []\n",
    "model_files = sorted(base_dir.glob(model_pattern))\n",
    "\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(f\"Nenhum arquivo encontrado em: {base_dir} com padrão {model_pattern}\")\n",
    "\n",
    "for model_file in model_files:\n",
    "    if model_file.name.lower() == \"observado.txt\":\n",
    "        continue\n",
    "    print(f\"  → {model_file.name}\")\n",
    "    res_model = calcula_delta_q_q_modelo(model_file, Q_pres_safe, horizons)\n",
    "    all_results.append(res_model)\n",
    "\n",
    "delta_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Remove linhas com NaN (caso Q_pres tenha sido 0 em alguma minibacia)\n",
    "delta_results = delta_results.dropna(subset=[\"delta_q_q\"]).copy()\n",
    "\n",
    "# Salvar CSV\n",
    "csv_out = output_root / \"delta_q_q_por_modelo_minibacia_ssp245.csv\"\n",
    "delta_results.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n  CSV salvo: {csv_out}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) BOXPLOTS POR HORIZONTE\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n[ETAPA 3] Gerando boxplots por horizonte...\")\n",
    "\n",
    "# Garantir ordem estável dos modelos no eixo X\n",
    "modelos = sorted(delta_results[\"modelo\"].unique())\n",
    "\n",
    "for horiz_name in horizons.keys():\n",
    "    df_h = delta_results[delta_results[\"horizonte\"] == horiz_name]\n",
    "\n",
    "    # lista de vetores (um por modelo)\n",
    "    data_box = [df_h.loc[df_h[\"modelo\"] == m, \"delta_q_q\"].values for m in modelos]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), dpi=300)\n",
    "    ax.boxplot(data_box, labels=modelos, showfliers=False)\n",
    "\n",
    "    ax.axhline(0, linestyle=\"--\", linewidth=1, color=\"grey\")\n",
    "    ax.set_title(f\"ΔQ/Q por modelo – horizonte {horiz_name}\\n\"\n",
    "                 )\n",
    "    ax.set_xlabel(\"Modelo climático\")\n",
    "    ax.set_ylabel(\"ΔQ/Q (%) – distribuição entre minibacias\")\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_out = output_root / f\"boxplot_delta_q_q_modelos_mediana_anual_{horiz_name}.png\"\n",
    "    plt.savefig(fig_out, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"  Figura salva: {fig_out.name}\")\n",
    "\n",
    "print(f\"\\nConcluído. CSV e figuras salvos em: {output_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b7553-3180-476c-a863-4e68b61c8f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script: gera_shapefiles_deltaQQ_e_mapas_3paineis.py\n",
    "\n",
    "Descrição geral\n",
    "---------------\n",
    "Este script faz duas etapas principais, em sequência:\n",
    "\n",
    "1) Geração dos shapefiles temáticos de ΔQ/Q (%)\n",
    "   - Lê um CSV com resultados de ΔQ/Q por minibacia, modelo e horizonte.\n",
    "   - Cruza esses dados com o shapefile das minibacias (minis_mgb.shp).\n",
    "   - Para cada combinação (modelo, horizonte), grava um shapefile do tipo:\n",
    "       minis_deltaQQ_{modelo_limpo}_{horiz_limpo}.shp\n",
    "     onde:\n",
    "       - modelo_limpo  = nome do modelo com \"-\" e espaços trocados por \"_\"\n",
    "       - horiz_limpo   = horizonte com \"-\" removido e \"_\" no lugar (ex.: 2015_2040)\n",
    "\n",
    "2) Geração de mapas 3×1 por modelo (estilo figura final da dissertação)\n",
    "   - Lê os shapefiles gerados na etapa (1).\n",
    "   - Calcula uma escala de cores global (vmin, vmax) usando todos os valores de ΔQ/Q (%)\n",
    "     de todos os modelos e horizontes (1º e 99º percentil, para reduzir outliers extremos).\n",
    "   - Para cada modelo, gera uma figura com 3 painéis (um por horizonte futuro),\n",
    "     utilizando a mesma escala de cores em todos.\n",
    "   - Sobrepõe:\n",
    "       • contorno das sub-bacias (Subbacias.shp)\n",
    "       • pontos das cidades de Curitiba e União da Vitória\n",
    "       • rótulos das cidades com halo (texto branco com borda preta)\n",
    "   - Salva as figuras no padrão:\n",
    "       MAPA_3PAINEIS_FIXO_{modelo}.png\n",
    "\n",
    "Uso esperado na pipeline\n",
    "------------------------\n",
    "1. Ajustar os CAMINHOS na seção de CONFIGURAÇÕES abaixo.\n",
    "2. Executar o script.\n",
    "3. Usar os shapefiles gerados (shapes_deltaQQ) para outras análises, se necessário.\n",
    "4. Usar as figuras (figuras_3paineis_FINAL) diretamente na dissertação / artigos.\n",
    "\"\"\"\n",
    "\n",
    "# ===================================================\n",
    "# IMPORTAÇÕES\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patheffects\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ===================================================\n",
    "# 0. CONFIGURAÇÕES – AJUSTAR AQUI\n",
    "# ===================================================\n",
    "\n",
    "# Pasta \"principal\" do cenário (onde está o CSV de ΔQ/Q e onde você quer guardar os outputs)\n",
    "base_dir = Path(r\"E:\\RESULTADOS\\SSP5_85\")  # AJUSTE AQUI SE PRECISAR\n",
    "\n",
    "# CSV gerado pelo script anterior com ΔQ/Q por minibacia, modelo e horizonte\n",
    "delta_csv = base_dir / \"BoxPlot_Modelos\\delta_q_q_por_modelo_minibacia_ssp585.csv\"\n",
    "\n",
    "# Shapefile das minibacias MGB\n",
    "shp_minis = Path(r\"E:\\IGUAÇU_OTTO\\6_Calibração\\minis_mgb.shp\")\n",
    "ID_FIELD  = \"ID_Mini\"  # campo de ID da minibacia no shapefile\n",
    "\n",
    "# Pasta onde serão salvos os shapefiles temáticos (saída da ETAPA 1)\n",
    "shapes_dir = base_dir / \"shapes_deltaQQ_Mediana\"\n",
    "shapes_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Pasta onde serão salvos os mapas 3×1 finais (saída da ETAPA 2)\n",
    "fig_out_dir = base_dir / \"Mapas_3paineis_Mediana\"\n",
    "fig_out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Shapefile das sub-bacias (para contorno)\n",
    "shp_sub = Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\")\n",
    "\n",
    "# Shapefile das cidades (contendo Curitiba e União da Vitória)\n",
    "shp_cidades = Path(\n",
    "    r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\"\n",
    ")\n",
    "\n",
    "# Campo com o nome da cidade no shapefile de cidades\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# ===================================================\n",
    "# 1. ETAPA 1 – GERAR SHAPEFILES TEMÁTICOS A PARTIR DO CSV\n",
    "# ===================================================\n",
    "\n",
    "print(\"\\n=== ETAPA 1: Gerando shapefiles de ΔQ/Q por modelo e horizonte ===\\n\")\n",
    "\n",
    "# 1.1 Ler CSV com ΔQ/Q\n",
    "delta_results = pd.read_csv(delta_csv)\n",
    "\n",
    "# Esperado: colunas ['modelo', 'horizonte', 'minibacia', 'delta_q_q']\n",
    "# Transformar \"mb_1\", \"mb_2\", ... → 1, 2, ...\n",
    "delta_results[\"mini\"] = (\n",
    "    delta_results[\"minibacia\"]\n",
    "    .str.replace(\"mb_\", \"\", regex=False)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# 1.2 Ler shapefile das minibacias e garantir tipo inteiro no campo de ID\n",
    "minis_gdf = gpd.read_file(shp_minis)\n",
    "minis_gdf[ID_FIELD] = minis_gdf[ID_FIELD].astype(int)\n",
    "\n",
    "# 1.3 Listar modelos e horizontes disponíveis no CSV\n",
    "# Remover \"-pr-\" dos nomes antes de qualquer processamento\n",
    "delta_results[\"modelo\"] = (\n",
    "    delta_results[\"modelo\"]\n",
    "    .str.replace(\"-pr-\", \"_\", regex=False)     # troca -pr- por _\n",
    "    .str.replace(\"-pr\",  \"\", regex=False)      # remove -pr se estiver no final\n",
    "    .str.replace(\"pr_\",  \"\", regex=False)      # remove pr_ se tiver vindo de outra forma\n",
    ")\n",
    "modelos = sorted(delta_results[\"modelo\"].unique())\n",
    "horizontes = sorted(delta_results[\"horizonte\"].unique())\n",
    "\n",
    "print(f\"Modelos encontrados no CSV ({len(modelos)}):\")\n",
    "for m in modelos:\n",
    "    print(\"  →\", m)\n",
    "\n",
    "print(\"\\nHorizontes encontrados no CSV:\")\n",
    "for h in horizontes:\n",
    "    print(\"  →\", h)\n",
    "\n",
    "# 1.4 Loop: para cada combinação (modelo, horizonte), gerar shapefile\n",
    "for modelo in modelos:\n",
    "    for horiz in horizontes:\n",
    "        df_mh = delta_results[\n",
    "            (delta_results[\"modelo\"] == modelo) &\n",
    "            (delta_results[\"horizonte\"] == horiz)\n",
    "        ][[\"mini\", \"delta_q_q\"]].copy()\n",
    "\n",
    "        # Merge com as minibacias\n",
    "        gdf_mh = minis_gdf.merge(df_mh, left_on=ID_FIELD, right_on=\"mini\", how=\"left\")\n",
    "\n",
    "        # Limpar nomes para usar no arquivo\n",
    "        modelo_limpo = modelo.replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "        horiz_limpo  = horiz.replace(\" \", \"\").replace(\"-\", \"_\")  # ex.: \"2015-2040\" → \"2015_2040\"\n",
    "\n",
    "        shp_out = shapes_dir / f\"minis_deltaQQ_{modelo_limpo}_{horiz_limpo}.shp\"\n",
    "        gdf_mh.to_file(shp_out)\n",
    "\n",
    "        print(f\"Shapefile salvo: {shp_out.name}\")\n",
    "\n",
    "print(\"\\n✔ ETAPA 1 concluída: shapefiles temáticos gerados em:\", shapes_dir)\n",
    "\n",
    "# ===================================================\n",
    "# 2. ETAPA 2 – GERAR MAPAS 3×1 (ESTILO CÓDIGO 3)\n",
    "# ===================================================\n",
    "\n",
    "print(\"\\n=== ETAPA 2: Gerando mapas 3×1 por modelo (com sub-bacias e cidades) ===\\n\")\n",
    "\n",
    "# 2.1 Definir rótulos e códigos dos horizontes (fixos)\n",
    "horiz_labels = [\"2015-2040\", \"2041-2070\", \"2071-2100\"]\n",
    "horiz_codes  = [\"2015_2040\", \"2041_2070\", \"2071_2100\"]\n",
    "\n",
    "print(\"Horizontes usados na ETAPA 2:\")\n",
    "for label, code in zip(horiz_labels, horiz_codes):\n",
    "    print(f\"  {label}  →  {code}\")\n",
    "\n",
    "# 2.2 Montar um dicionário {modelo_base: {code: caminho_shp}}\n",
    "shp_map = {}  # ex.: {\"ACCESS_CM2_ssp245\": {\"2015_2040\": Path(...), ...}}\n",
    "\n",
    "for f in shapes_dir.glob(\"minis_deltaQQ_*.shp\"):\n",
    "    stem = f.stem  # ex.: \"minis_deltaQQ_ACCESS_CM2_ssp245_2015_2040\"\n",
    "    prefix = \"minis_deltaQQ_\"\n",
    "    if not stem.startswith(prefix):\n",
    "        print(f\"[AVISO] Nome inesperado (ignorado): {f.name}\")\n",
    "        continue\n",
    "\n",
    "    resto = stem[len(prefix):]  # tira \"minis_deltaQQ_\"\n",
    "\n",
    "    # descobrir qual código de horizonte está no final\n",
    "    found_code = None\n",
    "    for code in horiz_codes:\n",
    "        suffix = \"_\" + code\n",
    "        if resto.endswith(suffix):\n",
    "            found_code = code\n",
    "            base_model = resto[:-len(suffix)]  # tudo antes de \"_2015_2040\", por ex.\n",
    "            break\n",
    "\n",
    "    if found_code is None:\n",
    "        print(f\"[AVISO] Não reconheci horizonte no nome (ignorado): {f.name}\")\n",
    "        continue\n",
    "\n",
    "    # registra no dicionário\n",
    "    if base_model not in shp_map:\n",
    "        shp_map[base_model] = {}\n",
    "    shp_map[base_model][found_code] = f\n",
    "\n",
    "# lista de modelos base\n",
    "modelos_para_mapear = sorted(shp_map.keys())\n",
    "\n",
    "print(f\"\\nModelos base detectados ({len(modelos_para_mapear)}):\")\n",
    "for m in modelos_para_mapear:\n",
    "    cods_disp = \", \".join(sorted(shp_map[m].keys()))\n",
    "    print(f\"  → {m}  (horizontes: {cods_disp})\")\n",
    "\n",
    "# 2.3 Definir escala global (vmin, vmax) com base em TODOS os shapefiles\n",
    "valores = []\n",
    "for base_model, dict_horiz in shp_map.items():\n",
    "    for code, shp_path in dict_horiz.items():\n",
    "        df_tmp = gpd.read_file(shp_path)\n",
    "        if \"delta_q_q\" in df_tmp.columns:\n",
    "            valores.extend(df_tmp[\"delta_q_q\"].dropna().tolist())\n",
    "        else:\n",
    "            print(f\"[AVISO] 'delta_q_q' não encontrada em {shp_path.name}\")\n",
    "\n",
    "if not valores:\n",
    "    raise RuntimeError(\"Não foram encontrados valores de 'delta_q_q' nos shapefiles.\")\n",
    "\n",
    "val_min, val_max = min(valores), max(valores)\n",
    "print(f\"VALORES REAIS → min = {val_min:.1f}  max = {val_max:.1f}\")\n",
    "\n",
    "# usa percentis pra limpar extremos, mas deixa a escala SIMÉTRICA em torno de 0\n",
    "p1, p99 = np.percentile(valores, [1, 99])\n",
    "max_abs = max(abs(p1), abs(p99))\n",
    "vmin, vmax = -max_abs, max_abs\n",
    "\n",
    "print(f\"\\nESCALA DIVERGENTE SIMÉTRICA APLICADA → {vmin:.1f}  a  {vmax:.1f}\\n\")\n",
    "\n",
    "# normalização divergente centrada em 0\n",
    "divnorm = TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "\n",
    "# 2.4 Ler sub-bacias e cidades\n",
    "gdf_sub = gpd.read_file(shp_sub)\n",
    "gdf_cid = gpd.read_file(shp_cidades)\n",
    "\n",
    "print(\"CRS das CIDADES:\", gdf_cid.crs)\n",
    "print(\"Campos disponíveis nas CIDADES:\", list(gdf_cid.columns))\n",
    "\n",
    "# Filtro robusto por substring para Curitiba e União da Vitória\n",
    "mask_cur = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"curit\", case=False, na=False)\n",
    "mask_un  = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"uni[aã]o da vit\", case=False, na=False, regex=True)\n",
    "\n",
    "cidades_sel = gdf_cid[mask_cur | mask_un].copy()\n",
    "\n",
    "print(\"\\nCidades selecionadas para plotagem:\")\n",
    "print(cidades_sel[[CAMPO_NOME_CIDADE]].drop_duplicates())\n",
    "\n",
    "# 2.5 Gerar mapas 3×1 para cada modelo base\n",
    "for base_model in modelos_para_mapear:\n",
    "\n",
    "    # garante que o modelo base tenha os 3 horizontes\n",
    "    if not all(code in shp_map[base_model] for code in horiz_codes):\n",
    "        print(f\"[AVISO] Modelo {base_model} não possui todos os horizontes. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nGerando figura para o modelo → {base_model}\")\n",
    "\n",
    "    # ler shapefiles das minibacias para cada horizonte na ordem certa\n",
    "    gdfs = [gpd.read_file(shp_map[base_model][code]) for code in horiz_codes]\n",
    "\n",
    "    # usar o CRS do primeiro shapefile de minibacias como referência\n",
    "    crs_minis = gdfs[0].crs\n",
    "\n",
    "    # reprojetar sub-bacias e cidades para o mesmo CRS das minibacias\n",
    "    gdf_sub_proj = gdf_sub.to_crs(crs_minis)\n",
    "    cidades_proj = cidades_sel.to_crs(crs_minis) if not cidades_sel.empty else cidades_sel\n",
    "\n",
    "    xmin, ymin, xmax, ymax = gdfs[0].total_bounds\n",
    "    dx = (xmax - xmin) * 0.01  # deslocamento relativo em x\n",
    "    dy = (ymax - ymin) * 0.01  # deslocamento relativo em y\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.05])\n",
    "\n",
    "    axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "\n",
    "    for ax, gdf, label in zip(axes, gdfs, horiz_labels):\n",
    "\n",
    "        # Mapa base das minibacias com ΔQ/Q\n",
    "        gdf.plot(\n",
    "            column=\"delta_q_q\",\n",
    "            cmap=\"RdYlBu\",   # negativo = vermelho, positivo = azul\n",
    "            norm=divnorm,    # centraliza o 0 na cor neutra\n",
    "            ax=ax,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.08,\n",
    "        )\n",
    "\n",
    "        # Contorno das sub-bacias\n",
    "        gdf_sub_proj.boundary.plot(\n",
    "            ax=ax,\n",
    "            edgecolor=\"grey\",\n",
    "            linewidth=1.2,\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "        # Pontos das cidades (se houver)\n",
    "        if not cidades_proj.empty:\n",
    "            cidades_proj.plot(\n",
    "                ax=ax,\n",
    "                marker=\"^\",\n",
    "                color=\"black\",\n",
    "                markersize=40,\n",
    "                zorder=4,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "            # Rótulos das cidades com halo\n",
    "            for _, row in cidades_proj.iterrows():\n",
    "                x = row.geometry.x\n",
    "                y = row.geometry.y\n",
    "                nome = row[CAMPO_NOME_CIDADE]\n",
    "\n",
    "                txt = ax.text(\n",
    "                    x + dx,\n",
    "                    y + dy,\n",
    "                    nome,\n",
    "                    fontsize=9,\n",
    "                    color=\"white\",\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                    zorder=5,\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                    patheffects.Normal()\n",
    "                ])\n",
    "\n",
    "        ax.set_title(f\"Horizonte {label}\", fontsize=11)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # COLORBAR na coluna 4\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "    sm  = plt.cm.ScalarMappable(\n",
    "        cmap=\"RdYlBu\",\n",
    "        norm=divnorm\n",
    "    )\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ/Q (%)\", fontsize=11)\n",
    "\n",
    "    # Título geral\n",
    "    fig.suptitle(\n",
    "        f\"ΔQ/Q (%) – Modelo {base_model}\",\n",
    "        fontsize=14,\n",
    "        weight=\"bold\",\n",
    "        y=0.97\n",
    "    )\n",
    "\n",
    "    # Ajuste fino de margens\n",
    "    fig.subplots_adjust(left=0.02, right=0.96, top=0.90, bottom=0.03, wspace=0.02)\n",
    "\n",
    "    # Salvar figura\n",
    "    fig_path = fig_out_dir / f\"MAPA_{base_model}.png\"\n",
    "    fig.savefig(fig_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Figura salva: {fig_path.name}\")\n",
    "\n",
    "print(\"\\n✨ ETAPA 2 FINALIZADA – Mapas 3×1 gerados com sucesso.\")\n",
    "print(\"  → Figuras 3×1:\", fig_out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1f33f-0501-45ee-8a09-c62f9a7c882c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================\n",
    "Cálculo de ΔQ/Q (%) a partir do ENSEMBLE (média multimodelo) por minibacia\n",
    "===============================================================================\n",
    "\n",
    "Objetivo\n",
    "--------\n",
    "Calcular a variação relativa ΔQ/Q (%) entre um período base (1980–2023) e\n",
    "horizontes futuros (2015–2040, 2041–2070, 2071–2100), usando o ENSEMBLE\n",
    "multimodelo como série representativa do futuro.\n",
    "\n",
    "Metodologia (coerente com \"vazão média anual\" + robustez a extremos)\n",
    "--------------------------------------------------------------------\n",
    "Este script segue a mesma lógica adotada na dissertação para reduzir a influência\n",
    "de anos extremos, sem distorcer o conceito de \"vazão média anual\":\n",
    "\n",
    "1) Série anual (TENDÊNCIA/representação física)\n",
    "   - (MÉDIA) Diário -> ANUAL por mean:\n",
    "       Q_ano = média diária dentro do ano\n",
    "\n",
    "2) Nível típico do período (ROBUSTEZ a extremos)\n",
    "   - (MEDIANA) Para cada período (base/horizonte), define-se o \"nível\" como:\n",
    "       Q_periodo = mediana dos valores anuais (médias anuais) do período\n",
    "\n",
    "3) Ensemble\n",
    "   - Para cada modelo: gera série ANUAL (média anual).\n",
    "   - (MÉDIA) Ensemble anual = média aritmética das séries anuais dos modelos.\n",
    "   - Para cada horizonte: Q_fut_ens = mediana dos valores anuais do ensemble no horizonte.\n",
    "\n",
    "4) ΔQ/Q (%)\n",
    "   - ΔQ/Q = (Q_fut_ens - Q_pres) / Q_pres × 100\n",
    "\n",
    "Por que NÃO usar \"mediana diária\" diretamente?\n",
    "----------------------------------------------\n",
    "A mediana diária ao longo de décadas representa um \"dia típico\" do período,\n",
    "e não uma vazão média anual. Para manter coerência hidrológica e robustez,\n",
    "usa-se:\n",
    "- média anual para construir a série\n",
    "- mediana entre anos para resumir o período\n",
    "\n",
    "Entradas esperadas\n",
    "------------------\n",
    "- Observado/base (`Observado.txt`):\n",
    "  - txt separado por espaço, sem cabeçalho\n",
    "  - linhas diárias 1980-01-01 a 2023-12-31\n",
    "  - colunas = minibacias (1..N) na mesma ordem dos modelos\n",
    "\n",
    "- Modelos (`*-ssp245.txt`, etc.):\n",
    "  - txt separado por espaço, sem cabeçalho\n",
    "  - linhas diárias 2015-01-01 a 2100-12-31\n",
    "  - colunas = minibacias (mesma ordem do observado)\n",
    "\n",
    "Saídas\n",
    "------\n",
    "1) CSV resumo geral:\n",
    "   - delta_q_q_ensemble_por_minibacia.csv\n",
    "     colunas: ['minibacia', 'horizonte', 'Q_pres', 'Q_fut_ens', 'delta_q_q_ensemble']\n",
    "\n",
    "2) CSVs individuais por minibacia:\n",
    "   - Ensemble_Modelos/Ensemble_Minibacias/\n",
    "     ex.: ensemble_delta_q_q_mb_1.csv, ...\n",
    "\n",
    "Dependências\n",
    "------------\n",
    "- pandas\n",
    "- numpy\n",
    "- pathlib\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# CONFIGURAÇÕES\n",
    "# ---------------------------------------------------\n",
    "root_dir = Path(r\"E:\\RESULTADOS_AB2\\SSP2-45\")\n",
    "base_dir = root_dir / \"QTudo_Fut_Cenario 2\"\n",
    "obs_file = root_dir / \"Qtudo_Pres\" / \"Observado.txt\"\n",
    "\n",
    "model_pattern = \"*-ssp245.txt\"\n",
    "\n",
    "# Período base\n",
    "ref_start = \"1980-01-01\"\n",
    "ref_end   = \"2023-12-31\"\n",
    "\n",
    "# Horizontes futuros\n",
    "horizons = {\n",
    "    \"2015-2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"2041-2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"2071-2100\": (\"2071-01-01\", \"2100-12-31\"),\n",
    "    \"2015-2100\": (\"2015-01-01\", \"2100-12-31\"),\n",
    "}\n",
    "\n",
    "# Datas completas esperadas\n",
    "OBS_START, OBS_END = \"1980-01-01\", \"2023-12-31\"\n",
    "FUT_START, FUT_END = \"2015-01-01\", \"2100-12-31\"\n",
    "\n",
    "# Saídas\n",
    "output_root = root_dir / \"Ensemble_Modelos\"\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_out_resumo = output_root / \"delta_q_q_ensemble_por_minibacia.csv\"\n",
    "\n",
    "out_minibacias_dir = output_root / \"Ensemble_Minibacias\"\n",
    "out_minibacias_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Proteção contra divisão por zero\n",
    "EPS = 1e-12\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# FUNÇÕES\n",
    "# ---------------------------------------------------\n",
    "def ler_txt_diario(\n",
    "    path: Path,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    n_cols_expected: int | None = None,\n",
    "    ajustar_1_linha_extra: str = \"fim\",  # \"fim\" (padrão) ou \"inicio\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lê TXT diário (espaço, sem header) e atribui índice diário.\n",
    "\n",
    "    Robustez:\n",
    "    - remove linhas totalmente vazias (ex.: newline/linha em branco no final)\n",
    "    - se houver exatamente 1 linha extra, corta do fim (padrão) ou do início\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, engine=\"python\")\n",
    "\n",
    "    # 1) remove linhas totalmente vazias\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    # 2) checa colunas\n",
    "    if n_cols_expected is not None and df.shape[1] != n_cols_expected:\n",
    "        raise ValueError(f\"{path.name}: colunas {df.shape[1]} != esperado {n_cols_expected}\")\n",
    "\n",
    "    # 3) índice esperado\n",
    "    idx = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    n_esp = len(idx)\n",
    "    n_obs = len(df)\n",
    "\n",
    "    # 4) ajusta diferença de 1 linha (caso típico)\n",
    "    if n_obs != n_esp:\n",
    "        if n_obs == n_esp + 1:\n",
    "            if ajustar_1_linha_extra.lower() == \"inicio\":\n",
    "                df = df.iloc[1:].reset_index(drop=True)   # corta 1ª linha\n",
    "            else:\n",
    "                df = df.iloc[:-1].reset_index(drop=True)  # corta última linha (padrão)\n",
    "        else:\n",
    "            raise ValueError(f\"{path.name}: linhas {n_obs} != dias {n_esp} ({start} a {end})\")\n",
    "\n",
    "    df.index = idx\n",
    "    return df\n",
    "\n",
    "\n",
    "def diario_para_anual_media(df_diario: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"(MÉDIA) diário -> anual (média anual).\"\"\"\n",
    "    return df_diario.resample(\"YS\").mean()\n",
    "\n",
    "def nivel_periodo_mediana_anual(df_anual: pd.DataFrame, start: str, end: str) -> pd.Series:\n",
    "    \"\"\"(MEDIANA) nível do período = mediana das médias anuais dentro do período.\"\"\"\n",
    "    y0 = pd.to_datetime(start).year\n",
    "    y1 = pd.to_datetime(end).year\n",
    "    sub = df_anual[(df_anual.index.year >= y0) & (df_anual.index.year <= y1)]\n",
    "    return sub.median(axis=0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ETAPA 1: LER BASE E CALCULAR Q_pres (ROBUSTO)\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n=== ETAPA 1: Lendo base e calculando Q_pres (mediana das médias anuais) ===\")\n",
    "\n",
    "obs = ler_txt_diario(obs_file, OBS_START, OBS_END)\n",
    "\n",
    "n_minibacias = obs.shape[1]\n",
    "obs.columns = [f\"mb_{i+1}\" for i in range(n_minibacias)]\n",
    "\n",
    "# (MÉDIA) diário -> anual\n",
    "obs_anual = diario_para_anual_media(obs)\n",
    "\n",
    "# (MEDIANA) nível do período base\n",
    "Q_pres = nivel_periodo_mediana_anual(obs_anual, ref_start, ref_end)\n",
    "\n",
    "# Proteção contra Q_pres ~ 0\n",
    "Q_pres_safe = Q_pres.copy()\n",
    "Q_pres_safe[np.abs(Q_pres_safe) < EPS] = np.nan\n",
    "\n",
    "print(f\"Minibacias detectadas: {len(Q_pres_safe)}\")\n",
    "print(\"Exemplo Q_pres (5 primeiras):\")\n",
    "print(Q_pres_safe.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ETAPA 2: LER MODELOS E CONSTRUIR ENSEMBLE ANUAL\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n=== ETAPA 2: Lendo modelos e construindo ENSEMBLE ANUAL (média entre modelos) ===\")\n",
    "\n",
    "model_files = sorted([f for f in base_dir.glob(model_pattern) if f.name.lower() != \"observado.txt\"])\n",
    "if not model_files:\n",
    "    raise RuntimeError(f\"Nenhum modelo encontrado em {base_dir} com padrão {model_pattern}\")\n",
    "\n",
    "print(f\"Modelos encontrados: {len(model_files)}\")\n",
    "for mf in model_files:\n",
    "    print(\"  →\", mf.name)\n",
    "\n",
    "# Acumulador do ensemble anual\n",
    "ensemble_anual_soma = None\n",
    "n_models = 0\n",
    "\n",
    "# Eixo anual do futuro (para garantir alinhamento)\n",
    "anos_fut = pd.date_range(start=FUT_START, end=FUT_END, freq=\"YS\")\n",
    "\n",
    "for i, model_file in enumerate(model_files, start=1):\n",
    "    print(f\"\\nLendo modelo {i}/{len(model_files)}: {model_file.name}\")\n",
    "\n",
    "    df = ler_txt_diario(model_file, FUT_START, FUT_END, n_cols_expected=len(Q_pres_safe))\n",
    "    df.columns = Q_pres_safe.index\n",
    "\n",
    "    # (MÉDIA) diário -> anual\n",
    "    df_anual = diario_para_anual_media(df).reindex(anos_fut)\n",
    "\n",
    "    if df_anual.isna().any().any():\n",
    "        raise ValueError(f\"{model_file.name}: NaNs após reindex anual. Verifique integridade temporal.\")\n",
    "\n",
    "    if ensemble_anual_soma is None:\n",
    "        ensemble_anual_soma = df_anual.astype(np.float64).copy()\n",
    "    else:\n",
    "        ensemble_anual_soma += df_anual.astype(np.float64)\n",
    "\n",
    "    n_models += 1\n",
    "\n",
    "# (MÉDIA) ensemble anual = média entre modelos\n",
    "ensemble_anual = ensemble_anual_soma / float(n_models)\n",
    "\n",
    "print(f\"\\nEnsemble anual calculado com {n_models} modelos.\")\n",
    "print(\"Dimensões:\", ensemble_anual.shape)\n",
    "print(\"Período:\", ensemble_anual.index.min(), \"a\", ensemble_anual.index.max())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ETAPA 3: CALCULAR Q_fut_ens (ROBUSTO) E ΔQ/Q\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n=== ETAPA 3: Calculando Q_fut_ens (mediana anual) e ΔQ/Q (%) ===\")\n",
    "\n",
    "registros = []\n",
    "\n",
    "for horiz_name, (h_start, h_end) in horizons.items():\n",
    "    print(f\"  Horizonte {horiz_name}: {h_start} a {h_end}\")\n",
    "\n",
    "    # (MEDIANA) nível do horizonte no ensemble anual\n",
    "    Q_fut_ens = nivel_periodo_mediana_anual(ensemble_anual, h_start, h_end)\n",
    "\n",
    "    # ΔQ/Q (%) com proteção contra zero\n",
    "    delta = (Q_fut_ens - Q_pres_safe) / Q_pres_safe * 100.0\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        \"minibacia\": Q_pres_safe.index,\n",
    "        \"horizonte\": horiz_name,\n",
    "        \"Q_pres\": Q_pres_safe.values,\n",
    "        \"Q_fut_ens\": Q_fut_ens.values,\n",
    "        \"delta_q_q_ensemble\": delta.values\n",
    "    })\n",
    "\n",
    "    registros.append(tmp)\n",
    "\n",
    "df_result = pd.concat(registros, ignore_index=True)\n",
    "df_result = df_result.sort_values([\"minibacia\", \"horizonte\"])\n",
    "\n",
    "# Remover NaNs (caso Q_pres seja zero ou faltante)\n",
    "df_result = df_result.dropna(subset=[\"delta_q_q_ensemble\"]).copy()\n",
    "\n",
    "df_result.to_csv(csv_out_resumo, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nCSV resumo salvo em: {csv_out_resumo}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ETAPA 4: GERAR CSV POR MINIBACIA (OPCIONAL)\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n=== ETAPA 4: Gerando CSV individual por minibacia (opcional) ===\")\n",
    "\n",
    "minibacias = df_result[\"minibacia\"].unique()\n",
    "print(f\"Minibacias para exportar: {len(minibacias)}\")\n",
    "\n",
    "for mb in minibacias:\n",
    "    df_mb = df_result[df_result[\"minibacia\"] == mb].copy()\n",
    "    out_path = out_minibacias_dir / f\"ensemble_delta_q_q_{mb}.csv\"\n",
    "    df_mb.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n✅ Processo concluído com sucesso.\")\n",
    "print(f\"  → CSV resumo: {csv_out_resumo}\")\n",
    "print(f\"  → CSVs por minibacia em: {out_minibacias_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785bb42-ff91-463e-86ad-cc8f60afc11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script: gera_shapefile_e_mapas_ensemble_3e4paineis.py\n",
    "\n",
    "O que este script faz\n",
    "---------------------\n",
    "1) Gera shapefiles temáticos de ΔQ/Q do ensemble por horizonte, a partir do CSV:\n",
    "   delta_q_q_ensemble_por_minibacia.csv\n",
    "\n",
    "2) Gera dois produtos:\n",
    "   A) Mapa 3×1 (3 painéis): 2015–2040, 2041–2070, 2071–2100\n",
    "   B) Mapa 2×2 (4 painéis): Curto, Médio, Longo e Total (2015–2100)\n",
    "\n",
    "A escala é fixa em [-100, +100] com saturação indicada na colorbar:\n",
    "\"< -100\" e \"> 100\".\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# IMPORTAÇÕES\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patheffects\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from pathlib import Path\n",
    "\n",
    "# ===================================================\n",
    "# 0. CONFIGURAÇÕES – AJUSTAR AQUI\n",
    "# ===================================================\n",
    "\n",
    "# Pasta raiz do cenário\n",
    "base_dir = Path(r\"E:\\RESULTADOS_AB2\\SSP2-45\")\n",
    "\n",
    "# CSV com ΔQ/Q ensemble por minibacia e horizonte\n",
    "ensemble_csv = base_dir / r\"Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia.csv\"\n",
    "\n",
    "# Shapefile das minibacias MGB\n",
    "shp_minis = Path(r\"E:\\IGUAÇU_OTTO\\6_Calibração\\minis_mgb.shp\")\n",
    "ID_FIELD  = \"ID_Mini\"  # campo de ID da minibacia no shapefile\n",
    "\n",
    "# Pasta para shapefiles do ensemble\n",
    "shapes_dir = base_dir / \"shapes_deltaQQ_ensemble\"\n",
    "shapes_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Pasta para figuras\n",
    "fig_out_dir = base_dir / \"figuras_ensemble\"\n",
    "fig_out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Shapefile das sub-bacias (para contorno)\n",
    "shp_sub = Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\")\n",
    "\n",
    "# Shapefile das cidades (contendo Curitiba e União da Vitória)\n",
    "shp_cidades = Path(\n",
    "    r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\"\n",
    ")\n",
    "\n",
    "# Campo com o nome da cidade no shapefile de cidades\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Horizontes: 3 painéis e 4 painéis (inclui Total)\n",
    "# ---------------------------------------------------\n",
    "horiz_labels_3 = [\"2015-2040\", \"2041-2070\", \"2071-2100\"]\n",
    "horiz_codes_3  = [\"2015_2040\", \"2041_2070\", \"2071_2100\"]\n",
    "\n",
    "horiz_labels_4 = [\"2015-2040\", \"2041-2070\", \"2071-2100\", \"2015-2100\"]\n",
    "horiz_codes_4  = [\"2015_2040\", \"2041_2070\", \"2071_2100\", \"2015_2100\"]\n",
    "\n",
    "# Rótulos mais didáticos (opcional)\n",
    "rotulos_paineis = {\n",
    "    \"2015-2040\": \"Horizonte 2015–2040\",\n",
    "    \"2041-2070\": \"Horizonte 2041–2070\",\n",
    "    \"2071-2100\": \"Horizonte 2071–2100\",\n",
    "    \"2015-2100\": \"Horizonte Total (2015–2100)\",\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Escala fixa\n",
    "# ---------------------------------------------------\n",
    "vmin, vmax = -100.0, 100.0\n",
    "divnorm = TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "\n",
    "# ===================================================\n",
    "# 1. ETAPA 1 – GERAR SHAPEFILES DE ΔQ/Q ENSEMBLE\n",
    "# ===================================================\n",
    "\n",
    "print(\"\\n=== ETAPA 1: Gerando shapefiles de ΔQ/Q ensemble por horizonte ===\\n\")\n",
    "\n",
    "df_ens = pd.read_csv(ensemble_csv)\n",
    "\n",
    "col_esp = {\"minibacia\", \"horizonte\", \"delta_q_q_ensemble\"}\n",
    "if not col_esp.issubset(df_ens.columns):\n",
    "    raise ValueError(\n",
    "        f\"O CSV de ensemble não contém as colunas esperadas. \"\n",
    "        f\"Esperado pelo menos: {col_esp}, encontrado: {set(df_ens.columns)}\"\n",
    "    )\n",
    "\n",
    "# \"mb_1\" → 1\n",
    "df_ens[\"mini\"] = df_ens[\"minibacia\"].str.replace(\"mb_\", \"\", regex=False).astype(int)\n",
    "\n",
    "minis_gdf = gpd.read_file(shp_minis)\n",
    "minis_gdf[ID_FIELD] = minis_gdf[ID_FIELD].astype(int)\n",
    "\n",
    "# Gerar shapefiles para TODOS os horizontes que vamos usar (3 + total)\n",
    "for h_label, h_code in zip(horiz_labels_4, horiz_codes_4):\n",
    "    print(f\"  Horizonte {h_label} → código {h_code}\")\n",
    "\n",
    "    df_h = df_ens[df_ens[\"horizonte\"] == h_label].copy()\n",
    "    if df_h.empty:\n",
    "        print(f\"   [AVISO] Não há dados para o horizonte {h_label} no CSV. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    gdf_h = minis_gdf.merge(\n",
    "        df_h[[\"mini\", \"delta_q_q_ensemble\"]],\n",
    "        left_on=ID_FIELD,\n",
    "        right_on=\"mini\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    gdf_h = gdf_h.rename(columns={\"delta_q_q_ensemble\": \"delta_q_q\"})\n",
    "\n",
    "    shp_out = shapes_dir / f\"minis_deltaQQ_ensemble_{h_code}.shp\"\n",
    "    gdf_h.to_file(shp_out)\n",
    "    print(f\"   Shapefile ensemble salvo: {shp_out.name}\")\n",
    "\n",
    "print(\"\\n✔ ETAPA 1 concluída: shapefiles ensemble gerados em:\", shapes_dir)\n",
    "\n",
    "# ===================================================\n",
    "# 2. ETAPA 2 – FUNÇÕES DE MAPA (3×1 e 2×2)\n",
    "# ===================================================\n",
    "\n",
    "print(\"\\n=== ETAPA 2: Gerando mapas do ensemble (3 painéis e 4 painéis) ===\\n\")\n",
    "\n",
    "def carregar_gdfs(codes: list[str]) -> list[gpd.GeoDataFrame]:\n",
    "    gdfs_local = []\n",
    "    for code in codes:\n",
    "        shp_path = shapes_dir / f\"minis_deltaQQ_ensemble_{code}.shp\"\n",
    "        if not shp_path.exists():\n",
    "            raise FileNotFoundError(f\"Shapefile não encontrado: {shp_path}\")\n",
    "        gdfs_local.append(gpd.read_file(shp_path))\n",
    "    return gdfs_local\n",
    "\n",
    "def preparar_camadas(crs_minis):\n",
    "    gdf_sub = gpd.read_file(shp_sub).to_crs(crs_minis)\n",
    "    gdf_cid = gpd.read_file(shp_cidades).to_crs(crs_minis)\n",
    "\n",
    "    mask_cur = gdf_cid[CAMPO_NOME_CIDADE].str.contains(r\"^curitiba$\", case=False, na=False, regex=True)\n",
    "    mask_un  = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"uni[aã]o da vit\", case=False, na=False, regex=True)\n",
    "    cidades = gdf_cid[mask_cur | mask_un].copy()\n",
    "\n",
    "    return gdf_sub, cidades\n",
    "\n",
    "def aplicar_colorbar(fig, cax):\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"RdYlBu\", norm=divnorm)\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ/Q (%) – mediana anual do ensemble\", fontsize=11)\n",
    "\n",
    "    ticks = [-100, -75, -50, -25, 0, 25, 50, 75, 100]\n",
    "    labels = [\"< -100\", \"-75\", \"-50\", \"-25\", \"0\", \"25\", \"50\", \"75\", \"> 100\"]\n",
    "    cbar.set_ticks(ticks)\n",
    "    cbar.set_ticklabels(labels)\n",
    "\n",
    "def plot_painel(ax, gdf, title, gdf_sub, cidades, bounds):\n",
    "    xmin, ymin, xmax, ymax = bounds\n",
    "    dx = (xmax - xmin) * 0.01\n",
    "    dy = (ymax - ymin) * 0.01\n",
    "\n",
    "    gdf.plot(\n",
    "        column=\"delta_q_q\",\n",
    "        cmap=\"RdYlBu\",\n",
    "        norm=divnorm,\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.08,\n",
    "    )\n",
    "\n",
    "    gdf_sub.boundary.plot(ax=ax, edgecolor=\"grey\", linewidth=1.2, zorder=3)\n",
    "\n",
    "    if not cidades.empty:\n",
    "        cidades.plot(ax=ax, marker=\"^\", color=\"black\", markersize=40, zorder=4, linewidth=0)\n",
    "        for _, row in cidades.iterrows():\n",
    "            x = row.geometry.x\n",
    "            y = row.geometry.y\n",
    "            nome = row[CAMPO_NOME_CIDADE]\n",
    "            txt = ax.text(\n",
    "                x + dx, y + dy, nome,\n",
    "                fontsize=9, color=\"white\",\n",
    "                ha=\"left\", va=\"bottom\", zorder=5\n",
    "            )\n",
    "            txt.set_path_effects([\n",
    "                patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                patheffects.Normal()\n",
    "            ])\n",
    "\n",
    "    ax.set_title(title, fontsize=11, pad=5)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# ===================================================\n",
    "# 3. MAPA 3×1\n",
    "# ===================================================\n",
    "\n",
    "gdfs_3 = carregar_gdfs(horiz_codes_3)\n",
    "crs_minis = gdfs_3[0].crs\n",
    "gdf_sub_proj, cidades_proj = preparar_camadas(crs_minis)\n",
    "bounds = gdfs_3[0].total_bounds\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6), dpi=300)\n",
    "gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.06])\n",
    "\n",
    "axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "\n",
    "for ax, gdf, label in zip(axes, gdfs_3, horiz_labels_3):\n",
    "    plot_painel(ax, gdf, rotulos_paineis[label], gdf_sub_proj, cidades_proj, bounds)\n",
    "\n",
    "cax = fig.add_subplot(gs[3])\n",
    "aplicar_colorbar(fig, cax)\n",
    "\n",
    "fig.suptitle(\"ΔQ/Q (%) – Ensemble (SSP2-4.5)\", fontsize=14, weight=\"bold\", y=0.97)\n",
    "fig.subplots_adjust(left=0.02, right=0.95, top=0.90, bottom=0.03, wspace=0.02)\n",
    "\n",
    "fig_path_3 = fig_out_dir / \"MAPA_3PAINEIS_ENSEMBLE.png\"\n",
    "fig.savefig(fig_path_3, dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"✔ Figura 3×1 salva:\", fig_path_3)\n",
    "\n",
    "# ===================================================\n",
    "# 4. MAPA 2×2 (4 PAINÉIS, INCLUI TOTAL)\n",
    "# ===================================================\n",
    "\n",
    "# Se o CSV não tiver \"2015-2100\", esta parte vai falhar ao carregar o shapefile.\n",
    "gdfs_4 = carregar_gdfs(horiz_codes_4)\n",
    "crs_minis = gdfs_4[0].crs\n",
    "gdf_sub_proj, cidades_proj = preparar_camadas(crs_minis)\n",
    "bounds = gdfs_4[0].total_bounds\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10), dpi=300)\n",
    "gs = gridspec.GridSpec(  2, 3,  width_ratios=[1, 1, 0.05],  # colorbar bem mais estreita\n",
    "    wspace=0.04,   hspace=0.08)\n",
    "\n",
    "\n",
    "ax_11 = fig.add_subplot(gs[0, 0])\n",
    "ax_12 = fig.add_subplot(gs[0, 1])\n",
    "ax_21 = fig.add_subplot(gs[1, 0])\n",
    "ax_22 = fig.add_subplot(gs[1, 1])\n",
    "cax   = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "axes = [ax_11, ax_12, ax_21, ax_22]\n",
    "\n",
    "for ax, gdf, label in zip(axes, gdfs_4, horiz_labels_4):\n",
    "    plot_painel(ax, gdf, rotulos_paineis[label], gdf_sub_proj, cidades_proj, bounds)\n",
    "\n",
    "aplicar_colorbar(fig, cax)\n",
    "\n",
    "fig.suptitle(\"ΔQ/Q (%) – Ensemble (SSP2-4.5)\", fontsize=14, weight=\"bold\", y=0.98)\n",
    "fig.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "\n",
    "fig_path_4 = fig_out_dir / \"MAPA_4PAINEIS_ENSEMBLE_2.png\"\n",
    "fig.savefig(fig_path_4, dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"✔ Figura 2×2 salva:\", fig_path_4)\n",
    "print(\"\\n✨ Concluído: mapas 3×1 e 4 painéis gerados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311051d9-26ee-4973-93bc-dbeaa41a338d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af7fd5-96bb-41f3-8a45-fdf8c3c69518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# CAMINHOS\n",
    "# ==============================\n",
    "base_dir = Path(r\"C:\\Users\\Matheus Marinho\\Downloads\\Nova pasta\\Leitor de Binários\\shapes_deltaQQ\")\n",
    "\n",
    "# horizontes\n",
    "horiz_codes  = [\"2015_2040\", \"2041_2070\", \"2071_2100\"]\n",
    "horiz_labels = [\"2015-2040\", \"2041-2070\", \"2071-2100\"]\n",
    "\n",
    "# saída\n",
    "out = base_dir.parent / \"figuras_3painéis_FINAL\"\n",
    "out.mkdir(exist_ok=True)\n",
    "\n",
    "# ==============================\n",
    "# 1. LISTAR MODELOS\n",
    "# ==============================\n",
    "modelos = sorted({ \"_\".join(f.stem.split(\"_\")[2:-2]) for f in base_dir.glob(\"minis_deltaQQ_*.shp\") })\n",
    "\n",
    "print(f\"\\nModelos detectados ({len(modelos)}):\")\n",
    "for m in modelos: print(\" →\", m)\n",
    "\n",
    "# ==============================\n",
    "# 2. DEFINIR ESCALA GLOBAL P/ TODOS MODELOS\n",
    "# ==============================\n",
    "valores = []\n",
    "for modelo in modelos:\n",
    "    for code in horiz_codes:\n",
    "        df = gpd.read_file(base_dir / f\"minis_deltaQQ_{modelo}_{code}.shp\")\n",
    "        valores.extend(df[\"delta_q_q\"].tolist())\n",
    "\n",
    "# escala fixa global\n",
    "vmin, vmax = np.percentile(valores, [1, 99])   # limpa outliers extremos\n",
    "# OU se quiser usar o range absoluto real → comente acima e descomente abaixo\n",
    "# vmin, vmax = min(valores), max(valores)\n",
    "\n",
    "print(f\"\\nESCALA GLOBAL FIXA APLICADA A TODOS MAPAS → {vmin:.1f}  a  {vmax:.1f}\\n\")\n",
    "\n",
    "# ==============================\n",
    "# 3. MAPA 3×1 PARA CADA MODELO (SEM DISTORÇÃO)\n",
    "# ==============================\n",
    "for modelo in modelos:\n",
    "\n",
    "    print(f\"\\nGerando figura → {modelo}\")\n",
    "\n",
    "    gdfs = [gpd.read_file(base_dir / f\"minis_deltaQQ_{modelo}_{code}.shp\")\n",
    "            for code in horiz_codes]\n",
    "\n",
    "    xmin, ymin, xmax, ymax = gdfs[0].total_bounds\n",
    "\n",
    "    # Grade 1×3 + barra lateral fixa (coluna 4)\n",
    "    fig = plt.figure(figsize=(18,6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1,4, width_ratios=[1,1,1,0.05])\n",
    "\n",
    "    axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "\n",
    "    for ax, gdf, label in zip(axes, gdfs, horiz_labels):\n",
    "\n",
    "        gdf.plot(column=\"delta_q_q\",\n",
    "                 cmap=\"RdYlBu_r\",\n",
    "                 ax=ax,\n",
    "                 vmin=vmin, vmax=vmax,\n",
    "                 edgecolor=\"black\", linewidth=0.08)\n",
    "\n",
    "        ax.set_title(f\"Horizonte {label}\", fontsize=11)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # COLORBAR na coluna 4 (sem encolher o 3º painel)\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "    sm  = plt.cm.ScalarMappable(cmap=\"RdYlBu_r\", norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ/Q (%)\", fontsize=11)\n",
    "\n",
    "    fig.suptitle(f\"ΔQ/Q (%) – Modelo {modelo}\", fontsize=14, weight=\"bold\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(out / f\"MAPA_3PAINEIS_FIXO_{modelo}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"\\n✨ FINALIZADO – Todos os mapas gerados com escala fixa e painéis alinhados.\")\n",
    "print(f\"Pasta de saída: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85145f8-cbf9-4c63-b922-0ba2d7375253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patheffects\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# CAMINHOS\n",
    "# ==============================\n",
    "base_dir = Path(r\"C:\\Users\\Matheus Marinho\\Downloads\\Nova pasta\\Leitor de Binários\\shapes_deltaQQ\")\n",
    "\n",
    "# shapefile das sub-bacias\n",
    "shp_sub = Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\")\n",
    "\n",
    "# shapefile das sedes municipais (contém Curitiba e União da Vitória)\n",
    "shp_cidades = Path(\n",
    "    r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\"\n",
    ")\n",
    "\n",
    "# horizontes\n",
    "horiz_codes  = [\"2015_2040\", \"2041_2070\", \"2071_2100\"]\n",
    "horiz_labels = [\"2015-2040\", \"2041-2070\", \"2071-2100\"]\n",
    "\n",
    "# pasta de saída\n",
    "out = base_dir.parent / \"figuras_3paineis_FINAL\"\n",
    "out.mkdir(exist_ok=True)\n",
    "\n",
    "# ==============================\n",
    "# 1. LISTAR MODELOS\n",
    "# ==============================\n",
    "modelos = sorted({\n",
    "    \"_\".join(f.stem.split(\"_\")[2:-2])\n",
    "    for f in base_dir.glob(\"minis_deltaQQ_*.shp\")\n",
    "})\n",
    "\n",
    "print(f\"\\nModelos detectados ({len(modelos)}):\")\n",
    "for m in modelos:\n",
    "    print(\" →\", m)\n",
    "\n",
    "# ==============================\n",
    "# 2. DEFINIR ESCALA GLOBAL P/ TODOS MODELOS\n",
    "# ==============================\n",
    "valores = []\n",
    "for modelo in modelos:\n",
    "    for code in horiz_codes:\n",
    "        df = gpd.read_file(base_dir / f\"minis_deltaQQ_{modelo}_{code}.shp\")\n",
    "        valores.extend(df[\"delta_q_q\"].tolist())\n",
    "\n",
    "# escala fixa global (1º e 99º percentil para tirar extremos muito fora da curva)\n",
    "vmin, vmax = np.percentile(valores, [1, 99])\n",
    "print(f\"\\nESCALA GLOBAL FIXA APLICADA A TODOS MAPAS → {vmin:.1f}  a  {vmax:.1f}\\n\")\n",
    "\n",
    "# ==============================\n",
    "# 3. LER SUB-BACIAS E CIDADES\n",
    "# ==============================\n",
    "gdf_sub = gpd.read_file(shp_sub)\n",
    "gdf_cid = gpd.read_file(shp_cidades)\n",
    "\n",
    "print(\"\\nCRS das cidades:\", gdf_cid.crs)\n",
    "print(\"Campos disponíveis nas cidades:\", list(gdf_cid.columns))\n",
    "\n",
    "# Campo com o nome do município (conforme a tabela)\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# Filtro robusto por substring (case-insensitive), à prova de grafia\n",
    "mask_cur = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"curit\", case=False, na=False)\n",
    "mask_un  = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"uni[aã]o da vit\", case=False, na=False)\n",
    "\n",
    "cidades_sel = gdf_cid[mask_cur | mask_un].copy()\n",
    "\n",
    "print(\"\\nCidades selecionadas para plotagem:\")\n",
    "print(cidades_sel[[CAMPO_NOME_CIDADE]].drop_duplicates())\n",
    "\n",
    "# ==============================\n",
    "# 4. MAPA 3×1 PARA CADA MODELO\n",
    "# ==============================\n",
    "for modelo in modelos:\n",
    "\n",
    "    print(f\"\\nGerando figura → {modelo}\")\n",
    "\n",
    "    # ler shapefiles das minibacias para cada horizonte\n",
    "    gdfs = [\n",
    "        gpd.read_file(base_dir / f\"minis_deltaQQ_{modelo}_{code}.shp\")\n",
    "        for code in horiz_codes\n",
    "    ]\n",
    "\n",
    "    # usar o CRS do primeiro shapefile como referência\n",
    "    crs_minis = gdfs[0].crs\n",
    "\n",
    "    # reprojetar sub-bacias e cidades para o mesmo CRS das minibacias\n",
    "    gdf_sub_proj = gdf_sub.to_crs(crs_minis)\n",
    "    cidades_proj = cidades_sel.to_crs(crs_minis) if not cidades_sel.empty else cidades_sel\n",
    "\n",
    "    xmin, ymin, xmax, ymax = gdfs[0].total_bounds\n",
    "    dx = (xmax - xmin) * 0.01  # deslocamento relativo (~1% da largura do mapa)\n",
    "    dy = (ymax - ymin) * 0.01  # deslocamento relativo em y\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.05])\n",
    "\n",
    "    axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "\n",
    "    for ax, gdf, label in zip(axes, gdfs, horiz_labels):\n",
    "\n",
    "        # mapa base das minibacias com ΔQ/Q\n",
    "        gdf.plot(\n",
    "            column=\"delta_q_q\",\n",
    "            cmap=\"RdYlBu_r\",\n",
    "            ax=ax,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.08,\n",
    "        )\n",
    "\n",
    "        # contorno das sub-bacias (mais grosso para destacar)\n",
    "        gdf_sub_proj.boundary.plot(\n",
    "            ax=ax,\n",
    "            edgecolor=\"grey\",\n",
    "            linewidth=1.2,\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "        # pontos das cidades (se o filtro encontrou alguma)\n",
    "        if not cidades_proj.empty:\n",
    "            cidades_proj.plot(\n",
    "                ax=ax,\n",
    "                marker=\"^\",\n",
    "                color=\"black\",\n",
    "                markersize=40,\n",
    "                zorder=4,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "            # rótulos das cidades, com deslocamento relativo e halo\n",
    "            for _, row in cidades_proj.iterrows():\n",
    "                x = row.geometry.x\n",
    "                y = row.geometry.y\n",
    "                nome = row[CAMPO_NOME_CIDADE]\n",
    "\n",
    "                txt = ax.text(\n",
    "                    x + dx,\n",
    "                    y + dy,\n",
    "                    nome,\n",
    "                    fontsize=9,\n",
    "                    color=\"white\",\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                    zorder=5,\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                    patheffects.Normal()\n",
    "                ])\n",
    "\n",
    "        ax.set_title(f\"Horizonte {label}\", fontsize=11)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # COLORBAR na coluna 4\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "    sm  = plt.cm.ScalarMappable(\n",
    "        cmap=\"RdYlBu_r\",\n",
    "        norm=plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    )\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ/Q (%)\", fontsize=11)\n",
    "\n",
    "    # título geral\n",
    "    fig.suptitle(\n",
    "        f\"ΔQ/Q (%) – Modelo {modelo}\",\n",
    "        fontsize=14,\n",
    "        weight=\"bold\",\n",
    "        y=0.97\n",
    "    )\n",
    "\n",
    "    # ajusta margens manualmente\n",
    "    fig.subplots_adjust(left=0.02, right=0.97, top=0.90, bottom=0.03, wspace=0.02)\n",
    "\n",
    "    # salvar figura\n",
    "    fig.savefig(out / f\"MAPA_3PAINEIS_FIXO_{modelo}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"\\n✨ FINALIZADO – Todos os mapas gerados com sub-bacias e cidades destacadas.\")\n",
    "print(f\"Pasta de saída: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159faa6e-f0bd-42f8-bcd0-88d64f1f3f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "#=============================================================\n",
    "# 1) CONFIGURAÇÃO DE DIRETÓRIOS\n",
    "#=============================================================\n",
    "base_txt  = Path(r\"C:\\Users\\Matheus Marinho\\Downloads\\Nova pasta\\Leitor de Binários\")\n",
    "base_shp  = base_txt / \"shapes_deltaQQ\"\n",
    "output    = base_txt / \"RESULTADOS_MK_FINAL\"\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "#=============================================================\n",
    "# 2) INTERVALOS TEMPORAIS (por ano)\n",
    "#=============================================================\n",
    "HORIZONTES = {\n",
    "    \"H1_2015_2040\": (2015,2040),\n",
    "    \"H2_2041_2070\": (2041,2070),\n",
    "    \"H3_2071_2100\": (2071,2100),\n",
    "    \"TOTAL_2015_2100\": (2015,2100),\n",
    "}\n",
    "\n",
    "P_LIMIT      = 0.05\n",
    "DELTA_LIMIT  = 10.0\n",
    "CONC_LIMIT   = 2/3\n",
    "\n",
    "#=============================================================\n",
    "# 3) CARREGA OBSERVADO PARA REFERÊNCIA (1980–2014)\n",
    "#=============================================================\n",
    "obs = pd.read_csv(base_txt/\"Observado.txt\", sep=r\"\\s+\", header=None)\n",
    "obs.columns=[f\"mb_{i}\" for i in range(1,obs.shape[1]+1)]\n",
    "obs.index=pd.date_range(\"1980-01-01\",\"2023-12-31\",freq=\"D\")\n",
    "\n",
    "Qref = obs.loc[\"1980\":\"2023\"].resample(\"A\").mean().mean() # média anual histórica\n",
    "\n",
    "#=============================================================\n",
    "# 4) LOCALIZA MODELOS DISPONÍVEIS\n",
    "#=============================================================\n",
    "model_files = sorted([f for f in base_txt.glob(\"*.txt\") if \"Observado\" not in f.name])\n",
    "modelos=[f.stem for f in model_files]\n",
    "\n",
    "print(\"\\nMODELOS CARREGADOS:\")\n",
    "for m in modelos: print(\"→\",m)\n",
    "\n",
    "#=============================================================\n",
    "# 5) FUNÇÃO MK UTILIZANDO SÉRIE ANUAL\n",
    "#=============================================================\n",
    "def mk_annual(series, y0, y1):\n",
    "    ser = series[str(y0):str(y1)].resample(\"A\").mean().dropna()\n",
    "    if len(ser)<8: return np.nan\n",
    "    t = np.arange(len(ser))\n",
    "    tau,p = kendalltau(t,ser)\n",
    "    return p\n",
    "\n",
    "#=============================================================\n",
    "# 6) PROCESSAMENTO GERAL\n",
    "#=============================================================\n",
    "resultado=[]\n",
    "\n",
    "for modelo in modelos:\n",
    "\n",
    "    print(f\"\\n⏳ PROCESSANDO {modelo} ...\")\n",
    "    df = pd.read_csv(base_txt/f\"{modelo}.txt\", sep=r\"\\s+\", header=None)\n",
    "    df.columns=Qref.index\n",
    "    df.index=pd.date_range(\"2015-01-01\",\"2100-12-31\",freq=\"D\")\n",
    "\n",
    "    for mini in Qref.index:\n",
    "        serie=df[mini]\n",
    "\n",
    "        pvals  ={h:mk_annual(serie,ini,fim) for h,(ini,fim) in HORIZONTES.items()}\n",
    "        deltas ={h:(serie[str(ini):str(fim)].resample(\"A\").mean().mean()-Qref[mini])/\n",
    "                  Qref[mini]*100 for h,(ini,fim) in HORIZONTES.items()}\n",
    "\n",
    "        resultado.append({\n",
    "            \"modelo\":modelo,\"mini\":mini,\n",
    "            **{f\"p_{h}\":pvals[h] for h in HORIZONTES},\n",
    "            **{f\"dq_{h}\":deltas[h] for h in HORIZONTES},\n",
    "        })\n",
    "\n",
    "resultado=pd.DataFrame(resultado)\n",
    "resultado.to_csv(output/\"MK_DeltaQ_Modelos.csv\",index=False)\n",
    "print(\"\\n✔ Base anual completa salva.\")\n",
    "\n",
    "#=============================================================\n",
    "# 7) CLASSIFICAÇÃO TERNÁRIA POR HORIZONTE\n",
    "#=============================================================\n",
    "classe={}\n",
    "\n",
    "for h in HORIZONTES:\n",
    "\n",
    "    df=resultado[[\"mini\",\"modelo\",f\"p_{h}\",f\"dq_{h}\"]]\n",
    "\n",
    "    grup=df.groupby(\"mini\").agg({\n",
    "        f\"p_{h}\":lambda x:(x<P_LIMIT).mean(),\n",
    "        f\"dq_{h}\":[\"mean\",\n",
    "                   lambda x:(x>+DELTA_LIMIT).mean(),\n",
    "                   lambda x:(x<-DELTA_LIMIT).mean()]\n",
    "    })\n",
    "\n",
    "    grup.columns=[\"p_sig\",\"dq_media\",\"frac_pos\",\"frac_neg\"]\n",
    "    grup[\"classe\"]=0\n",
    "    grup.loc[(grup[\"p_sig\"]>=CONC_LIMIT)&(grup[\"frac_neg\"]>=CONC_LIMIT)&(grup[\"dq_media\"]<-DELTA_LIMIT),\"classe\"]=-2\n",
    "    grup.loc[(grup[\"p_sig\"]>=CONC_LIMIT)&(grup[\"frac_pos\"]>=CONC_LIMIT)&(grup[\"dq_media\"]>+DELTA_LIMIT),\"classe\"]=+2\n",
    "\n",
    "    grup.to_csv(output/f\"CLASS_{h}.csv\")\n",
    "    classe[h]=grup.reset_index()\n",
    "\n",
    "print(\"\\n✔ Critérios aplicados e salvos.\")\n",
    "\n",
    "#=============================================================\n",
    "# 8) MAPAS FINAIS (3 HORIZONTES POR MODELO)\n",
    "#=============================================================\n",
    "shp=gpd.read_file(base_shp/f\"minis_deltaQQ_{modelos[0]}_2015_2040.shp\")\n",
    "\n",
    "for modelo in modelos:\n",
    "    print(f\"\\n🗺  MAPAS {modelo} ...\")\n",
    "\n",
    "    fig=plt.figure(figsize=(18,6),dpi=300)\n",
    "    gs=gridspec.GridSpec(1,4,width_ratios=[1,1,1,0.07])\n",
    "\n",
    "    for i,h in enumerate([\"H1_2015_2040\",\"H2_2041_2070\",\"H3_2071_2100\"]):\n",
    "\n",
    "        df=classe[h]\n",
    "        gdf=shp.merge(df,on=\"mini\")\n",
    "\n",
    "        ax=fig.add_subplot(gs[i])\n",
    "        gdf.plot(column=\"classe\",cmap=\"bwr\",vmin=-2,vmax=2,\n",
    "                 edgecolor=\"black\",linewidth=0.08,ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(h.replace(\"_\",\" → \").replace(\"H1\",\"2015–2040\")\n",
    "                     .replace(\"H2\",\"2041–2070\").replace(\"H3\",\"2071–2100\"))\n",
    "\n",
    "    # barra de legenda\n",
    "    cax=fig.add_subplot(gs[3])\n",
    "    sm=plt.cm.ScalarMappable(cmap=\"bwr\",norm=plt.Normalize(-2,2))\n",
    "    sm._A=[]\n",
    "    cbar=fig.colorbar(sm,cax=cax)\n",
    "    cbar.set_ticks([-2,0,2])\n",
    "    cbar.set_ticklabels([\"Redução robusta\",\"Inconclusivo\",\"Aumento robusto\"])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output/f\"MAPA_ROBUSTEZ_{modelo}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"\\n🎉 FINALIZADO — RESULTADOS EM:\\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38881c5f-36a8-4d7a-bf5c-b102b850754a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, patheffects\n",
    "from pathlib import Path\n",
    "\n",
    "#==============================================================\n",
    "# ⚙️ CAMINHOS\n",
    "#==============================================================\n",
    "base      = Path(r\"C:\\Users\\Matheus Marinho\\Downloads\\Nova pasta\\Leitor de Binários\")\n",
    "\n",
    "# shapefile das minibacias (onde está o ID_Mini)\n",
    "shp_minis = Path(r\"E:\\IGUAÇU_OTTO\\6_Calibração\\minis_mgb.shp\")\n",
    "\n",
    "# shapefile das sub-bacias (contorno por sub-bacia)\n",
    "shp_sub   = Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\")\n",
    "\n",
    "# shapefile das sedes municipais (Curitiba e União da Vitória)\n",
    "shp_cid   = Path(\n",
    "    r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\"\n",
    ")\n",
    "\n",
    "out       = base / \"RESULTADOS_Q95_Q5\"\n",
    "out_shp   = out  / \"SHP\"\n",
    "out_maps  = out  / \"MAPAS\"\n",
    "out.mkdir(exist_ok=True)\n",
    "out_shp.mkdir(exist_ok=True)\n",
    "out_maps.mkdir(exist_ok=True)\n",
    "\n",
    "#==============================================================\n",
    "# 📅 HORIZONTES (DIÁRIO) – MESMO PADRÃO DE NOMES DOS MAPAS DE MÉDIA\n",
    "#==============================================================\n",
    "H = {\n",
    "    \"2015_2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"2041_2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"2071_2100\": (\"2071-01-01\", \"2100-12-31\"),\n",
    "}\n",
    "H_LABEL = {\n",
    "    \"2015_2040\": \"2015-2040\",\n",
    "    \"2041_2070\": \"2041-2070\",\n",
    "    \"2071_2100\": \"2071-2100\",\n",
    "}\n",
    "\n",
    "#==============================================================\n",
    "# Funções estatísticas\n",
    "#==============================================================\n",
    "def q95(s):\n",
    "    return np.nanpercentile(s, 95)\n",
    "\n",
    "def q5(s):\n",
    "    return np.nanpercentile(s, 5)\n",
    "\n",
    "#==============================================================\n",
    "# 🔵 Calcular Qref do Observado (1980–2023)\n",
    "#==============================================================\n",
    "obs = pd.read_csv(base / \"Observado.txt\", sep=r\"\\s+\", header=None)\n",
    "obs.columns = [f\"mb_{i}\" for i in range(1, obs.shape[1] + 1)]\n",
    "obs.index   = pd.date_range(\"1980-01-01\", \"2023-12-31\", freq=\"D\")\n",
    "\n",
    "Qref95 = obs.loc[\"1980\":\"2023\"].apply(q95)\n",
    "Qref5  = obs.loc[\"1980\":\"2023\"].apply(q5)\n",
    "\n",
    "#==============================================================\n",
    "# Listar modelos (todos .txt exceto Observado)\n",
    "#==============================================================\n",
    "modelos = [f.stem for f in base.glob(\"*.txt\") if \"Observado\" not in f.name]\n",
    "\n",
    "print(\"\\nModelos encontrados:\")\n",
    "for m in modelos:\n",
    "    print(\"  →\", m)\n",
    "\n",
    "#==============================================================\n",
    "# 🔷 Ler shapes (minibacias, sub-bacias, cidades)\n",
    "#==============================================================\n",
    "shape_minis = gpd.read_file(shp_minis)\n",
    "shape_sub   = gpd.read_file(shp_sub)\n",
    "shape_cid   = gpd.read_file(shp_cid)\n",
    "\n",
    "print(\"\\nCRS das shapes:\")\n",
    "print(\"  Minibacias:\", shape_minis.crs)\n",
    "print(\"  Sub-bacias:\", shape_sub.crs)\n",
    "print(\"  Cidades   :\", shape_cid.crs)\n",
    "\n",
    "# Campo com o nome do município no shapefile de cidades\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# Filtro robusto por substring (case-insensitive) para Curitiba e União da Vitória\n",
    "mask_cur = shape_cid[CAMPO_NOME_CIDADE].str.contains(\"curit\", case=False, na=False)\n",
    "mask_un  = shape_cid[CAMPO_NOME_CIDADE].str.contains(\"uni[aã]o da vit\", case=False, na=False)\n",
    "\n",
    "cidades_sel = shape_cid[mask_cur | mask_un].copy()\n",
    "print(\"\\nCidades selecionadas:\")\n",
    "print(cidades_sel[[CAMPO_NOME_CIDADE]].drop_duplicates())\n",
    "\n",
    "# Reprojetar sub-bacias e cidades para o CRS das minibacias\n",
    "crs_minis     = shape_minis.crs\n",
    "sub_proj      = shape_sub.to_crs(crs_minis)\n",
    "cidades_proj  = cidades_sel.to_crs(crs_minis) if not cidades_sel.empty else cidades_sel\n",
    "\n",
    "xmin, ymin, xmax, ymax = shape_minis.total_bounds\n",
    "dx = (xmax - xmin) * 0.01  # deslocamento relativo p/ rótulos\n",
    "dy = (ymax - ymin) * 0.01\n",
    "\n",
    "#==============================================================\n",
    "# 🔥 PRÉ-PASSO → Encontrar valores globais (para cor fixa)\n",
    "#==============================================================\n",
    "all_95_vals = []\n",
    "all_5_vals  = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    df = pd.read_csv(base / f\"{modelo}.txt\", sep=r\"\\s+\", header=None)\n",
    "    df.columns = Qref95.index\n",
    "    df.index   = pd.date_range(\"2015-01-01\", \"2100-12-31\", freq=\"D\")\n",
    "\n",
    "    for _, (ini, fim) in H.items():\n",
    "        bloco = df.loc[ini:fim].copy()\n",
    "\n",
    "        all_95_vals.extend(((bloco.apply(q95) - Qref95) / Qref95 * 100).values)\n",
    "        all_5_vals.extend(((bloco.apply(q5) - Qref5) / Qref5 * 100).values)\n",
    "\n",
    "# Escala global (pode usar min/max ou percentil; aqui uso percentil para tirar extremos)\n",
    "vmin95, vmax95 = np.nanpercentile(all_95_vals, [1, 99])\n",
    "vmin5 , vmax5  = np.nanpercentile(all_5_vals,  [1, 99])\n",
    "\n",
    "print(\"\\n📌 Escala global definida para todos os mapas:\")\n",
    "print(f\"ΔQ95 → min={vmin95:.2f}   max={vmax95:.2f}\")\n",
    "print(f\"ΔQ5  → min={vmin5 :.2f}   max={vmax5 :.2f}\")\n",
    "\n",
    "#==============================================================\n",
    "# PROCESSAMENTO FINAL – SHPs + MAPAS\n",
    "#==============================================================\n",
    "for modelo in modelos:\n",
    "\n",
    "    print(f\"\\n===========================\\nPROCESSANDO {modelo}\\n===========================\")\n",
    "\n",
    "    df = pd.read_csv(base / f\"{modelo}.txt\", sep=r\"\\s+\", header=None)\n",
    "    df.columns = Qref95.index\n",
    "    df.index   = pd.date_range(\"2015-01-01\", \"2100-12-31\", freq=\"D\")\n",
    "\n",
    "    deltaQ95 = {}\n",
    "    deltaQ5  = {}\n",
    "\n",
    "    #========== Q95 / Q5 por modelo ============================\n",
    "    for Hcode, (ini, fim) in H.items():\n",
    "        bloco = df.loc[ini:fim]\n",
    "\n",
    "        dQ95 = (bloco.apply(q95) - Qref95) / Qref95 * 100\n",
    "        dQ5  = (bloco.apply(q5)  - Qref5 ) / Qref5  * 100\n",
    "\n",
    "        deltaQ95[Hcode] = dQ95\n",
    "        deltaQ5 [Hcode] = dQ5\n",
    "\n",
    "        #=== gerar SHP automático (minibacias) ===\n",
    "        s95 = dQ95.copy()\n",
    "        s95.index = s95.index.str.replace(\"mb_\", \"\").astype(int)\n",
    "\n",
    "        s5  = dQ5.copy()\n",
    "        s5.index  = s5.index.str.replace(\"mb_\", \"\").astype(int)\n",
    "\n",
    "        g95 = shape_minis.merge(s95.rename(\"dQ95\"), left_on=\"ID_Mini\", right_index=True)\n",
    "        g95.to_file(out_shp / f\"Q95_{modelo}_{Hcode}.shp\")\n",
    "\n",
    "        g5  = shape_minis.merge(s5.rename(\"dQ5\"), left_on=\"ID_Mini\", right_index=True)\n",
    "        g5.to_file(out_shp / f\"Q5_{modelo}_{Hcode}.shp\")\n",
    "\n",
    "    #========== MAPA Q95 (escala global fixa) ==================\n",
    "    fig = plt.figure(figsize=(18, 6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.07])\n",
    "\n",
    "    for i, (Hcode, serie) in enumerate(deltaQ95.items()):\n",
    "        s = serie.copy()\n",
    "        s.index = s.index.str.replace(\"mb_\", \"\").astype(int)\n",
    "        g = shape_minis.merge(s.rename(\"dQ95\"), left_on=\"ID_Mini\", right_index=True)\n",
    "\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        g.plot(\n",
    "            column=\"dQ95\",\n",
    "            cmap=\"RdYlBu_r\",\n",
    "            vmin=vmin95,\n",
    "            vmax=vmax95,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.08,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # contorno das sub-bacias\n",
    "        sub_proj.boundary.plot(\n",
    "            ax=ax,\n",
    "            edgecolor=\"grey\",\n",
    "            linewidth=1.2,\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "        # cidades + rótulos\n",
    "        if not cidades_proj.empty:\n",
    "            cidades_proj.plot(\n",
    "                ax=ax,\n",
    "                marker=\"^\",\n",
    "                color=\"black\",\n",
    "                markersize=40,\n",
    "                zorder=4,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "            for _, row in cidades_proj.iterrows():\n",
    "                x = row.geometry.x\n",
    "                y = row.geometry.y\n",
    "                nome = row[CAMPO_NOME_CIDADE]\n",
    "\n",
    "                txt = ax.text(\n",
    "                    x + dx,\n",
    "                    y + dy,\n",
    "                    nome,\n",
    "                    fontsize=9,\n",
    "                    color=\"white\",\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                    zorder=5,\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                    patheffects.Normal()\n",
    "                ])\n",
    "\n",
    "        ax.set_title(f\"Horizonte {H_LABEL[Hcode]}\", fontsize=11)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    sm  = plt.cm.ScalarMappable(cmap=\"RdYlBu_r\",\n",
    "                                norm=plt.Normalize(vmin95, vmax95))\n",
    "    sm._A = []\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ95 (%)\")\n",
    "\n",
    "    fig.suptitle(f\"ΔQ95 (%) – Modelo {modelo}\", fontsize=14, weight=\"bold\", y=0.97)\n",
    "    fig.subplots_adjust(left=0.02, right=0.97, top=0.90,\n",
    "                        bottom=0.03, wspace=0.02)\n",
    "\n",
    "    fig.savefig(out_maps / f\"MAPA_Q95_{modelo}.png\")\n",
    "    plt.close(fig)\n",
    "    print(f\"📍 MAPA_Q95_{modelo}.png ✔\")\n",
    "\n",
    "    #========== MAPA Q5 (escala global fixa) ==================\n",
    "    fig = plt.figure(figsize=(18, 6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.07])\n",
    "\n",
    "    for i, (Hcode, serie) in enumerate(deltaQ5.items()):\n",
    "        s = serie.copy()\n",
    "        s.index = s.index.str.replace(\"mb_\", \"\").astype(int)\n",
    "        g = shape_minis.merge(s.rename(\"dQ5\"), left_on=\"ID_Mini\", right_index=True)\n",
    "\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        g.plot(\n",
    "            column=\"dQ5\",\n",
    "            cmap=\"RdYlBu_r\",\n",
    "            vmin=vmin5,\n",
    "            vmax=vmax5,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.08,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # contorno das sub-bacias\n",
    "        sub_proj.boundary.plot(\n",
    "            ax=ax,\n",
    "            edgecolor=\"grey\",\n",
    "            linewidth=1.2,\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "        # cidades + rótulos\n",
    "        if not cidades_proj.empty:\n",
    "            cidades_proj.plot(\n",
    "                ax=ax,\n",
    "                marker=\"^\",\n",
    "                color=\"black\",\n",
    "                markersize=40,\n",
    "                zorder=4,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "            for _, row in cidades_proj.iterrows():\n",
    "                x = row.geometry.x\n",
    "                y = row.geometry.y\n",
    "                nome = row[CAMPO_NOME_CIDADE]\n",
    "\n",
    "                txt = ax.text(\n",
    "                    x + dx,\n",
    "                    y + dy,\n",
    "                    nome,\n",
    "                    fontsize=9,\n",
    "                    color=\"white\",\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                    zorder=5,\n",
    "                )\n",
    "                txt.set_path_effects([\n",
    "                    patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                    patheffects.Normal()\n",
    "                ])\n",
    "\n",
    "        ax.set_title(f\"Horizonte {H_LABEL[Hcode]}\", fontsize=11)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    sm  = plt.cm.ScalarMappable(cmap=\"RdYlBu_r\",\n",
    "                                norm=plt.Normalize(vmin5, vmax5))\n",
    "    sm._A = []\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"ΔQ5 (%)\")\n",
    "\n",
    "    fig.suptitle(f\"ΔQ5 (%) – Modelo {modelo}\", fontsize=14, weight=\"bold\", y=0.97)\n",
    "    fig.subplots_adjust(left=0.02, right=0.97, top=0.90,\n",
    "                        bottom=0.03, wspace=0.02)\n",
    "\n",
    "    fig.savefig(out_maps / f\"MAPA_Q5_{modelo}.png\")\n",
    "    plt.close(fig)\n",
    "    print(f\"📍 MAPA_Q5_{modelo}.png ✔\")\n",
    "\n",
    "print(\"\\n🎉 FINALIZADO — SHPs e mapas de ΔQ95 e ΔQ5 gerados com o mesmo padrão dos mapas de ΔQ/Q.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2f7d8-a5ba-4afe-b4ec-307c803b73dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# CONFIGURAÇÕES\n",
    "# ---------------------------------------------------\n",
    "base_dir = Path(r\"C:\\Users\\Matheus Marinho\\Downloads\\Nova pasta\\Leitor de Binários\")\n",
    "\n",
    "obs_file = base_dir / \"Observado.txt\"\n",
    "model_pattern = \"*-pr-ssp245.txt\"\n",
    "\n",
    "ref_start = \"1980-01-01\"\n",
    "ref_end   = \"2023-12-31\"\n",
    "\n",
    "horizons = {\n",
    "    \"2015-2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"2041-2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"2071-2100\": (\"2071-01-01\", \"2100-12-31\")\n",
    "}\n",
    "\n",
    "# 📁 saída — boxplots e tabela final\n",
    "out = base_dir / \"Q95_Q5_boxplots\"\n",
    "out.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Funções estatísticas\n",
    "# ---------------------------------------------------\n",
    "def q95(s): return np.nanpercentile(s,95)\n",
    "def q5(s):  return np.nanpercentile(s,5)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Observado — Referência hidrológica\n",
    "# ---------------------------------------------------\n",
    "obs = pd.read_csv(obs_file, sep=r\"\\s+\", header=None)\n",
    "obs.columns = [f\"mb_{i+1}\" for i in range(obs.shape[1])]\n",
    "obs.index   = pd.date_range(\"1980-01-01\",\"2023-12-31\",freq=\"D\")\n",
    "\n",
    "# Q95_ref e Q5_ref (base para o Δ%)\n",
    "Q95_ref = obs.loc[\"1980\":\"2014\"].apply(q95)\n",
    "Q5_ref  = obs.loc[\"1980\":\"2014\"].apply(q5)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Função principal – calcula ΔQ95 e ΔQ5 para um modelo\n",
    "# ---------------------------------------------------\n",
    "def processa_modelo(model_file):\n",
    "    df = pd.read_csv(model_file, sep=r\"\\s+\", header=None)\n",
    "    df.columns = Q95_ref.index\n",
    "    df.index   = pd.date_range(\"2015-01-01\",\"2100-12-31\",freq=\"D\")\n",
    "    model_name = model_file.stem\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for horiz_name,(h_start,h_end) in horizons.items():\n",
    "        d = df.loc[h_start:h_end]\n",
    "\n",
    "        Q95 = d.apply(q95)\n",
    "        Q5  = d.apply(q5)\n",
    "\n",
    "        dQ95 = (Q95 - Q95_ref) / Q95_ref * 100\n",
    "        dQ5  = (Q5  - Q5_ref ) / Q5_ref  * 100\n",
    "\n",
    "        # estrutura longa por minibacia\n",
    "        tmp = pd.DataFrame({\n",
    "            \"modelo\":model_name,\n",
    "            \"horizonte\":horiz_name,\n",
    "            \"minibacia\":dQ95.index,\n",
    "            \"delta_Q95\":dQ95.values,\n",
    "            \"delta_Q5\":dQ5.values\n",
    "        })\n",
    "        registros.append(tmp)\n",
    "\n",
    "    return pd.concat(registros,ignore_index=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Loop geral — todos os modelos da pasta\n",
    "# ---------------------------------------------------\n",
    "resultados=[]\n",
    "\n",
    "for mf in base_dir.glob(model_pattern):\n",
    "    if \"Observado\" in mf.name: continue\n",
    "    print(f\"Processando modelo → {mf.name}\")\n",
    "    resultados.append(processa_modelo(mf))\n",
    "\n",
    "df_final = pd.concat(resultados,ignore_index=True)\n",
    "df_final.to_csv(out/\"Q95_Q5_delta_por_modelo.csv\",index=False)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. BOXPLOTS — Q95 e Q5\n",
    "# ---------------------------------------------------\n",
    "modelos = sorted(df_final[\"modelo\"].unique())\n",
    "\n",
    "for horiz,(h_start,h_end) in horizons.items():\n",
    "\n",
    "    df_h = df_final[df_final[\"horizonte\"]==horiz]\n",
    "\n",
    "    # BOX ΔQ95\n",
    "    data95=[df_h[df_h.modelo==m][\"delta_Q95\"].values for m in modelos]\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.boxplot(data95,labels=modelos,showfliers=False)\n",
    "    plt.xticks(rotation=45,ha=\"right\")\n",
    "    plt.axhline(0,color=\"black\",linestyle=\"--\")\n",
    "    plt.title(f\"ΔQ95 (%) – distribuição por minibacia – {horiz}\")\n",
    "    plt.ylabel(\"ΔQ95 (%)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out/f\"BOX_Q95_{horiz}.png\",dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # BOX ΔQ5\n",
    "    data5=[df_h[df_h.modelo==m][\"delta_Q5\"].values for m in modelos]\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.boxplot(data5,labels=modelos,showfliers=False)\n",
    "    plt.xticks(rotation=45,ha=\"right\")\n",
    "    plt.axhline(0,color=\"black\",linestyle=\"--\")\n",
    "    plt.title(f\"ΔQ5 (%) – distribuição por minibacia – {horiz}\")\n",
    "    plt.ylabel(\"ΔQ5 (%)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out/f\"BOX_Q5_{horiz}.png\",dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\n📌 FINALIZADO — Boxplots e CSV salvos em:\",out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cab84-2580-4333-b4d5-289e0a31f57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd1c48-a191-4b28-9587-fe1a1d4a3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "ENSEMBLE – Variação espacial de ΔQ/Q (%) por horizonte (SSP2-4.5 e SSP5-8.5)\n",
    "\n",
    "FIGURA FINAL (2×1):\n",
    "- Uma linha por cenário (SSP2-4.5 em cima, SSP5-8.5 embaixo)\n",
    "- Em cada cenário: 4 boxplots lado a lado (um por horizonte) no MESMO eixo\n",
    "- Eixo Y comum (comparável) e ajustado AUTOMATICAMENTE aos whiskers (quando showfliers=False)\n",
    "- Linha de referência em ΔQ/Q = 0\n",
    "\n",
    "TABELA COMPLETA:\n",
    "- Estatísticas espaciais de ΔQ/Q (%) por cenário × horizonte:\n",
    "  n_minibacias, min, p05, q1, mediana, media, q3, p95, max, iqr, amplitude,\n",
    "  std, cv, skew, pct_pos, pct_neg, pct_zero\n",
    "- Comparação espacial de níveis:\n",
    "  Qpres_media_espacial, Qpres_mediana_espacial,\n",
    "  Qfut_media_espacial, Qfut_mediana_espacial,\n",
    "  Qfut_minus_Qpres_media_espacial, Qfut_minus_Qpres_mediana_espacial\n",
    "\n",
    "Entradas:\n",
    "- SSP2-4.5:\n",
    "  E:\\RESULTADOS\\SSP2_45\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp245.csv\n",
    "- SSP5-8.5:\n",
    "  E:\\RESULTADOS\\SSP5_85\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp585.csv\n",
    "\n",
    "Formato esperado do CSV:\n",
    "['minibacia','horizonte','Q_pres','Q_fut_ens','delta_q_q_ensemble']\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURAÇÕES\n",
    "# ==========================================================\n",
    "ensemble_csv = {\n",
    "    \"SSP2-4.5\": Path(r\"E:\\RESULTADOS_AB2\\SSP2-45\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp245.csv\"),\n",
    "    \"SSP5-8.5\": Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp585.csv\"),\n",
    "}\n",
    "\n",
    "out_dir = Path(r\"E:\\RESULTADOS_AB2\\_FIGS_ENSEMBLE\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COL_ID  = \"minibacia\"\n",
    "COL_H   = \"horizonte\"\n",
    "COL_QP  = \"Q_pres\"\n",
    "COL_QF  = \"Q_fut_ens\"\n",
    "COL_DLT = \"delta_q_q_ensemble\"\n",
    "\n",
    "HORIZ_ORDER = [\"2015-2040\", \"2041-2070\", \"2071-2100\", \"2015-2100\"]\n",
    "\n",
    "# Figura final\n",
    "FIG_W = 16\n",
    "FIG_H = 10\n",
    "SHOW_FLIERS = False   # se True, plota outliers como bolinhas\n",
    "WHIS = 1.5            # whiskers padrão (IQR*1.5)\n",
    "Y_PAD_FRAC = 0.08     # margem visual\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# FUNÇÕES\n",
    "# ==========================================================\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.replace(\"\\u200b\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def ensure_cols(df: pd.DataFrame, required: list[str], scen: str):\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{scen}] Colunas ausentes: {missing}\\nColunas: {list(df.columns)}\")\n",
    "\n",
    "def build_box_data(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[COL_H] = df[COL_H].astype(str).str.strip()\n",
    "\n",
    "    horizons = [h for h in HORIZ_ORDER if h in set(df[COL_H])]\n",
    "    if not horizons:\n",
    "        horizons = list(df[COL_H].unique())\n",
    "\n",
    "    data = []\n",
    "    for h in horizons:\n",
    "        v = pd.to_numeric(df.loc[df[COL_H] == h, COL_DLT], errors=\"coerce\").dropna()\n",
    "        data.append(v.values)\n",
    "\n",
    "    return horizons, data\n",
    "\n",
    "def whisker_limits(values: np.ndarray, whis: float = 1.5):\n",
    "    v = pd.to_numeric(pd.Series(values), errors=\"coerce\").dropna().values\n",
    "    if v.size == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    q1 = np.quantile(v, 0.25)\n",
    "    q3 = np.quantile(v, 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lf = q1 - whis * iqr\n",
    "    uf = q3 + whis * iqr\n",
    "\n",
    "    v_in = v[(v >= lf) & (v <= uf)]\n",
    "    if v_in.size == 0:\n",
    "        return float(np.min(v)), float(np.max(v))\n",
    "\n",
    "    return float(np.min(v_in)), float(np.max(v_in))\n",
    "\n",
    "def compute_global_ylim(data_by_scen: dict):\n",
    "    \"\"\"\n",
    "    y-limits globais coerentes entre cenários.\n",
    "    - Se SHOW_FLIERS=False: usa whiskers (ignora outliers não plotados)\n",
    "    - Se SHOW_FLIERS=True: usa min/max total (porque outliers aparecem)\n",
    "    \"\"\"\n",
    "    lows, highs = [], []\n",
    "\n",
    "    for data_list in data_by_scen.values():\n",
    "        for arr in data_list:\n",
    "            if arr is None or len(arr) == 0:\n",
    "                continue\n",
    "\n",
    "            if SHOW_FLIERS:\n",
    "                v = pd.to_numeric(pd.Series(arr), errors=\"coerce\").dropna().values\n",
    "                if v.size == 0:\n",
    "                    continue\n",
    "                lo, hi = float(np.min(v)), float(np.max(v))\n",
    "            else:\n",
    "                lo, hi = whisker_limits(arr, whis=WHIS)\n",
    "\n",
    "            if not np.isnan(lo) and not np.isnan(hi):\n",
    "                lows.append(lo)\n",
    "                highs.append(hi)\n",
    "\n",
    "    if not lows:\n",
    "        return (-1.0, 1.0)\n",
    "\n",
    "    y_min = min(min(lows), 0.0)\n",
    "    y_max = max(max(highs), 0.0)\n",
    "\n",
    "    span = (y_max - y_min) if y_max > y_min else 1.0\n",
    "    pad = Y_PAD_FRAC * span\n",
    "    return (y_min - pad, y_max + pad)\n",
    "\n",
    "def spatial_stats_full(values: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Estatísticas completas da variação espacial de ΔQ/Q (%).\n",
    "    \"\"\"\n",
    "    v = pd.to_numeric(values, errors=\"coerce\").dropna()\n",
    "    if v.empty:\n",
    "        return {\n",
    "            \"n_minibacias\": 0,\n",
    "            \"min\": np.nan, \"p05\": np.nan, \"q1\": np.nan, \"mediana\": np.nan, \"media\": np.nan,\n",
    "            \"q3\": np.nan, \"p95\": np.nan, \"max\": np.nan, \"iqr\": np.nan, \"amplitude\": np.nan,\n",
    "            \"std\": np.nan, \"cv\": np.nan, \"skew\": np.nan,\n",
    "            \"pct_pos\": np.nan, \"pct_neg\": np.nan, \"pct_zero\": np.nan,\n",
    "        }\n",
    "\n",
    "    q1 = v.quantile(0.25)\n",
    "    q3 = v.quantile(0.75)\n",
    "    media = v.mean()\n",
    "    std = v.std(ddof=1)\n",
    "    cv = (std / abs(media)) if media != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"n_minibacias\": int(v.shape[0]),\n",
    "        \"min\": float(v.min()),\n",
    "        \"p05\": float(v.quantile(0.05)),\n",
    "        \"q1\": float(q1),\n",
    "        \"mediana\": float(v.median()),\n",
    "        \"media\": float(media),\n",
    "        \"q3\": float(q3),\n",
    "        \"p95\": float(v.quantile(0.95)),\n",
    "        \"max\": float(v.max()),\n",
    "        \"iqr\": float(q3 - q1),\n",
    "        \"amplitude\": float(v.max() - v.min()),\n",
    "        \"std\": float(std),\n",
    "        \"cv\": float(cv),\n",
    "        \"skew\": float(v.skew()),\n",
    "        \"pct_pos\": float((v > 0).mean() * 100.0),\n",
    "        \"pct_neg\": float((v < 0).mean() * 100.0),\n",
    "        \"pct_zero\": float((v == 0).mean() * 100.0),\n",
    "    }\n",
    "\n",
    "def q_spatial_summary(df_h: pd.DataFrame) -> dict:\n",
    "    qp = pd.to_numeric(df_h[COL_QP], errors=\"coerce\").dropna()\n",
    "    qf = pd.to_numeric(df_h[COL_QF], errors=\"coerce\").dropna()\n",
    "    return {\n",
    "        \"Qpres_media_espacial\": float(qp.mean()) if not qp.empty else np.nan,\n",
    "        \"Qpres_mediana_espacial\": float(qp.median()) if not qp.empty else np.nan,\n",
    "        \"Qfut_media_espacial\": float(qf.mean()) if not qf.empty else np.nan,\n",
    "        \"Qfut_mediana_espacial\": float(qf.median()) if not qf.empty else np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# LEITURA\n",
    "# ==========================================================\n",
    "dfs = {}\n",
    "boxdata_by_scen = {}\n",
    "\n",
    "for scen, path in ensemble_csv.items():\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"[{scen}] CSV não encontrado: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "    df = clean_columns(df)\n",
    "    ensure_cols(df, [COL_ID, COL_H, COL_QP, COL_QF, COL_DLT], scen)\n",
    "\n",
    "    df[COL_ID] = df[COL_ID].astype(str).str.strip()\n",
    "    df[COL_H] = df[COL_H].astype(str).str.strip()\n",
    "\n",
    "    dfs[scen] = df\n",
    "\n",
    "    _, data = build_box_data(df)\n",
    "    boxdata_by_scen[scen] = data\n",
    "\n",
    "ylims = compute_global_ylim(boxdata_by_scen)\n",
    "print(\"[INFO] y-limits globais:\", ylims)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# FIGURA FINAL (2×1) – UM EIXO POR CENÁRIO, 4 BOXPLOTS NO MESMO EIXO\n",
    "# ==========================================================\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(FIG_W, FIG_H), dpi=300, sharey=True)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, scen in zip(axes, [\"SSP2-4.5\", \"SSP5-8.5\"]):\n",
    "    labels, data = build_box_data(dfs[scen])\n",
    "\n",
    "    ax.boxplot(data, labels=labels, showfliers=SHOW_FLIERS, whis=WHIS)\n",
    "    ax.axhline(0, linestyle=\"--\", linewidth=1, color=\"grey\")\n",
    "    ax.set_ylim(*ylims)\n",
    "\n",
    "    ax.set_ylabel(\"ΔQ/Q (%)\")\n",
    "    ax.set_title(f\"{scen} — Ensemble: variação espacial de ΔQ/Q (%) por horizonte\")\n",
    "\n",
    "axes[-1].set_xlabel(\"Horizonte\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_out = out_dir / \"painel_final_ensemble_2x1_quatro_horizontes.png\"\n",
    "plt.savefig(fig_out, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Figura salva:\", fig_out)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# TABELA COMPLETA DE ESTATÍSTICAS ESPACIAIS\n",
    "# ==========================================================\n",
    "rows = []\n",
    "\n",
    "for scen, df in dfs.items():\n",
    "    # garante ordem de horizontes\n",
    "    for h in HORIZ_ORDER:\n",
    "        sub = df[df[COL_H] == h].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        st = spatial_stats_full(sub[COL_DLT])\n",
    "        qs = q_spatial_summary(sub)\n",
    "\n",
    "        rows.append({\n",
    "            \"cenario\": scen,\n",
    "            \"horizonte\": h,\n",
    "            **st,\n",
    "            **qs,\n",
    "            \"Qfut_minus_Qpres_media_espacial\": (\n",
    "                qs[\"Qfut_media_espacial\"] - qs[\"Qpres_media_espacial\"]\n",
    "                if (not np.isnan(qs[\"Qfut_media_espacial\"]) and not np.isnan(qs[\"Qpres_media_espacial\"]))\n",
    "                else np.nan\n",
    "            ),\n",
    "            \"Qfut_minus_Qpres_mediana_espacial\": (\n",
    "                qs[\"Qfut_mediana_espacial\"] - qs[\"Qpres_mediana_espacial\"]\n",
    "                if (not np.isnan(qs[\"Qfut_mediana_espacial\"]) and not np.isnan(qs[\"Qpres_mediana_espacial\"]))\n",
    "                else np.nan\n",
    "            ),\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(rows)\n",
    "\n",
    "# ordenação\n",
    "stats_df[\"horiz_ord\"] = pd.Categorical(stats_df[\"horizonte\"], categories=HORIZ_ORDER, ordered=True)\n",
    "stats_df = stats_df.sort_values([\"cenario\", \"horiz_ord\"]).drop(columns=[\"horiz_ord\"])\n",
    "\n",
    "out_stats = out_dir / \"estatisticas_espaciais_ensemble_por_horizonte.csv\"\n",
    "stats_df.to_csv(out_stats, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Tabela salva:\", out_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202ca7d-303f-4af4-a096-177a4feab199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Mapa da ANOMALIA ABSOLUTA entre Abordagem 2 e Abordagem 1 (m³/s), por minibacia\n",
    "================================================================================\n",
    "\n",
    "ANOMALIA_ABS (m³/s) = Q_AB2 - Q_AB1\n",
    "\n",
    "ATUALIZAÇÕES (LEGIBILIDADE)\n",
    "---------------------------\n",
    "1) Escala DISCRETA por CLASSES FIXAS (bins) — sem rampa contínua\n",
    "2) Mesma legenda/escala para todos os painéis\n",
    "3) Gera também uma figura SEPARADA apenas para o período TOTAL (2015–2100)\n",
    "4) SUBTÍTULOS sem sobreposição: desenhados fora do mapa com ax.text (transAxes)\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patheffects\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================================================\n",
    "# 0) CONFIGURAÇÕES – AJUSTE AQUI\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Caminhos dos CSVs por abordagem ---\n",
    "CSV_AB1 = Path(r\"E:\\RESULTADOS\\SSP5_85\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp585.csv\")\n",
    "CSV_AB2 = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\Ensemble_Modelos\\delta_q_q_ensemble_por_minibacia_ssp585.csv\")\n",
    "\n",
    "# --- Nome da coluna com a vazão típica futura do ensemble (m³/s) ---\n",
    "COL_QFUT = \"Q_fut_ens\"\n",
    "\n",
    "# --- Horizonte(s) a mapear ---\n",
    "HORIZ_LABELS = [\"2015-2040\", \"2041-2070\", \"2071-2100\", \"2015-2100\"]\n",
    "HORIZ_CODES  = [\"2015_2040\", \"2041_2070\", \"2071_2100\", \"2015_2100\"]\n",
    "\n",
    "# --- Layout do mapa final ---\n",
    "# \"4\" = 2x2 (inclui Total), \"3\" = 3x1 (sem Total)\n",
    "LAYOUT = \"4\"\n",
    "\n",
    "# --- Shapefile das minibacias ---\n",
    "SHP_MINIS = Path(r\"E:\\IGUAÇU_OTTO\\6_Calibração\\minis_mgb.shp\")\n",
    "ID_FIELD  = \"ID_Mini\"\n",
    "\n",
    "# --- Camadas auxiliares (opcionais) ---\n",
    "SHP_SUB = Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\")\n",
    "SHP_CIDADES = Path(r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\")\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# --- Saídas ---\n",
    "OUT_DIR = Path(r\"E:\\IGUAÇU_OTTO\\9_Figuras_e_Tabelas_Ensemble_AB2\\Anomalia_AB2_minus_AB1\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SHAPES_DIR = OUT_DIR / \"shapes_anomalia\"\n",
    "SHAPES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "FIG_DIR = OUT_DIR / \"figuras\"\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ESCALA DISCRETA (BINS FIXOS)\n",
    "# ------------------------------------------------------------------------------\n",
    "BINS_FIXED = [-40, -30, -20, -12, -6, -2, 2, 6, 12, 20, 30, 40]\n",
    "CMAP_NAME = \"RdYlBu\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# AJUSTES DE LAYOUT PARA SUBTÍTULOS (SEM SOBREPOR)\n",
    "# ------------------------------------------------------------------------------\n",
    "SUBTITLE_Y = 1.04         # posição do subtítulo acima do eixo (transAxes)\n",
    "SUBTITLE_FONTSIZE = 11\n",
    "HSPACE_2X2 = 0.12         # espaço vertical entre linhas no GridSpec 2x2\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1) FUNÇÕES AUXILIARES\n",
    "# ==============================================================================\n",
    "\n",
    "def read_and_prepare(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    req = {\"minibacia\", \"horizonte\", COL_QFUT}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"CSV {csv_path.name} não contém colunas obrigatórias: {missing}. \"\n",
    "            f\"Colunas: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    # mini: \"mb_1\" -> 1\n",
    "    df[\"mini\"] = df[\"minibacia\"].astype(str).str.replace(\"mb_\", \"\", regex=False).astype(int)\n",
    "    df[\"horizonte\"] = df[\"horizonte\"].astype(str)\n",
    "\n",
    "    df = df[[\"mini\", \"horizonte\", COL_QFUT]].copy()\n",
    "    df = df.rename(columns={COL_QFUT: \"Q_fut\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_anomaly(df_ab1: pd.DataFrame, df_ab2: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retorna tabela com:\n",
    "      mini, horizonte, Q_ab1, Q_ab2, anomalia_abs (m³/s)\n",
    "    \"\"\"\n",
    "    m = df_ab1.merge(df_ab2, on=[\"mini\", \"horizonte\"], how=\"inner\", suffixes=(\"_ab1\", \"_ab2\"))\n",
    "    m = m.rename(columns={\"Q_fut_ab1\": \"Q_ab1\", \"Q_fut_ab2\": \"Q_ab2\"})\n",
    "    m[\"anomalia_abs\"] = m[\"Q_ab2\"] - m[\"Q_ab1\"]\n",
    "    return m\n",
    "\n",
    "\n",
    "def build_discrete_style(bins: list[float], cmap_name: str):\n",
    "    \"\"\"\n",
    "    Cria cmap discreto + norm por classes (BoundaryNorm).\n",
    "    \"\"\"\n",
    "    n_classes = len(bins) - 1\n",
    "    base = plt.get_cmap(cmap_name)\n",
    "    colors = base(np.linspace(0, 1, n_classes))\n",
    "    cmap = ListedColormap(colors)\n",
    "    norm = BoundaryNorm(bins, ncolors=n_classes, clip=True)\n",
    "    return cmap, norm\n",
    "\n",
    "\n",
    "def plot_colorbar_discrete(fig, cax, cmap, norm, bins):\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm._A = []\n",
    "\n",
    "    # ticks nos limites das classes\n",
    "    cbar = fig.colorbar(sm, cax=cax, ticks=bins, boundaries=bins, spacing=\"proportional\")\n",
    "    cbar.set_label(\"Anomalia (m³/s)\", fontsize=11)\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "\n",
    "def plot_panel(ax, gdf, title, gdf_sub, cidades, bounds, cmap, norm):\n",
    "    \"\"\"\n",
    "    Painel do mapa + subtítulo fora do mapa (sem sobrepor).\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bounds\n",
    "    dx = (xmax - xmin) * 0.01\n",
    "    dy = (ymax - ymin) * 0.01\n",
    "\n",
    "    gdf.plot(\n",
    "        column=\"anomalia_abs\",\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.08,\n",
    "    )\n",
    "\n",
    "    if gdf_sub is not None:\n",
    "        gdf_sub.boundary.plot(ax=ax, edgecolor=\"grey\", linewidth=1.2, zorder=3)\n",
    "\n",
    "    if cidades is not None and not cidades.empty:\n",
    "        cidades.plot(ax=ax, marker=\"^\", color=\"black\", markersize=40, zorder=4, linewidth=0)\n",
    "\n",
    "        for _, row in cidades.iterrows():\n",
    "            x = row.geometry.x\n",
    "            y = row.geometry.y\n",
    "            nome = row[CAMPO_NOME_CIDADE]\n",
    "            txt = ax.text(\n",
    "                x + dx, y + dy, nome,\n",
    "                fontsize=9, color=\"white\",\n",
    "                ha=\"left\", va=\"bottom\", zorder=5\n",
    "            )\n",
    "            txt.set_path_effects([\n",
    "                patheffects.Stroke(linewidth=1.5, foreground=\"black\"),\n",
    "                patheffects.Normal()\n",
    "            ])\n",
    "\n",
    "    # --- Subtítulo fora do mapa (posição relativa ao eixo) ---\n",
    "    ax.text(\n",
    "        0.5, SUBTITLE_Y, title,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=SUBTITLE_FONTSIZE,\n",
    "        bbox=dict(facecolor=\"white\", edgecolor=\"none\", pad=2.5),\n",
    "        clip_on=False,\n",
    "        zorder=10\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "\n",
    "def save_total_only_map(gdf_total, bounds, gdf_sub, cidades_sel, cmap, norm, bins, out_path: Path, suptitle: str):\n",
    "    \"\"\"\n",
    "    Figura individual apenas para o horizonte total (2015-2100).\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(9, 6), dpi=300)\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 0.06], wspace=0.03)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    cax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    plot_panel(\n",
    "        ax=ax,\n",
    "        gdf=gdf_total,\n",
    "        title=\"Horizonte 2015–2100\",\n",
    "        gdf_sub=gdf_sub,\n",
    "        cidades=cidades_sel,\n",
    "        bounds=bounds,\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "\n",
    "    plot_colorbar_discrete(fig, cax, cmap, norm, bins)\n",
    "\n",
    "    fig.suptitle(suptitle, fontsize=13, weight=\"bold\", y=0.98)\n",
    "    fig.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "    fig.savefig(out_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2) PIPELINE PRINCIPAL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n=== Lendo CSVs e calculando anomalia AB2 − AB1 ===\\n\")\n",
    "\n",
    "df1 = read_and_prepare(CSV_AB1)\n",
    "df2 = read_and_prepare(CSV_AB2)\n",
    "\n",
    "df_anom = compute_anomaly(df1, df2)\n",
    "\n",
    "# Filtrar horizontes desejados\n",
    "df_anom = df_anom[df_anom[\"horizonte\"].isin(HORIZ_LABELS)].copy()\n",
    "\n",
    "print(\"Horizontes disponíveis:\", sorted(df_anom[\"horizonte\"].unique()))\n",
    "print(\"Minibacias:\", df_anom[\"mini\"].nunique())\n",
    "\n",
    "# Ler shapefile minibacias\n",
    "minis = gpd.read_file(SHP_MINIS)\n",
    "minis[ID_FIELD] = minis[ID_FIELD].astype(int)\n",
    "\n",
    "# Camadas auxiliares\n",
    "gdf_sub = None\n",
    "cidades_sel = None\n",
    "\n",
    "# Preparar CRS base (minibacias)\n",
    "crs_minis = minis.crs\n",
    "\n",
    "if SHP_SUB.exists():\n",
    "    gdf_sub = gpd.read_file(SHP_SUB).to_crs(crs_minis)\n",
    "\n",
    "if SHP_CIDADES.exists():\n",
    "    gdf_cid = gpd.read_file(SHP_CIDADES).to_crs(crs_minis)\n",
    "    mask_cur = gdf_cid[CAMPO_NOME_CIDADE].str.contains(r\"^curitiba$\", case=False, na=False, regex=True)\n",
    "    mask_un  = gdf_cid[CAMPO_NOME_CIDADE].str.contains(\"uni[aã]o da vit\", case=False, na=False, regex=True)\n",
    "    cidades_sel = gdf_cid[mask_cur | mask_un].copy()\n",
    "\n",
    "# Gerar shapefiles por horizonte + coletar valores\n",
    "print(\"\\n=== Gerando shapefiles temáticos por horizonte ===\\n\")\n",
    "\n",
    "gdfs_h = []\n",
    "values_all = []\n",
    "\n",
    "for h_label, h_code in zip(HORIZ_LABELS, HORIZ_CODES):\n",
    "    df_h = df_anom[df_anom[\"horizonte\"] == h_label][[\"mini\", \"anomalia_abs\"]].copy()\n",
    "\n",
    "    gdf_h = minis.merge(df_h, left_on=ID_FIELD, right_on=\"mini\", how=\"left\")\n",
    "    shp_out = SHAPES_DIR / f\"minis_anomalia_ab2_minus_ab1_{h_code}.shp\"\n",
    "    gdf_h.to_file(shp_out)\n",
    "\n",
    "    print(f\"Shapefile salvo: {shp_out.name}\")\n",
    "\n",
    "    gdfs_h.append((h_label, gdf_h))\n",
    "    values_all.extend(gdf_h[\"anomalia_abs\"].dropna().tolist())\n",
    "\n",
    "if not values_all:\n",
    "    raise RuntimeError(\"Não encontrei valores de anomalia para plotagem.\")\n",
    "\n",
    "# Estilo discreto (escala fixa por bins)\n",
    "bins = BINS_FIXED\n",
    "cmap, norm = build_discrete_style(bins, CMAP_NAME)\n",
    "\n",
    "# Bounds para manter mesmo enquadramento em todos os painéis\n",
    "bounds = minis.total_bounds\n",
    "\n",
    "# ==============================================================================\n",
    "# 3) FIGURA FINAL (3 ou 4 painéis) — CLASSES FIXAS + SUBTÍTULO SEM SOBREPOR\n",
    "# ==============================================================================\n",
    "\n",
    "if LAYOUT == \"3\":\n",
    "    # 3×1 (sem Total)\n",
    "    fig = plt.figure(figsize=(18, 6), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.06], wspace=0.05)\n",
    "\n",
    "    axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "    cax = fig.add_subplot(gs[3])\n",
    "\n",
    "    for ax, (h_label, gdf_h) in zip(axes, gdfs_h[:3]):\n",
    "        plot_panel(ax, gdf_h, f\"Horizonte {h_label}\", gdf_sub, cidades_sel, bounds, cmap, norm)\n",
    "\n",
    "    plot_colorbar_discrete(fig, cax, cmap, norm, bins)\n",
    "\n",
    "    fig.suptitle(\"Anomalia absoluta de vazão (m³/s) – SSP5-8.5\", fontsize=14, weight=\"bold\", y=0.98)\n",
    "    fig.subplots_adjust(left=0.05, right=0.95, top=0.88, bottom=0.03)\n",
    "\n",
    "    fig_path = FIG_DIR / \"MAPA_ANOMALIA_ABS_AB2_minus_AB1_3paineis_classes.png\"\n",
    "    fig.savefig(fig_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "else:\n",
    "    # 2×2 (4 painéis, inclui Total)\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=300)\n",
    "\n",
    "    # hspace maior para \"abrir\" espaço entre as linhas e acomodar subtítulos fora do mapa\n",
    "    gs  = gridspec.GridSpec(\n",
    "        2, 3,\n",
    "        width_ratios=[1, 1, 0.08],\n",
    "        wspace=0.02,\n",
    "        hspace=HSPACE_2X2\n",
    "    )\n",
    "\n",
    "    ax_11 = fig.add_subplot(gs[0, 0])\n",
    "    ax_12 = fig.add_subplot(gs[0, 1])\n",
    "    ax_21 = fig.add_subplot(gs[1, 0])\n",
    "    ax_22 = fig.add_subplot(gs[1, 1])\n",
    "    cax   = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "    axes = [ax_11, ax_12, ax_21, ax_22]\n",
    "\n",
    "    for ax, (h_label, gdf_h) in zip(axes, gdfs_h):\n",
    "        plot_panel(ax, gdf_h, f\"Horizonte {h_label}\", gdf_sub, cidades_sel, bounds, cmap, norm)\n",
    "\n",
    "    plot_colorbar_discrete(fig, cax, cmap, norm, bins)\n",
    "\n",
    "    fig.suptitle(\"Anomalia absoluta de vazão (m³/s) – SSP5-8.5\", fontsize=14, weight=\"bold\", y=0.985)\n",
    "\n",
    "    # reservar topo maior para o título geral + subtítulos\n",
    "    fig.tight_layout(rect=[0.02, 0.02, 0.98, 0.90])\n",
    "\n",
    "    fig_path = FIG_DIR / \"MAPA_ANOMALIA_ABS_AB2_minus_AB1_4paineis_classes.png\"\n",
    "    fig.savefig(fig_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4) FIGURA SEPARADA — APENAS PERÍODO TOTAL (2015–2100)\n",
    "# ==============================================================================\n",
    "\n",
    "gdf_total = None\n",
    "for h_label, gdf_h in gdfs_h:\n",
    "    if h_label == \"2015-2100\":\n",
    "        gdf_total = gdf_h\n",
    "        break\n",
    "\n",
    "if gdf_total is not None:\n",
    "    fig_total_path = FIG_DIR / \"MAPA_ANOMALIA_ABS_AB2_minus_AB1_TOTAL_2015_2100_classes.png\"\n",
    "    save_total_only_map(\n",
    "        gdf_total=gdf_total,\n",
    "        bounds=bounds,\n",
    "        gdf_sub=gdf_sub,\n",
    "        cidades_sel=cidades_sel,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        bins=bins,\n",
    "        out_path=fig_total_path,\n",
    "        suptitle=\"Anomalia absoluta de vazão (m³/s) – SSP5-8.5\"\n",
    "    )\n",
    "else:\n",
    "    fig_total_path = None\n",
    "    print(\"\\n⚠️ Horizonte 2015-2100 não encontrado nos dados filtrados; não foi possível gerar a figura total.\")\n",
    "\n",
    "print(\"\\n✅ Figuras geradas com sucesso!\")\n",
    "print(\"→ Figura principal:\", fig_path)\n",
    "if fig_total_path is not None:\n",
    "    print(\"→ Figura total (2015–2100):\", fig_total_path)\n",
    "print(\"Shapefiles:\", SHAPES_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
