{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c3c81a",
   "metadata": {},
   "source": [
    "# Secao4.3 FDC Sazonalidade\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a célula **CONFIGURAÇÕES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURAÇÕES (edite se necessário)\n",
    "# A pasta raiz do projeto (por padrão, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff397d3-f4e2-41fa-80fb-69d0ec6f6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "EXPORTAÇÃO: 1 GeoPackage (.gpkg) por camada (1 layer por arquivo)\n",
    "\n",
    "- Corrige CRS ausente (heurística por bounds ou CRS fixo por camada)\n",
    "- Reprojeta tudo para EPSG:31982 (SIRGAS 2000 / UTM 22S)\n",
    "- Saneia colunas problemáticas (ex.: 'fid') para evitar FieldError\n",
    "- Salva um .gpkg por camada\n",
    "\n",
    "PLUS (hidrografia):\n",
    "- Filtra ordem <= ORDEM_MAX\n",
    "- Recorte rápido ao limite das sub-bacias (union) usando MASK vetorizado (sjoin)\n",
    "  (SEM clip geométrico — mais rápido e suficiente para plotagem)\n",
    "\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENTRADAS\n",
    "# =============================================================================\n",
    "INPUTS = {\n",
    "    \"minis_mgb\": Path(r\"E:\\IGUAÇU_OTTO\\6_Calibração\\minis_mgb.shp\"),\n",
    "    \"subbacias\": Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Subbacias.shp\"),\n",
    "    \"cidades\": Path(\n",
    "        r\"G:\\Meu Drive\\2_MESTRADO\\1_Dissertação\\Figuras\\20250516_SHAPES_FIGURA\\GEOFT_CIDADE_2016.shp\"\n",
    "    ),\n",
    "    \"estacoes\": Path(r\"E:\\IGUAÇU_OTTO\\3_Estações FLU\\Estações_Alto_IG.shp\"),\n",
    "    \"hidrografia\": Path(r\"E:\\IGUAÇU_OTTO\\Shp\\Hidrografia.shp\"),\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# SAÍDA\n",
    "# =============================================================================\n",
    "OUT_DIR = Path(r\"E:\\Base_Cartografica_GPKG\")\n",
    "CRS_FINAL_EPSG = 31982\n",
    "\n",
    "# Hidrografia\n",
    "ORDEM_MAX = 5\n",
    "CAMPO_ORDEM_PREFERIDO = \"nuordemcda\"  # se não existir, o código tenta detectar automaticamente\n",
    "\n",
    "# Se quiser FORÇAR CRS de origem quando estiver ausente (mais seguro):\n",
    "CRS_ORIGEM_FIXO_SEM_CRS: Dict[str, int] = {\n",
    "    # \"estacoes\": 31982,\n",
    "    # \"hidrografia\": 31982,\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÕES\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def bounds_look_geographic(bounds: Tuple[float, float, float, float]) -> bool:\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    return (\n",
    "        -180 <= minx <= 180 and -180 <= maxx <= 180 and\n",
    "        -90 <= miny <= 90 and -90 <= maxy <= 90\n",
    "    )\n",
    "\n",
    "\n",
    "def guess_crs_if_missing(gdf: gpd.GeoDataFrame) -> int:\n",
    "    b = tuple(gdf.total_bounds)\n",
    "    return 4326 if bounds_look_geographic(b) else 31982\n",
    "\n",
    "\n",
    "def sanitize_gdf(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Saneia campos para escrita em GeoPackage via pyogrio:\n",
    "    - renomeia colunas que costumam conflitar (fid, ogc_fid)\n",
    "    - remove colunas duplicadas\n",
    "    - remove geometrias nulas\n",
    "    \"\"\"\n",
    "    gdf = gdf.copy()\n",
    "    gdf = gdf[~gdf.geometry.isna()].copy()\n",
    "\n",
    "    def _rename_if_exists(col_lower: str, new_base: str):\n",
    "        nonlocal gdf\n",
    "        for c in list(gdf.columns):\n",
    "            if c.lower() == col_lower:\n",
    "                new_name = new_base\n",
    "                i = 1\n",
    "                while new_name in gdf.columns:\n",
    "                    i += 1\n",
    "                    new_name = f\"{new_base}{i}\"\n",
    "                gdf = gdf.rename(columns={c: new_name})\n",
    "\n",
    "    _rename_if_exists(\"fid\", \"fid_src\")\n",
    "    _rename_if_exists(\"ogc_fid\", \"ogc_fid_src\")\n",
    "\n",
    "    if not gdf.columns.is_unique:\n",
    "        gdf = gdf.loc[:, ~gdf.columns.duplicated()].copy()\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def load_fix_reproject(path: Path, layer_name: str) -> gpd.GeoDataFrame:\n",
    "    gdf = gpd.read_file(path)\n",
    "\n",
    "    if gdf.crs is None:\n",
    "        if layer_name in CRS_ORIGEM_FIXO_SEM_CRS:\n",
    "            src = CRS_ORIGEM_FIXO_SEM_CRS[layer_name]\n",
    "            print(f\"[CRS] {path.name}: CRS ausente -> FORÇADO EPSG:{src}\")\n",
    "        else:\n",
    "            src = guess_crs_if_missing(gdf)\n",
    "            print(f\"[CRS] {path.name}: CRS ausente -> heurística EPSG:{src}\")\n",
    "        gdf = gdf.set_crs(epsg=src, allow_override=True)\n",
    "\n",
    "    if gdf.crs.to_epsg() != CRS_FINAL_EPSG:\n",
    "        gdf = gdf.to_crs(epsg=CRS_FINAL_EPSG)\n",
    "        print(f\"[CRS] {path.name}: reprojetado -> EPSG:{CRS_FINAL_EPSG}\")\n",
    "    else:\n",
    "        print(f\"[CRS] {path.name}: já está -> EPSG:{CRS_FINAL_EPSG}\")\n",
    "\n",
    "    return sanitize_gdf(gdf)\n",
    "\n",
    "\n",
    "def detectar_campo_ordem(gdf_h: gpd.GeoDataFrame, preferido: str | None) -> str:\n",
    "    cols = list(gdf_h.columns)\n",
    "    if preferido and preferido in cols:\n",
    "        return preferido\n",
    "\n",
    "    lower_map = {c.lower(): c for c in cols}\n",
    "    candidatos = [\n",
    "        \"nuordemdca\", \"nuordemcda\", \"nuordem\", \"ordem\", \"order\", \"ord\",\n",
    "        \"strahler\", \"str_order\", \"ord_strah\"\n",
    "    ]\n",
    "    for c in candidatos:\n",
    "        if c.lower() in lower_map:\n",
    "            return lower_map[c.lower()]\n",
    "\n",
    "    heur = [c for c in cols if (\"ord\" in c.lower()) or (\"strah\" in c.lower())]\n",
    "    if heur:\n",
    "        return heur[0]\n",
    "\n",
    "    raise KeyError(\"Não encontrei campo de ordem na hidrografia. Inspecione os campos do arquivo.\")\n",
    "\n",
    "\n",
    "def filtrar_recortar_hidrografia_rapido(\n",
    "    gdf_h: gpd.GeoDataFrame,\n",
    "    gdf_sub: gpd.GeoDataFrame,\n",
    "    ordem_max: int,\n",
    "    campo_ordem_preferido: str | None,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Hidrografia para plot (rápido):\n",
    "    1) Filtra ordem <= ordem_max\n",
    "    2) Recorte rápido por:\n",
    "       - bbox do polígono união\n",
    "       - spatial join (predicate intersects) com a máscara (sem recortar geometria)\n",
    "    \"\"\"\n",
    "    campo = detectar_campo_ordem(gdf_h, campo_ordem_preferido)\n",
    "\n",
    "    gdf = gdf_h.copy()\n",
    "    gdf[\"_ord\"] = pd.to_numeric(gdf[campo], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    gdf = gdf[(gdf[\"_ord\"] >= 1) & (gdf[\"_ord\"] <= ordem_max)].copy()\n",
    "\n",
    "    clip_geom = gdf_sub.unary_union.buffer(0)  # robustez\n",
    "    minx, miny, maxx, maxy = clip_geom.bounds\n",
    "\n",
    "    # bbox primeiro (reduz muito)\n",
    "    gdf = gdf.cx[minx:maxx, miny:maxy].copy()\n",
    "\n",
    "    # máscara como GeoDataFrame\n",
    "    mask = gpd.GeoDataFrame(geometry=[clip_geom], crs=gdf.crs)\n",
    "\n",
    "    # spatial join vetorizado (rápido)\n",
    "    gdf = gpd.sjoin(gdf, mask, how=\"inner\", predicate=\"intersects\")\n",
    "    gdf = gdf.drop(columns=[\"index_right\", \"_ord\"], errors=\"ignore\")\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def write_single_layer_gpkg(gdf: gpd.GeoDataFrame, out_gpkg: Path, layer: str) -> None:\n",
    "    if out_gpkg.exists():\n",
    "        out_gpkg.unlink()\n",
    "\n",
    "    gdf2 = sanitize_gdf(gdf)\n",
    "\n",
    "    # NÃO especificar engine -> usa pyogrio automaticamente no seu ambiente\n",
    "    gdf2.to_file(out_gpkg, layer=layer, driver=\"GPKG\", index=False)\n",
    "    print(f\"[OK] {out_gpkg.name} | layer='{layer}' | feats={len(gdf2)}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUT_DIR)\n",
    "\n",
    "    # 1) Carrega subbacias primeiro (para máscara do recorte)\n",
    "    if not INPUTS[\"subbacias\"].exists():\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {INPUTS['subbacias']}\")\n",
    "    gdf_sub = load_fix_reproject(INPUTS[\"subbacias\"], \"subbacias\")\n",
    "\n",
    "    # 2) Exporta camadas (hidrografia já sai filtrada/recortada rápida)\n",
    "    for layer_name, shp_path in INPUTS.items():\n",
    "        if not shp_path.exists():\n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {shp_path}\")\n",
    "\n",
    "        gdf = load_fix_reproject(shp_path, layer_name)\n",
    "\n",
    "        if layer_name == \"hidrografia\":\n",
    "            gdf = filtrar_recortar_hidrografia_rapido(\n",
    "                gdf_h=gdf,\n",
    "                gdf_sub=gdf_sub,\n",
    "                ordem_max=ORDEM_MAX,\n",
    "                campo_ordem_preferido=CAMPO_ORDEM_PREFERIDO,\n",
    "            )\n",
    "            print(f\"[HIDRO] Hidrografia pronta para plot: ordem<= {ORDEM_MAX} + recorte rápido (sjoin)\")\n",
    "\n",
    "        out_gpkg = OUT_DIR / f\"{layer_name}.gpkg\"\n",
    "        write_single_layer_gpkg(gdf, out_gpkg, layer=layer_name)\n",
    "\n",
    "    print(f\"\\n✅ Concluído! GPKGs salvos em: {OUT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496f890-db5c-4d94-9a1b-675ffd1d7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Script: FDC por Estação — Observado (REF) + Simulado Futuro (Modelos + Ensemble)\n",
    "#          (Ensemble = média por posição/quantil; NÃO média diária no tempo)\n",
    "#\n",
    "# O QUE FOI CORRIGIDO:\n",
    "# - O \"ENSEMBLE_MEAN\" agora é calculado no espaço da excedência:\n",
    "#   1) Para cada horizonte, calcula-se a FDC (quantis) de cada modelo\n",
    "#   2) Para cada excedência (posição), calcula-se a média entre modelos\n",
    "#\n",
    "# Vantagem: evita o artefato de elevar as mínimas por dessincronização temporal\n",
    "# entre modelos (média diária antes de ordenar).\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURAÇÕES\n",
    "# =============================================================================\n",
    "\n",
    "# Projeções\n",
    "RAIZ_PROJECOES = Path(r\"E:\\IGUAÇU_OTTO\\7_Projeções_ssp585 - Clima\")\n",
    "SHIFT_ANOS = 80\n",
    "\n",
    "# Observado (ascii_mgb)\n",
    "OBS_DIR = Path(r\"E:\\IGUAÇU_OTTO\\3_Estações FLU\\Input\\ascii_mgb\")\n",
    "\n",
    "# Mapeamento estação -> minibacia\n",
    "MAPEAMENTO_CSV = Path(r\"E:\\IGUAÇU_OTTO\\3_Estações FLU\\Estações_mini.csv\")\n",
    "SEP_MAP = \";\"\n",
    "\n",
    "# Saída\n",
    "OUT_DIR = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\FDC_Projecoes_ssp585\")\n",
    "SEP_OUT = \";\"\n",
    "ENC_OUT = \"utf-8\"\n",
    "\n",
    "# Excedência\n",
    "EXC_PCT = np.arange(0.0, 100.0 + 1e-9, 1.0)\n",
    "\n",
    "# REF observada\n",
    "REF_OBS = (\"1980-01-01\", \"2023-12-31\")\n",
    "\n",
    "# 4 horizontes futuros\n",
    "HORIZONTES: Dict[str, Tuple[str, str]] = {\n",
    "    \"CURTO_2015_2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"MEDIO_2041_2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"LONGO_2071_2100\": (\"2071-01-01\", \"2100-12-31\"),\n",
    "    \"TOTAL_2015_2100\": (\"2015-01-01\", \"2100-12-31\"),\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÕES\n",
    "# =============================================================================\n",
    "\n",
    "def garantir_pasta(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def listar_modelos(raiz: Path) -> List[Path]:\n",
    "    modelos: List[Path] = []\n",
    "    for p in sorted(raiz.iterdir()):\n",
    "        if p.is_dir() and (p / \"Output\").exists():\n",
    "            modelos.append(p)\n",
    "    return modelos\n",
    "\n",
    "\n",
    "def ler_txt_mgb(caminho: Path) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Lê arquivo MGB (dia mes ano valor). Trata -1 como NaN.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        caminho,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=[\"dia\", \"mes\", \"ano\", \"valor\"],\n",
    "        dtype=str,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    df[\"valor\"] = df[\"valor\"].str.replace(\",\", \"\", regex=False).astype(float)\n",
    "    df.loc[df[\"valor\"] == -1, \"valor\"] = np.nan\n",
    "\n",
    "    df[\"data\"] = pd.to_datetime(\n",
    "        df.rename(columns={\"ano\": \"year\", \"mes\": \"month\", \"dia\": \"day\"})[[\"year\", \"month\", \"day\"]],\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    df = df.dropna(subset=[\"data\"]).set_index(\"data\").sort_index()\n",
    "    s = df[\"valor\"]\n",
    "    s.name = caminho.stem\n",
    "    return s\n",
    "\n",
    "\n",
    "def aplicar_shift_anos(s: pd.Series, shift_anos: int) -> pd.Series:\n",
    "    s2 = s.copy()\n",
    "    s2.index = s2.index + pd.DateOffset(years=shift_anos)\n",
    "    return s2\n",
    "\n",
    "\n",
    "def recortar(s: pd.Series, ini: str, fim: str) -> pd.Series:\n",
    "    return s.loc[(s.index >= pd.Timestamp(ini)) & (s.index <= pd.Timestamp(fim))]\n",
    "\n",
    "\n",
    "def calcular_fdc(s: pd.Series, exc_pct: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    FDC via quantis:\n",
    "      excedência p% -> quantil (1 - p)\n",
    "    \"\"\"\n",
    "    x = s.dropna().values\n",
    "    if x.size == 0:\n",
    "        return pd.DataFrame({\"exc\": exc_pct, \"q\": np.nan})\n",
    "\n",
    "    p = exc_pct / 100.0\n",
    "    q = np.quantile(x, 1.0 - p)\n",
    "    return pd.DataFrame({\"exc\": exc_pct, \"q\": q})\n",
    "\n",
    "\n",
    "def ensemble_fdc_por_posicao(\n",
    "    fdc_por_modelo: Dict[str, pd.DataFrame],\n",
    "    metodo: str = \"mean\",\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Recebe dict: modelo -> DataFrame FDC com colunas ['exc','q'] (mesma grade de exc)\n",
    "    Retorna DataFrame com ['exc','q'] do ensemble por posição (por excedência).\n",
    "\n",
    "    metodo:\n",
    "      - \"mean\": média entre modelos em cada excedência\n",
    "      - \"median\": mediana entre modelos em cada excedência (mais robusta)\n",
    "    \"\"\"\n",
    "    if not fdc_por_modelo:\n",
    "        return None\n",
    "\n",
    "    # monta matriz (linhas=excedências, colunas=modelos)\n",
    "    cols = {}\n",
    "    exc_ref = None\n",
    "    for m, df in fdc_por_modelo.items():\n",
    "        if exc_ref is None:\n",
    "            exc_ref = df[\"exc\"].to_numpy()\n",
    "        cols[m] = df[\"q\"].to_numpy()\n",
    "\n",
    "    mat = pd.DataFrame(cols)\n",
    "    if metodo.lower() == \"median\":\n",
    "        q_ens = mat.median(axis=1, skipna=True).to_numpy()\n",
    "    else:\n",
    "        q_ens = mat.mean(axis=1, skipna=True).to_numpy()\n",
    "\n",
    "    out = pd.DataFrame({\"exc\": exc_ref, \"q\": q_ens})\n",
    "    return out\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main() -> None:\n",
    "    garantir_pasta(OUT_DIR)\n",
    "\n",
    "    map_df = pd.read_csv(MAPEAMENTO_CSV, sep=SEP_MAP, dtype=str).fillna(\"\")\n",
    "    obrig = {\"estacao_obs\", \"codigo_mini\", \"nome_estacao\"}\n",
    "    if not obrig.issubset(map_df.columns):\n",
    "        raise ValueError(f\"CSV de mapeamento deve conter colunas: {sorted(obrig)}\")\n",
    "\n",
    "    modelos = listar_modelos(RAIZ_PROJECOES)\n",
    "    if not modelos:\n",
    "        raise FileNotFoundError(f\"Não encontrei pastas de modelos com Output/ em {RAIZ_PROJECOES}\")\n",
    "\n",
    "    all_rows: List[pd.DataFrame] = []\n",
    "\n",
    "    for _, row in map_df.iterrows():\n",
    "        estacao = row[\"estacao_obs\"].strip()\n",
    "        mini = row[\"codigo_mini\"].strip()\n",
    "        nome = row[\"nome_estacao\"].strip()\n",
    "\n",
    "        if not estacao or not mini:\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Observado (REF)\n",
    "        # -----------------------------\n",
    "        arq_obs = OBS_DIR / f\"{estacao}.txt\"\n",
    "        if not arq_obs.exists():\n",
    "            print(f\"⚠️ Observado não encontrado: {arq_obs.name}. Pulando {estacao}.\")\n",
    "            continue\n",
    "\n",
    "        s_obs = ler_txt_mgb(arq_obs)\n",
    "        s_obs_ref = recortar(s_obs, *REF_OBS)\n",
    "        fdc_obs_ref = calcular_fdc(s_obs_ref, EXC_PCT).rename(columns={\"q\": \"q_obs_ref\"})\n",
    "        fdc_obs_ref.insert(0, \"horizonte\", \"REF_1980_2023\")\n",
    "        fdc_obs_ref.insert(0, \"modelo\", \"OBS\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Simulado por modelo (futuro)\n",
    "        # -----------------------------\n",
    "        sims: Dict[str, pd.Series] = {}\n",
    "        for pasta_modelo in modelos:\n",
    "            mname = pasta_modelo.name\n",
    "            arq_sim = pasta_modelo / \"Output\" / f\"SIM_MC_{mini}.TXT\"\n",
    "            if not arq_sim.exists():\n",
    "                continue\n",
    "\n",
    "            s = ler_txt_mgb(arq_sim)\n",
    "            s = aplicar_shift_anos(s, SHIFT_ANOS)\n",
    "            sims[mname] = s\n",
    "\n",
    "        if not sims:\n",
    "            print(f\"⚠️ Nenhum simulado encontrado para {estacao} (SIM_MC_{mini}).\")\n",
    "            continue\n",
    "\n",
    "        saidas: List[pd.DataFrame] = []\n",
    "\n",
    "        # -----------------------------\n",
    "        # FDCs dos modelos por horizonte\n",
    "        # -----------------------------\n",
    "        for horiz, (ini, fim) in HORIZONTES.items():\n",
    "            # 1) calcula FDC de cada modelo nesse horizonte\n",
    "            fdc_por_modelo: Dict[str, pd.DataFrame] = {}\n",
    "            for mname, s in sims.items():\n",
    "                s_h = recortar(s, ini, fim)\n",
    "                fdc_m = calcular_fdc(s_h, EXC_PCT)\n",
    "                fdc_por_modelo[mname] = fdc_m\n",
    "\n",
    "                # salva a curva individual\n",
    "                fdc_m_out = fdc_m.rename(columns={\"q\": \"q_sim\"}).copy()\n",
    "                fdc_m_out.insert(0, \"horizonte\", horiz)\n",
    "                fdc_m_out.insert(0, \"modelo\", mname)\n",
    "                saidas.append(fdc_m_out)\n",
    "\n",
    "            # 2) ensemble por posição (média dos quantis)\n",
    "            fdc_ens = ensemble_fdc_por_posicao(fdc_por_modelo, metodo=\"mean\")\n",
    "            if fdc_ens is not None:\n",
    "                fdc_ens_out = fdc_ens.rename(columns={\"q\": \"q_sim\"}).copy()\n",
    "                fdc_ens_out.insert(0, \"horizonte\", horiz)\n",
    "                fdc_ens_out.insert(0, \"modelo\", \"ENSEMBLE_MEAN_POS\")\n",
    "                saidas.append(fdc_ens_out)\n",
    "\n",
    "        df_sim = pd.concat(saidas, ignore_index=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Junta curva observada (REF) por excedência\n",
    "        # -----------------------------\n",
    "        df_sim = df_sim.merge(\n",
    "            fdc_obs_ref[[\"exc\", \"q_obs_ref\"]],\n",
    "            on=\"exc\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # metadados\n",
    "        df_sim.insert(0, \"codigo_mini\", mini)\n",
    "        df_sim.insert(0, \"nome_estacao\", nome)\n",
    "        df_sim.insert(0, \"estacao_obs\", estacao)\n",
    "\n",
    "        # Também salva a FDC observada REF como bloco próprio\n",
    "        df_obs_out = fdc_obs_ref.copy()\n",
    "        df_obs_out.insert(0, \"codigo_mini\", mini)\n",
    "        df_obs_out.insert(0, \"nome_estacao\", nome)\n",
    "        df_obs_out.insert(0, \"estacao_obs\", estacao)\n",
    "\n",
    "        # concatena obs_ref (como bloco separado) + futuros (ensure colunas compatíveis)\n",
    "        df_obs_block = df_obs_out.assign(q_sim=np.nan)\n",
    "        df_out = pd.concat([df_obs_block, df_sim], ignore_index=True)\n",
    "\n",
    "        out_file = OUT_DIR / f\"FDC_{estacao}_obs_ref_e_futuro.csv\"\n",
    "        df_out.to_csv(out_file, sep=SEP_OUT, index=False, encoding=ENC_OUT)\n",
    "\n",
    "        all_rows.append(df_out)\n",
    "        print(f\"✅ OK: {estacao} | modelos={len(sims)} | {out_file.name}\")\n",
    "\n",
    "    if all_rows:\n",
    "        df_all = pd.concat(all_rows, ignore_index=True)\n",
    "        out_all = OUT_DIR / \"FDC_consolidado_obs_ref_e_futuro.csv\"\n",
    "        df_all.to_csv(out_all, sep=SEP_OUT, index=False, encoding=ENC_OUT)\n",
    "        print(f\"\\n✅ Consolidado salvo: {out_all}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dff04-692e-40d0-afc7-7b7f41e0d4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "SAZONALIDADE — modelos individuais + ensemble + observado\n",
    "\n",
    "Saídas:\n",
    "1) CSV consolidado (formato longo | climatologia mensal por horizonte):\n",
    "   SAZONALIDADE_mensal_consolidada.csv\n",
    "\n",
    "2) CSV individual por estação (formato longo | climatologia mensal por horizonte):\n",
    "   por_estacao/SAZONALIDADE_<estacao_obs>.csv\n",
    "\n",
    "3) CSV PADRÃO (formato wide, para plot rápido no mapa):\n",
    "   SAZONALIDADE_mensal_padrao_obs_sim.csv\n",
    "\n",
    "4) CSV INTERANUAL (OBS + ENSEMBLE + GCM) — para INSETS (violino/box interanual):\n",
    "   SAZONALIDADE_boxplot_interanual_obs_ensemble.csv  (mantido o nome por compatibilidade)\n",
    "\n",
    "5) NOVO — SÉRIE MENSAL COMPLETA (OBS + ENSEMBLE + GCM), análogo ao consolidado da FDC:\n",
    "   SAZONALIDADE_mensal_serie_consolidada.csv\n",
    "   por_estacao_mensal_serie/SAZONALIDADE_SERIE_MENSAL_<estacao_obs>.csv\n",
    "\n",
    "Formatos:\n",
    "A) Climatologia (longo):\n",
    "   estacao_obs;codigo_mini;horizonte;fonte;modelo;mes;Q_medio\n",
    "\n",
    "B) Padrão wide:\n",
    "   estacao_obs;mes;q_obs_ref_mensal;q_sim_mensal\n",
    "\n",
    "C) Interanual (ano, mes):\n",
    "   estacao_obs;codigo_mini;horizonte;fonte;modelo;ano;mes;Q_mensal\n",
    "\n",
    "D) Série mensal completa (ano, mes):\n",
    "   estacao_obs;codigo_mini;horizonte;fonte;modelo;ano;mes;Q_mensal\n",
    "\n",
    "onde:\n",
    "- fonte = OBS | GCM | ENSEMBLE\n",
    "- modelo = nome do GCM (pasta) | ENSEMBLE_MEAN | OBS\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIG\n",
    "# =============================================================================\n",
    "RAIZ_PROJECOES = Path(r\"E:\\IGUAÇU_OTTO\\7_Projeções_ssp585 - Clima\")\n",
    "OBS_DIR = Path(r\"E:\\IGUAÇU_OTTO\\3_Estações FLU\\Input\\ascii_mgb\")\n",
    "MAPEAMENTO_CSV = Path(r\"E:\\IGUAÇU_OTTO\\3_Estações FLU\\Estações_mini.csv\")\n",
    "\n",
    "OUT_DIR = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\SAZONALIDADE\")\n",
    "OUT_DIR_EST = OUT_DIR / \"por_estacao\"\n",
    "OUT_CSV_ALL = OUT_DIR / \"SAZONALIDADE_mensal_consolidada.csv\"\n",
    "\n",
    "# Saída padronizada (wide)\n",
    "OUT_CSV_PADRAO = OUT_DIR / \"SAZONALIDADE_mensal_padrao_obs_sim.csv\"\n",
    "\n",
    "# Saída interanual (AGORA: OBS + ENSEMBLE + GCM)\n",
    "OUT_CSV_BOX = OUT_DIR / \"SAZONALIDADE_boxplot_interanual_obs_ensemble.csv\"\n",
    "\n",
    "# NOVO: série mensal completa (OBS + ENSEMBLE + GCM) — análogo ao consolidado da FDC\n",
    "OUT_CSV_MENSAL_SERIE = OUT_DIR / \"SAZONALIDADE_mensal_serie_consolidada.csv\"\n",
    "OUT_DIR_EST_SERIE = OUT_DIR / \"por_estacao_mensal_serie\"\n",
    "\n",
    "SEP = \";\"\n",
    "ENC = \"utf-8\"\n",
    "\n",
    "SHIFT_ANOS = 80\n",
    "\n",
    "# Observado (referência)\n",
    "REF_OBS = (\"1980-01-01\", \"2023-12-31\")\n",
    "\n",
    "# Horizontes (4)\n",
    "HORIZONTES: Dict[str, Tuple[str, str]] = {\n",
    "    \"CURTO_2015_2040\": (\"2015-01-01\", \"2040-12-31\"),\n",
    "    \"MEDIO_2041_2070\": (\"2041-01-01\", \"2070-12-31\"),\n",
    "    \"LONGO_2071_2100\": (\"2071-01-01\", \"2100-12-31\"),\n",
    "    \"TOTAL_2015_2100\": (\"2015-01-01\", \"2100-12-31\"),\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# CSV PADRÃO (wide): qual simulado entra na coluna q_sim_mensal?\n",
    "# (independente do interanual e da série mensal)\n",
    "# =============================================================================\n",
    "PADRAO_HORIZ_OBS = \"REF_1980_2023\"\n",
    "PADRAO_FONTE_OBS = \"OBS\"\n",
    "PADRAO_MODELO_OBS = \"OBS\"\n",
    "\n",
    "PADRAO_HORIZ_SIM = \"TOTAL_2015_2100\"   # escolha um dos HORIZONTES\n",
    "PADRAO_FONTE_SIM = \"ENSEMBLE\"          # \"ENSEMBLE\" (recomendado) ou \"GCM\"\n",
    "PADRAO_MODELO_SIM = \"ENSEMBLE_MEAN\"    # se fonte=GCM, coloque o nome exato da pasta do modelo\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÕES\n",
    "# =============================================================================\n",
    "def garantir_pasta(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def listar_modelos(raiz: Path) -> List[Path]:\n",
    "    modelos = []\n",
    "    for p in sorted(raiz.iterdir()):\n",
    "        if p.is_dir() and (p / \"Output\").exists():\n",
    "            modelos.append(p)\n",
    "    return modelos\n",
    "\n",
    "def ler_txt_mgb(caminho: Path) -> pd.Series:\n",
    "    df = pd.read_csv(\n",
    "        caminho, sep=r\"\\s+\", header=None,\n",
    "        names=[\"dia\", \"mes\", \"ano\", \"valor\"],\n",
    "        dtype=str, engine=\"python\"\n",
    "    )\n",
    "    df[\"valor\"] = df[\"valor\"].str.replace(\",\", \"\", regex=False).astype(float)\n",
    "    df.loc[df[\"valor\"] == -1, \"valor\"] = np.nan\n",
    "\n",
    "    df[\"data\"] = pd.to_datetime(\n",
    "        df.rename(columns={\"ano\": \"year\", \"mes\": \"month\", \"dia\": \"day\"})[[\"year\", \"month\", \"day\"]],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df = df.dropna(subset=[\"data\"]).set_index(\"data\").sort_index()\n",
    "    return df[\"valor\"]\n",
    "\n",
    "def aplicar_shift_anos(s: pd.Series, shift_anos: int) -> pd.Series:\n",
    "    s2 = s.copy()\n",
    "    s2.index = s2.index + pd.DateOffset(years=shift_anos)\n",
    "    return s2\n",
    "\n",
    "def recortar(s: pd.Series, ini: str, fim: str) -> pd.Series:\n",
    "    return s.loc[(s.index >= pd.Timestamp(ini)) & (s.index <= pd.Timestamp(fim))]\n",
    "\n",
    "def climatologia_mensal(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Climatologia mensal: média de TODOS os dias por mês (1..12) no intervalo.\n",
    "    \"\"\"\n",
    "    x = s.dropna()\n",
    "    if x.empty:\n",
    "        return pd.Series(index=range(1, 13), dtype=float)\n",
    "\n",
    "    df = x.to_frame(\"q\")\n",
    "    df[\"mes\"] = df.index.month\n",
    "    clim = df.groupby(\"mes\")[\"q\"].mean().reindex(range(1, 13))\n",
    "    return clim\n",
    "\n",
    "def ensemble_diario(series_por_modelo: Dict[str, pd.Series]) -> pd.Series:\n",
    "    if not series_por_modelo:\n",
    "        return pd.Series(dtype=float)\n",
    "    df = pd.concat(series_por_modelo, axis=1)\n",
    "    ens = df.mean(axis=1, skipna=True)\n",
    "    ens.name = \"ENSEMBLE_MEAN\"\n",
    "    return ens\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Médias mensais por ANO (para boxplot/violino interanual)\n",
    "# -----------------------------------------------------------------------------\n",
    "def medias_mensais_por_ano(s: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retorna médias mensais por ano.\n",
    "    Saída: colunas [ano, mes, Q_mensal]\n",
    "    \"\"\"\n",
    "    x = s.dropna()\n",
    "    if x.empty:\n",
    "        return pd.DataFrame(columns=[\"ano\", \"mes\", \"Q_mensal\"])\n",
    "\n",
    "    df = x.to_frame(\"q\")\n",
    "    df[\"ano\"] = df.index.year\n",
    "    df[\"mes\"] = df.index.month\n",
    "\n",
    "    out = (\n",
    "        df.groupby([\"ano\", \"mes\"])[\"q\"]\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          .rename(columns={\"q\": \"Q_mensal\"})\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# NOVO: Série mensal completa (um valor por ano-mês) — análogo ao que você quer\n",
    "# -----------------------------------------------------------------------------\n",
    "def serie_mensal(s: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Série mensal: média de todos os dias em cada mês (um valor por ano-mês).\n",
    "    Saída: colunas [ano, mes, Q_mensal]\n",
    "    \"\"\"\n",
    "    x = s.dropna()\n",
    "    if x.empty:\n",
    "        return pd.DataFrame(columns=[\"ano\", \"mes\", \"Q_mensal\"])\n",
    "\n",
    "    sm = x.resample(\"MS\").mean()  # 1 valor por mês (início do mês)\n",
    "    out = sm.to_frame(\"Q_mensal\").reset_index().rename(columns={\"index\": \"data\"})\n",
    "    # em alguns pandas, reset_index cria coluna com o nome do índice (\"data\") ou \"index\"\n",
    "    if \"data\" not in out.columns:\n",
    "        out = out.rename(columns={\"index\": \"data\"})\n",
    "    out[\"ano\"] = out[\"data\"].dt.year.astype(int)\n",
    "    out[\"mes\"] = out[\"data\"].dt.month.astype(int)\n",
    "    out = out.drop(columns=[\"data\"])\n",
    "    return out[[\"ano\", \"mes\", \"Q_mensal\"]]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CSV padrão wide (Obs vs Sim)\n",
    "# =============================================================================\n",
    "def gerar_csv_padrao(df_all: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Entrada: df_all no formato longo:\n",
    "      estacao_obs;codigo_mini;horizonte;fonte;modelo;mes;Q_medio\n",
    "\n",
    "    Saída: formato wide:\n",
    "      estacao_obs;mes;q_obs_ref_mensal;q_sim_mensal\n",
    "    \"\"\"\n",
    "    df = df_all.copy()\n",
    "\n",
    "    df[\"estacao_obs\"] = df[\"estacao_obs\"].astype(str).str.strip()\n",
    "    df[\"mes\"] = pd.to_numeric(df[\"mes\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"Q_medio\"] = pd.to_numeric(df[\"Q_medio\"], errors=\"coerce\")\n",
    "\n",
    "    obs = df[\n",
    "        (df[\"horizonte\"] == PADRAO_HORIZ_OBS) &\n",
    "        (df[\"fonte\"] == PADRAO_FONTE_OBS) &\n",
    "        (df[\"modelo\"] == PADRAO_MODELO_OBS)\n",
    "    ][[\"estacao_obs\", \"mes\", \"Q_medio\"]].rename(columns={\"Q_medio\": \"q_obs_ref_mensal\"})\n",
    "\n",
    "    sim = df[\n",
    "        (df[\"horizonte\"] == PADRAO_HORIZ_SIM) &\n",
    "        (df[\"fonte\"] == PADRAO_FONTE_SIM) &\n",
    "        (df[\"modelo\"] == PADRAO_MODELO_SIM)\n",
    "    ][[\"estacao_obs\", \"mes\", \"Q_medio\"]].rename(columns={\"Q_medio\": \"q_sim_mensal\"})\n",
    "\n",
    "    out = pd.merge(obs, sim, on=[\"estacao_obs\", \"mes\"], how=\"outer\")\n",
    "\n",
    "    ests = sorted(out[\"estacao_obs\"].dropna().unique())\n",
    "    grid = pd.MultiIndex.from_product([ests, range(1, 13)], names=[\"estacao_obs\", \"mes\"]).to_frame(index=False)\n",
    "    out = pd.merge(grid, out, on=[\"estacao_obs\", \"mes\"], how=\"left\")\n",
    "\n",
    "    return out.sort_values([\"estacao_obs\", \"mes\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "def main():\n",
    "    garantir_pasta(OUT_DIR)\n",
    "    garantir_pasta(OUT_DIR_EST)\n",
    "    garantir_pasta(OUT_DIR_EST_SERIE)\n",
    "\n",
    "    map_df = pd.read_csv(MAPEAMENTO_CSV, sep=SEP, dtype=str).fillna(\"\")\n",
    "    modelos = listar_modelos(RAIZ_PROJECOES)\n",
    "    if not modelos:\n",
    "        raise FileNotFoundError(f\"Nenhuma pasta de modelo com Output/ encontrada em {RAIZ_PROJECOES}\")\n",
    "\n",
    "    rows_all: List[dict] = []           # climatologia (longo)\n",
    "    rows_box: List[dict] = []           # interanual (ano, mes) p/ violin/box\n",
    "    rows_mensal_serie: List[dict] = []  # NOVO: série mensal completa (ano, mes)\n",
    "\n",
    "    for _, row in map_df.iterrows():\n",
    "        estacao = row.get(\"estacao_obs\", \"\").strip()\n",
    "        mini = row.get(\"codigo_mini\", \"\").strip()\n",
    "        if not estacao or not mini:\n",
    "            continue\n",
    "\n",
    "        rows_est: List[dict] = []        # climatologia por estação\n",
    "        rows_est_serie: List[dict] = []  # série mensal por estação\n",
    "\n",
    "        # ---- Observado REF ----\n",
    "        arq_obs = OBS_DIR / f\"{estacao}.txt\"\n",
    "        if arq_obs.exists():\n",
    "            s_obs = ler_txt_mgb(arq_obs)\n",
    "\n",
    "            # climatologia mensal OBS (REF)\n",
    "            clim_obs = climatologia_mensal(recortar(s_obs, *REF_OBS))\n",
    "            for mes, val in clim_obs.items():\n",
    "                rows_est.append({\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": \"REF_1980_2023\",\n",
    "                    \"fonte\": \"OBS\",\n",
    "                    \"modelo\": \"OBS\",\n",
    "                    \"mes\": int(mes),\n",
    "                    \"Q_medio\": float(val) if pd.notna(val) else np.nan,\n",
    "                })\n",
    "\n",
    "            # interanual OBS (médias mensais por ano)\n",
    "            df_obs_box = medias_mensais_por_ano(recortar(s_obs, *REF_OBS))\n",
    "            for _, rr in df_obs_box.iterrows():\n",
    "                rows_box.append({\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": \"REF_1980_2023\",\n",
    "                    \"fonte\": \"OBS\",\n",
    "                    \"modelo\": \"OBS\",\n",
    "                    \"ano\": int(rr[\"ano\"]),\n",
    "                    \"mes\": int(rr[\"mes\"]),\n",
    "                    \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                })\n",
    "\n",
    "            # NOVO: série mensal OBS (REF) — um valor por ano-mês\n",
    "            df_obs_serie = serie_mensal(recortar(s_obs, *REF_OBS))\n",
    "            for _, rr in df_obs_serie.iterrows():\n",
    "                d = {\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": \"REF_1980_2023\",\n",
    "                    \"fonte\": \"OBS\",\n",
    "                    \"modelo\": \"OBS\",\n",
    "                    \"ano\": int(rr[\"ano\"]),\n",
    "                    \"mes\": int(rr[\"mes\"]),\n",
    "                    \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                }\n",
    "                rows_mensal_serie.append(d)\n",
    "                rows_est_serie.append(d)\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ {estacao}: observado não encontrado ({arq_obs.name}).\")\n",
    "\n",
    "        # ---- Simulados por modelo + ensemble ----\n",
    "        sims: Dict[str, pd.Series] = {}\n",
    "        for pasta_modelo in modelos:\n",
    "            mname = pasta_modelo.name\n",
    "            arq_sim = pasta_modelo / \"Output\" / f\"SIM_MC_{mini}.TXT\"\n",
    "            if not arq_sim.exists():\n",
    "                continue\n",
    "            s = aplicar_shift_anos(ler_txt_mgb(arq_sim), SHIFT_ANOS)\n",
    "            sims[mname] = s\n",
    "\n",
    "        if not sims:\n",
    "            print(f\"⚠️ {estacao}: nenhum simulado encontrado (SIM_MC_{mini}).\")\n",
    "            continue\n",
    "\n",
    "        # 1) Por modelo — climatologia mensal por horizonte\n",
    "        for mname, s in sims.items():\n",
    "            for horiz, (ini, fim) in HORIZONTES.items():\n",
    "                clim = climatologia_mensal(recortar(s, ini, fim))\n",
    "                for mes, val in clim.items():\n",
    "                    rows_est.append({\n",
    "                        \"estacao_obs\": estacao,\n",
    "                        \"codigo_mini\": mini,\n",
    "                        \"horizonte\": horiz,\n",
    "                        \"fonte\": \"GCM\",\n",
    "                        \"modelo\": mname,\n",
    "                        \"mes\": int(mes),\n",
    "                        \"Q_medio\": float(val) if pd.notna(val) else np.nan,\n",
    "                    })\n",
    "\n",
    "        # 2) Ensemble diário -> climatologia mensal\n",
    "        ens = ensemble_diario(sims)\n",
    "        for horiz, (ini, fim) in HORIZONTES.items():\n",
    "            clim = climatologia_mensal(recortar(ens, ini, fim))\n",
    "            for mes, val in clim.items():\n",
    "                rows_est.append({\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": horiz,\n",
    "                    \"fonte\": \"ENSEMBLE\",\n",
    "                    \"modelo\": \"ENSEMBLE_MEAN\",\n",
    "                    \"mes\": int(mes),\n",
    "                    \"Q_medio\": float(val) if pd.notna(val) else np.nan,\n",
    "                })\n",
    "\n",
    "        # 3) Interanual por GCM (ano, mes) por horizonte\n",
    "        for mname, s in sims.items():\n",
    "            for horiz, (ini, fim) in HORIZONTES.items():\n",
    "                df_gcm_box = medias_mensais_por_ano(recortar(s, ini, fim))\n",
    "                for _, rr in df_gcm_box.iterrows():\n",
    "                    rows_box.append({\n",
    "                        \"estacao_obs\": estacao,\n",
    "                        \"codigo_mini\": mini,\n",
    "                        \"horizonte\": horiz,\n",
    "                        \"fonte\": \"GCM\",\n",
    "                        \"modelo\": mname,\n",
    "                        \"ano\": int(rr[\"ano\"]),\n",
    "                        \"mes\": int(rr[\"mes\"]),\n",
    "                        \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                    })\n",
    "\n",
    "        # 4) Interanual ENSEMBLE (ano, mes) por horizonte\n",
    "        for horiz, (ini, fim) in HORIZONTES.items():\n",
    "            df_ens_box = medias_mensais_por_ano(recortar(ens, ini, fim))\n",
    "            for _, rr in df_ens_box.iterrows():\n",
    "                rows_box.append({\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": horiz,\n",
    "                    \"fonte\": \"ENSEMBLE\",\n",
    "                    \"modelo\": \"ENSEMBLE_MEAN\",\n",
    "                    \"ano\": int(rr[\"ano\"]),\n",
    "                    \"mes\": int(rr[\"mes\"]),\n",
    "                    \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                })\n",
    "\n",
    "        # 5) NOVO: Série mensal completa por GCM (ano, mes) por horizonte\n",
    "        for mname, s in sims.items():\n",
    "            for horiz, (ini, fim) in HORIZONTES.items():\n",
    "                df_gcm_serie = serie_mensal(recortar(s, ini, fim))\n",
    "                for _, rr in df_gcm_serie.iterrows():\n",
    "                    d = {\n",
    "                        \"estacao_obs\": estacao,\n",
    "                        \"codigo_mini\": mini,\n",
    "                        \"horizonte\": horiz,\n",
    "                        \"fonte\": \"GCM\",\n",
    "                        \"modelo\": mname,\n",
    "                        \"ano\": int(rr[\"ano\"]),\n",
    "                        \"mes\": int(rr[\"mes\"]),\n",
    "                        \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                    }\n",
    "                    rows_mensal_serie.append(d)\n",
    "                    rows_est_serie.append(d)\n",
    "\n",
    "        # 6) NOVO: Série mensal completa ENSEMBLE (ano, mes) por horizonte\n",
    "        for horiz, (ini, fim) in HORIZONTES.items():\n",
    "            df_ens_serie = serie_mensal(recortar(ens, ini, fim))\n",
    "            for _, rr in df_ens_serie.iterrows():\n",
    "                d = {\n",
    "                    \"estacao_obs\": estacao,\n",
    "                    \"codigo_mini\": mini,\n",
    "                    \"horizonte\": horiz,\n",
    "                    \"fonte\": \"ENSEMBLE\",\n",
    "                    \"modelo\": \"ENSEMBLE_MEAN\",\n",
    "                    \"ano\": int(rr[\"ano\"]),\n",
    "                    \"mes\": int(rr[\"mes\"]),\n",
    "                    \"Q_mensal\": float(rr[\"Q_mensal\"]) if pd.notna(rr[\"Q_mensal\"]) else np.nan,\n",
    "                }\n",
    "                rows_mensal_serie.append(d)\n",
    "                rows_est_serie.append(d)\n",
    "\n",
    "        # ---- salva por estação (climatologia) ----\n",
    "        df_est = pd.DataFrame(rows_est)\n",
    "        out_est = OUT_DIR_EST / f\"SAZONALIDADE_{estacao}.csv\"\n",
    "        df_est.to_csv(out_est, sep=SEP, index=False, encoding=ENC)\n",
    "\n",
    "        # ---- salva por estação (série mensal completa) ----\n",
    "        df_est_serie = pd.DataFrame(rows_est_serie)\n",
    "        out_est_serie = OUT_DIR_EST_SERIE / f\"SAZONALIDADE_SERIE_MENSAL_{estacao}.csv\"\n",
    "        df_est_serie.to_csv(out_est_serie, sep=SEP, index=False, encoding=ENC)\n",
    "\n",
    "        rows_all.extend(rows_est)\n",
    "        print(f\"✅ OK: {estacao} | modelos={len(sims)} | salvo={out_est.name} | serie={out_est_serie.name}\")\n",
    "\n",
    "    # ---- consolidado climatologia (longo) ----\n",
    "    df_all = pd.DataFrame(rows_all)\n",
    "    df_all.to_csv(OUT_CSV_ALL, sep=SEP, index=False, encoding=ENC)\n",
    "    print(f\"\\n✅ Consolidado (climatologia) salvo: {OUT_CSV_ALL}\")\n",
    "\n",
    "    # ---- padronizado (wide) ----\n",
    "    df_padrao = gerar_csv_padrao(df_all)\n",
    "    df_padrao.to_csv(OUT_CSV_PADRAO, sep=SEP, index=False, encoding=ENC)\n",
    "    print(f\"✅ Padrão (wide) salvo: {OUT_CSV_PADRAO}\")\n",
    "\n",
    "    # ---- interanual (OBS + ENSEMBLE + GCM) ----\n",
    "    df_box = pd.DataFrame(rows_box)\n",
    "    df_box.to_csv(OUT_CSV_BOX, sep=SEP, index=False, encoding=ENC)\n",
    "    print(f\"✅ Interanual (OBS + ENSEMBLE + GCM) salvo: {OUT_CSV_BOX}\")\n",
    "\n",
    "    # ---- NOVO: série mensal completa (OBS + ENSEMBLE + GCM) ----\n",
    "    df_serie = pd.DataFrame(rows_mensal_serie)\n",
    "    df_serie.to_csv(OUT_CSV_MENSAL_SERIE, sep=SEP, index=False, encoding=ENC)\n",
    "    print(f\"✅ Série mensal completa (OBS + ENSEMBLE + GCM) salva: {OUT_CSV_MENSAL_SERIE}\")\n",
    "\n",
    "    # DIAG opcional\n",
    "    try:\n",
    "        fontes = sorted(df_box[\"fonte\"].dropna().unique())\n",
    "        print(\"\\n[DIAG] Interanual: fontes únicas =\", fontes)\n",
    "        if \"GCM\" in fontes:\n",
    "            ngcm = df_box.loc[df_box[\"fonte\"] == \"GCM\", \"modelo\"].nunique()\n",
    "            print(f\"[DIAG] Interanual: #GCMs distintos = {ngcm}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        fontes2 = sorted(df_serie[\"fonte\"].dropna().unique())\n",
    "        print(\"[DIAG] Série mensal: fontes únicas =\", fontes2)\n",
    "        if \"GCM\" in fontes2:\n",
    "            ngcm2 = df_serie.loc[df_serie[\"fonte\"] == \"GCM\", \"modelo\"].nunique()\n",
    "            print(f\"[DIAG] Série mensal: #GCMs distintos = {ngcm2}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n[INFO] CSV padrão (wide) usa:\")\n",
    "    print(f\"  OBS: horizonte={PADRAO_HORIZ_OBS} | fonte={PADRAO_FONTE_OBS} | modelo={PADRAO_MODELO_OBS}\")\n",
    "    print(f\"  SIM: horizonte={PADRAO_HORIZ_SIM} | fonte={PADRAO_FONTE_SIM} | modelo={PADRAO_MODELO_SIM}\")\n",
    "\n",
    "    print(\"\\n[INFO] CSV interanual (boxplot/violin) contém:\")\n",
    "    print(\"  OBS: REF_1980_2023 | fonte=OBS | modelo=OBS | Q_mensal por (ano, mes)\")\n",
    "    print(\"  GCM: cada horizonte | fonte=GCM | modelo=<nome do GCM> | Q_mensal por (ano, mes)\")\n",
    "    print(\"  ENSEMBLE: cada horizonte | fonte=ENSEMBLE | modelo=ENSEMBLE_MEAN | Q_mensal por (ano, mes)\")\n",
    "\n",
    "    print(\"\\n[INFO] CSV série mensal completa contém:\")\n",
    "    print(\"  OBS: REF_1980_2023 | fonte=OBS | modelo=OBS | Q_mensal por (ano, mes)\")\n",
    "    print(\"  GCM: cada horizonte | fonte=GCM | modelo=<nome do GCM> | Q_mensal por (ano, mes)\")\n",
    "    print(\"  ENSEMBLE: cada horizonte | fonte=ENSEMBLE | modelo=ENSEMBLE_MEAN | Q_mensal por (ano, mes)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd0045-4ba2-422c-b7ab-dacdcf1acc44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "SCRIPT 01 — BASE CARTOGRÁFICA CONSOLIDADA (SEM RECORTE / SEM FILTRO)\n",
    "\n",
    "Premissas\n",
    "---------\n",
    "- Hidrografia já está:\n",
    "  • recortada ao limite da bacia/sub-bacias\n",
    "  • filtrada por ordem (ex.: <= 5)\n",
    "- Este script NÃO altera geometria nem conteúdo temático.\n",
    "- Apenas organiza, padroniza CRS, rotula sub-bacias e salva uma base única.\n",
    "\n",
    "Saídas\n",
    "------\n",
    "- final_base.gpkg  -> camadas prontas para plotagem\n",
    "- base_meta.json   -> metadados para uso no Script 02\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CAMINHOS (GPKG por camada)\n",
    "# =============================================================================\n",
    "gpkg_cidades   = Path(r\"E:\\Base_Cartografica_GPKG\\cidades.gpkg\")\n",
    "gpkg_estacoes  = Path(r\"E:\\Base_Cartografica_GPKG\\estacoes.gpkg\")\n",
    "gpkg_hidro     = Path(r\"E:\\Base_Cartografica_GPKG\\hidrografia.gpkg\")\n",
    "gpkg_minis     = Path(r\"E:\\Base_Cartografica_GPKG\\minis_mgb.gpkg\")\n",
    "gpkg_subbacias = Path(r\"E:\\Base_Cartografica_GPKG\\subbacias.gpkg\")\n",
    "\n",
    "LAYER_CIDADES   = \"cidades\"\n",
    "LAYER_ESTACOES  = \"estacoes\"\n",
    "LAYER_HIDRO     = \"hidrografia\"\n",
    "LAYER_MINIS     = \"minis_mgb\"\n",
    "LAYER_SUBBACIAS = \"subbacias\"\n",
    "\n",
    "# Campos\n",
    "SUB_ID_FIELD = \"Sub_Basin\"            # ex.: \"SB\" se existir\n",
    "CAMPO_NOME_CIDADE = \"CID_NM\"\n",
    "\n",
    "# CRS alvo\n",
    "TARGET_EPSG = 31982\n",
    "\n",
    "# Filtro simples de cidades (opcional)\n",
    "CIDADES_SELECIONADAS = [\"Curitiba\", \"União da Vitória\"]\n",
    "\n",
    "# Saída\n",
    "OUT_DIR = Path(r\"E:\\Base_Cartografica_GPKG\\_base\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_GPKG = OUT_DIR / \"final_base.gpkg\"\n",
    "OUT_META = OUT_DIR / \"base_meta.json\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÕES AUXILIARES\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_crs(gdf: gpd.GeoDataFrame, target_epsg: int) -> gpd.GeoDataFrame:\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError(\"Camada sem CRS definido.\")\n",
    "    if gdf.crs.to_epsg() != target_epsg:\n",
    "        return gdf.to_crs(epsg=target_epsg)\n",
    "    return gdf\n",
    "\n",
    "def label_subbasins(\n",
    "    gdf_sub: gpd.GeoDataFrame,\n",
    "    field: Optional[str]\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    gdf = gdf_sub.copy()\n",
    "\n",
    "    if field is None:\n",
    "        raise ValueError(      \"SUB_ID_FIELD está None. Defina, por exemplo: SUB_ID_FIELD = 'Sub_Basin'.\"  )\n",
    "\n",
    "    if field not in gdf.columns:\n",
    "        raise KeyError(  f\"Campo '{field}' não existe em subbacias. \"\n",
    "            f\"Colunas disponíveis: {list(gdf.columns)}\"\n",
    "        )\n",
    "\n",
    "    # extrai apenas o número da sub-bacia\n",
    "    s = gdf[field].astype(str).str.strip()\n",
    "    num = s.str.replace(r\"\\D\", \"\", regex=True)\n",
    "\n",
    "    # rótulo final padronizado\n",
    "    gdf[\"SB_LBL\"] = \"SB-\" + num.str.zfill(2)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def detectar_campo_codigo_estacao(gdf_est: gpd.GeoDataFrame) -> str:\n",
    "    cols = list(gdf_est.columns)\n",
    "    lower_map = {c.lower(): c for c in cols}\n",
    "\n",
    "    candidatos = [\n",
    "        \"codigo\", \"cod\", \"code\", \"station\", \"estacao\",\n",
    "        \"id\", \"id_est\", \"cd_estacao\"\n",
    "    ]\n",
    "    for c in candidatos:\n",
    "        if c.lower() in lower_map:\n",
    "            return lower_map[c.lower()]\n",
    "\n",
    "    # heurística: coluna com muitos números longos\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for c in cols:\n",
    "        if c == gdf_est.geometry.name:\n",
    "            continue\n",
    "        s = gdf_est[c].astype(str).str.replace(r\"\\D\", \"\", regex=True)\n",
    "        score = (s.str.len() >= 6).sum()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = c\n",
    "\n",
    "    if best is None:\n",
    "        raise KeyError(\"Não foi possível detectar o campo do código da estação.\")\n",
    "    return best\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main() -> None:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Leitura das camadas\n",
    "    # -------------------------------------------------------------------------\n",
    "    gdf_minis = gpd.read_file(gpkg_minis, layer=LAYER_MINIS)\n",
    "    gdf_sub   = gpd.read_file(gpkg_subbacias, layer=LAYER_SUBBACIAS)\n",
    "    gdf_hidro = gpd.read_file(gpkg_hidro, layer=LAYER_HIDRO)\n",
    "    gdf_cid   = gpd.read_file(gpkg_cidades, layer=LAYER_CIDADES)\n",
    "    gdf_est   = gpd.read_file(gpkg_estacoes, layer=LAYER_ESTACOES)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) CRS\n",
    "    # -------------------------------------------------------------------------\n",
    "    gdf_minis = ensure_crs(gdf_minis, TARGET_EPSG)\n",
    "    gdf_sub   = ensure_crs(gdf_sub, TARGET_EPSG)\n",
    "    gdf_hidro = ensure_crs(gdf_hidro, TARGET_EPSG)\n",
    "    gdf_cid   = ensure_crs(gdf_cid, TARGET_EPSG)\n",
    "    gdf_est   = ensure_crs(gdf_est, TARGET_EPSG)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Sub-bacias rotuladas\n",
    "    # -------------------------------------------------------------------------\n",
    "    gdf_sub = label_subbasins(gdf_sub, SUB_ID_FIELD)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Cidades (filtro simples)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if CAMPO_NOME_CIDADE in gdf_cid.columns:\n",
    "        gdf_cid = gdf_cid[gdf_cid[CAMPO_NOME_CIDADE].isin(CIDADES_SELECIONADAS)].copy()\n",
    "    else:\n",
    "        print(f\"[AVISO] Campo {CAMPO_NOME_CIDADE} não encontrado em cidades.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Estações: detectar campo de código e normalizar\n",
    "    # -------------------------------------------------------------------------\n",
    "    campo_cod_est = detectar_campo_codigo_estacao(gdf_est)\n",
    "\n",
    "    gdf_est = gdf_est.copy()\n",
    "    gdf_est[\"_cod_str\"] = (\n",
    "        gdf_est[campo_cod_est]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Exportar GPKG consolidado (sem alterar geometrias)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if OUT_GPKG.exists():\n",
    "        OUT_GPKG.unlink()\n",
    "\n",
    "    gdf_minis.to_file(OUT_GPKG, layer=\"minis\", driver=\"GPKG\")\n",
    "    gdf_sub.to_file(OUT_GPKG, layer=\"subbacias\", driver=\"GPKG\")\n",
    "    gdf_hidro.to_file(OUT_GPKG, layer=\"hidrografia\", driver=\"GPKG\")\n",
    "    gdf_cid.to_file(OUT_GPKG, layer=\"cidades\", driver=\"GPKG\")\n",
    "    gdf_est.to_file(OUT_GPKG, layer=\"estacoes\", driver=\"GPKG\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 7) Metadados (para Script 02)\n",
    "    # -------------------------------------------------------------------------\n",
    "    bounds = gdf_sub.total_bounds\n",
    "    basin_center = gdf_sub.unary_union.centroid\n",
    "\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"target_epsg\": TARGET_EPSG,\n",
    "        \"station_code_aux_field\": \"_cod_str\",\n",
    "        \"station_code_original_field\": campo_cod_est,\n",
    "        \"sub_label_field\": \"SB_LBL\",\n",
    "        \"sub_id_field_original\": SUB_ID_FIELD,\n",
    "        \"map_bounds\": {\n",
    "            \"xmin\": float(bounds[0]),\n",
    "            \"ymin\": float(bounds[1]),\n",
    "            \"xmax\": float(bounds[2]),\n",
    "            \"ymax\": float(bounds[3]),\n",
    "        },\n",
    "        \"basin_center_xy\": {\n",
    "            \"x\": float(basin_center.x),\n",
    "            \"y\": float(basin_center.y),\n",
    "        },\n",
    "        \"layers\": {\n",
    "            \"minis\": \"minis\",\n",
    "            \"subbacias\": \"subbacias\",\n",
    "            \"hidrografia\": \"hidrografia\",\n",
    "            \"cidades\": \"cidades\",\n",
    "            \"estacoes\": \"estacoes\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    OUT_META.write_text(\n",
    "        json.dumps(meta, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    print(\"✅ Base cartográfica consolidada com sucesso:\")\n",
    "    print(f\"   GPKG : {OUT_GPKG}\")\n",
    "    print(f\"   META : {OUT_META}\")\n",
    "    print(f\"   Campo código estação: {campo_cod_est}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0a384-46ec-4a02-8031-400a5513a66a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RODA MAPAS DE FORMA MANUAL\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "SCRIPT 02 — MAPA FINAL + INSETS (FDC ou SAZONALIDADE) — LAYOUT FIXO (manual)\n",
    "\n",
    "- Mantém minis + sub-bacias + simbologia da hidrografia por ordem\n",
    "- Insets com posições FIXAS (slots) conforme layout desenhado (INSET_POS)\n",
    "- Callouts conectam a estação ao canto mais próximo do inset\n",
    "\n",
    "MODOS DISPONÍVEIS\n",
    "1) FDC:\n",
    "   - Curva de permanência (opcional log)\n",
    "2) SAZONALIDADE — BOX (GCMs):\n",
    "   - Boxplots mensais (amostra = 19 GCMs) + linha Obs + linha Ensemble\n",
    "3) SAZONALIDADE — VIOLIN/BOX INTERANUAL (ENSEMBLE):\n",
    "   - Violino+box mensal do ENSEMBLE (amostra = anos, usando Q_mensal)\n",
    "   - Linhas suaves: mediana mensal do ENSEMBLE + mediana mensal do OBS\n",
    "   - Violinos coloridos (1 cor por mês)\n",
    "   - Meses no eixo X de cada inset (sem legenda)\n",
    "\n",
    "APÊNDICE — FIGURAS INDIVIDUAIS POR MODELO\n",
    "- FDC: gera também 1 mapa por GCM (além do MODELO_PLOT), usando o mesmo layout.\n",
    "- SAZONALIDADE (VIOLIN/BOX interanual): gera também 1 mapa por modelo GCM (fonte=\"GCM\"),\n",
    "  mantendo OBS como referência.\n",
    "- SAZONALIDADE (BOX GCMs): por definição NÃO gera por modelo (box = distribuição intermodelo).\n",
    "\n",
    "OBS: Nenhuma alteração de estética/edição gráfica foi feita — apenas unificação + loop por modelo.\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# usado apenas no modo VIOLIN (mantém igual ao seu script 2)\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENTRADAS: BASE (saída do Script 01)\n",
    "# =============================================================================\n",
    "BASE_DIR = Path(r\"E:\\Base_Cartografica_GPKG\\_base\")\n",
    "BASE_GPKG = BASE_DIR / \"final_base.gpkg\"\n",
    "BASE_META = BASE_DIR / \"base_meta.json\"\n",
    "\n",
    "# Saída\n",
    "OUT_DIR = Path(r\"E:\\RESULTADOS\\SSP5_85\\Figuras_FDC\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subpasta p/ apêndice (mapas individuais por modelo)\n",
    "OUT_APPENDIX_DIR = OUT_DIR / \"_appendice_modelos\"\n",
    "OUT_APPENDIX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ESCOLHA DO TIPO DE INSET\n",
    "#   - \"fdc\"\n",
    "#   - \"seasonal_box_gcms\"            (BOX: 19 GCMs + Obs + Ensemble)\n",
    "#   - \"seasonal_violin_interannual\"  (VIOLIN/BOX: Ensemble interanual + linhas)\n",
    "# =============================================================================\n",
    "PLOT_KIND = \"fdc\"\n",
    "\n",
    "# =============================================================================\n",
    "# APÊNDICE: GERAR MAPAS INDIVIDUAIS POR MODELO?\n",
    "# - FDC: itera sobre os modelos (GCMs) existentes no CSV\n",
    "# - VIOLIN interanual: itera sobre MODELO_COL dentro de fonte=\"GCM\"\n",
    "# - seasonal_box_gcms: não gera por modelo (não é metodologicamente adequado)\n",
    "# =============================================================================\n",
    "GENERATE_APPENDIX_PER_MODEL = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# LAYOUT FIGURA\n",
    "# =============================================================================\n",
    "FIGSIZE = (11.69, 8.27)  # A4 paisagem\n",
    "DPI = 300\n",
    "AX_RECT = [0.05, 0.08, 0.90, 0.84]\n",
    "\n",
    "# Tamanho dos insets\n",
    "INSET_W = 0.21\n",
    "INSET_H = 0.18\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FDC\n",
    "# =============================================================================\n",
    "CSV_FDC = Path(r\"E:\\RESULTADOS\\SSP2_45\\FDC_Projecoes_ssp245\\FDC_consolidado_obs_ref_e_futuro.csv\")\n",
    "FDC_SEP = \";\"\n",
    "HORIZONTE_PLOT = \"TOTAL_2015_2100\"\n",
    "MODELO_PLOT = \"ENSEMBLE_MEAN_POS\"\n",
    "EXC_COL = \"exc\"\n",
    "QSIM_COL = \"q_sim\"\n",
    "QOBS_COL = \"q_obs_ref\"\n",
    "FDC_YLOG = True  # log no eixo Y da FDC\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SAZONALIDADE (BOX: 19 GCMs) — CSV CONSOLIDADO (formato longo)\n",
    "# Colunas esperadas:\n",
    "# estacao_obs;codigo_mini;horizonte;fonte;modelo;mes;Q_medio\n",
    "# =============================================================================\n",
    "CSV_SEASON = Path(r\"E:\\RESULTADOS\\SSP2_45\\Sazonalidade\\SAZONALIDADE_mensal_consolidada.csv\")\n",
    "SEASON_SEP = \";\"\n",
    "\n",
    "EST_COL   = \"estacao_obs\"\n",
    "HORIZ_COL = \"horizonte\"\n",
    "FONTE_COL = \"fonte\"\n",
    "MODELO_COL = \"modelo\"\n",
    "MES_COL   = \"mes\"\n",
    "Q_COL     = \"Q_medio\"\n",
    "\n",
    "HORIZONTE_SIM = \"TOTAL_2015_2100\"   # CURTO_2015_2040 / MEDIO_2041_2070 / LONGO_2071_2100 / TOTAL_2015_2100\n",
    "HORIZONTE_OBS = \"REF_1980_2023\"\n",
    "\n",
    "SHOW_OBS = True\n",
    "SHOW_ENSEMBLE = True\n",
    "SEASON_YLOG = False  # se quiser sazonal em log, mude p/ True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SAZONALIDADE — VIOLIN/BOX INTERANUAL (OBS + ENSEMBLE)\n",
    "# CSV:\n",
    "# estacao_obs;codigo_mini;horizonte;fonte;modelo;ano;mes;Q_mensal\n",
    "# =============================================================================\n",
    "CSV_SEASON_BOX = Path(r\"E:\\RESULTADOS\\SSP2_45\\SAZONALIDADE\\SAZONALIDADE_boxplot_interanual_obs_ensemble.csv\")\n",
    "\n",
    "ANO_COL = \"ano\"\n",
    "Q_COL_BOX = \"Q_mensal\"\n",
    "\n",
    "# Paleta qualitativa (tab20 existe; usamos 12 cores)\n",
    "MONTH_CMAP = mpl.colormaps[\"tab20\"]\n",
    "MONTH_LABELS = [\"Jan\",\"Fev\",\"Mar\",\"Abr\",\"Mai\",\"Jun\",\"Jul\",\"Ago\",\"Set\",\"Out\",\"Nov\",\"Dez\"]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# POSIÇÕES FIXAS (slots) — coordenadas da FIGURA (0–1)\n",
    "# =============================================================================\n",
    "INSET_POS: Dict[str, Tuple[float, float]] = {\n",
    "    # topo\n",
    "    \"65208000\": (0.15, 0.86),\n",
    "    \"65060000\": (0.52, 0.86),\n",
    "    \"65035000\": (0.82, 0.86),\n",
    "\n",
    "    # lados\n",
    "    \"65310000\": (0.08, 0.55),\n",
    "    \"65155000\": (0.82, 0.55),\n",
    "\n",
    "    # base\n",
    "    \"65220000\": (0.33, 0.15),\n",
    "    \"65295000\": (0.08, 0.18),\n",
    "    \"65175000\": (0.58, 0.15),\n",
    "    \"65095000\": (0.82, 0.28),\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CARTOGRAFIA (mantém padrão)\n",
    "# =============================================================================\n",
    "COLOR_MINIS = \"#8a8a8a\"\n",
    "COLOR_SUB_EDGE = \"#cc0000\"\n",
    "\n",
    "COLOR_H_13 = \"#1f4e79\"\n",
    "COLOR_H_4  = \"#4f81bd\"\n",
    "COLOR_H_5  = \"#9dc3e6\"\n",
    "\n",
    "LW_MINIS = 0.25\n",
    "LW_SUB_EDGE = 1.10\n",
    "LW_H_13 = 0.75\n",
    "LW_H_4  = 0.95\n",
    "LW_H_5  = 1.10\n",
    "\n",
    "ALPHA_SUB_FILL = 0.22\n",
    "\n",
    "CALL_OUT_COLOR = \"crimson\"\n",
    "CALL_OUT_LW = 0.9\n",
    "CALL_OUT_ALPHA = 0.85\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HELPERS (apêndice por modelo)\n",
    "# =============================================================================\n",
    "def _sanitize_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    for ch in [\"/\", \"\\\\\", \":\", \"*\", \"?\", '\"', \"<\", \">\", \"|\"]:\n",
    "        s = s.replace(ch, \"_\")\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    return s\n",
    "\n",
    "def _looks_like_ensemble_or_obs(model_name: str) -> bool:\n",
    "    m = str(model_name).strip().upper()\n",
    "    if m in {\"OBS\", \"OBS_REF\", \"OBSERVADO\", \"OBSERVED\"}:\n",
    "        return True\n",
    "    if \"ENSEMBLE\" in m:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÕES AUXILIARES (comuns)\n",
    "# =============================================================================\n",
    "def data_to_figcoords(ax, x, y) -> Tuple[float, float]:\n",
    "    xy_disp = ax.transData.transform((x, y))\n",
    "    xy_fig = ax.figure.transFigure.inverted().transform(xy_disp)\n",
    "    return float(xy_fig[0]), float(xy_fig[1])\n",
    "\n",
    "def make_inset(fig, center_xy, w, h):\n",
    "    cx, cy = center_xy\n",
    "    left = cx - w / 2\n",
    "    bottom = cy - h / 2\n",
    "    return fig.add_axes([left, bottom, w, h])\n",
    "\n",
    "def inset_corners(center_xy, w, h):\n",
    "    cx, cy = center_xy\n",
    "    left = cx - w/2\n",
    "    right = cx + w/2\n",
    "    bottom = cy - h/2\n",
    "    top = cy + h/2\n",
    "    return [(left, bottom), (left, top), (right, bottom), (right, top)]\n",
    "\n",
    "def nearest_corner_of_inset(center_xy, w, h, target_xy):\n",
    "    tx, ty = target_xy\n",
    "    corners = inset_corners(center_xy, w, h)\n",
    "    return min(corners, key=lambda p: (p[0]-tx)**2 + (p[1]-ty)**2)\n",
    "\n",
    "def detectar_campo_ordem(gdf_h: gpd.GeoDataFrame) -> Optional[str]:\n",
    "    cols = list(gdf_h.columns)\n",
    "    if \"_ord\" in cols:\n",
    "        return \"_ord\"\n",
    "    lower_map = {c.lower(): c for c in cols}\n",
    "    candidatos = [\"nuordemcda\", \"nuordemdca\", \"nuordem\", \"ordem\", \"order\", \"ord\", \"strahler\", \"str_order\"]\n",
    "    for c in candidatos:\n",
    "        if c.lower() in lower_map:\n",
    "            return lower_map[c.lower()]\n",
    "    heur = [c for c in cols if (\"ord\" in c.lower()) or (\"strah\" in c.lower())]\n",
    "    return heur[0] if heur else None\n",
    "\n",
    "def plot_hidrografia(ax, gdf_h: gpd.GeoDataFrame):\n",
    "    campo = detectar_campo_ordem(gdf_h)\n",
    "    if campo is None:\n",
    "        gdf_h.plot(ax=ax, color=COLOR_H_4, linewidth=0.8, alpha=0.9, zorder=3)\n",
    "        return\n",
    "\n",
    "    ords = pd.to_numeric(gdf_h[campo], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    g = gdf_h.assign(_ord2=ords)\n",
    "    g = g[(g[\"_ord2\"] >= 1) & (g[\"_ord2\"] <= 5)].copy()\n",
    "\n",
    "    g13 = g[g[\"_ord2\"].isin([1, 2, 3])]\n",
    "    g4  = g[g[\"_ord2\"] == 4]\n",
    "    g5  = g[g[\"_ord2\"] == 5]\n",
    "\n",
    "    if len(g13):\n",
    "        g13.plot(ax=ax, color=COLOR_H_13, linewidth=LW_H_13, alpha=0.9, zorder=3)\n",
    "    if len(g4):\n",
    "        g4.plot(ax=ax, color=COLOR_H_4, linewidth=LW_H_4, alpha=0.7, zorder=3)\n",
    "    if len(g5):\n",
    "        g5.plot(ax=ax, color=COLOR_H_5, linewidth=LW_H_5, alpha=0.5, zorder=3)\n",
    "\n",
    "def plot_estacoes(ax, gdf_est: gpd.GeoDataFrame, code_field: str):\n",
    "    gdf_est.plot(ax=ax, marker=\"v\", markersize=70, color=\"black\",\n",
    "                 edgecolor=\"white\", linewidth=0.6, zorder=6)\n",
    "    for _, r in gdf_est.iterrows():\n",
    "        txt = str(r.get(code_field, \"\")).strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        ax.annotate(\n",
    "            txt,\n",
    "            xy=(r.geometry.x, r.geometry.y),\n",
    "            xytext=(4, 4),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            color=\"black\",\n",
    "            zorder=7,\n",
    "        )\n",
    "\n",
    "def plot_cidades(ax, gdf_cid: gpd.GeoDataFrame, nome_field: str):\n",
    "    if gdf_cid.empty or nome_field not in gdf_cid.columns:\n",
    "        return\n",
    "    gdf_cid.plot(ax=ax, marker=\"o\", markersize=35, color=\"white\",\n",
    "                 edgecolor=\"black\", linewidth=0.8, zorder=7)\n",
    "    for _, r in gdf_cid.iterrows():\n",
    "        ax.annotate(\n",
    "            str(r[nome_field]),\n",
    "            xy=(r.geometry.x, r.geometry.y),\n",
    "            xytext=(5, -8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            color=\"black\",\n",
    "            zorder=8,\n",
    "        )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: FDC\n",
    "# =============================================================================\n",
    "def plot_fdc_inset(ax_in, df_fdc: pd.DataFrame, title: str):\n",
    "    df_fdc = df_fdc.sort_values(EXC_COL).copy()\n",
    "\n",
    "    def pos(s):\n",
    "        s = pd.to_numeric(s, errors=\"coerce\")\n",
    "        return s.where(s > 0)\n",
    "\n",
    "    x = pd.to_numeric(df_fdc[EXC_COL], errors=\"coerce\")\n",
    "    y_sim = pos(df_fdc[QSIM_COL])\n",
    "\n",
    "    if QOBS_COL in df_fdc.columns:\n",
    "        y_obs = pos(df_fdc[QOBS_COL])\n",
    "        if y_obs.notna().any():\n",
    "            ax_in.plot(x, y_obs, lw=1.2, color=\"black\", label=\"Obs\")\n",
    "\n",
    "    ax_in.plot(x, y_sim, lw=1.1, label=\"Sim\")\n",
    "\n",
    "    ax_in.set_xlim(0, 100)\n",
    "    if FDC_YLOG:\n",
    "        ax_in.set_yscale(\"log\")\n",
    "\n",
    "    ax_in.set_title(title, fontsize=7, pad=2)\n",
    "    ax_in.set_xlabel(\"Excedência (%)\", fontsize=6)\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.tick_params(labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "    ax_in.legend(fontsize=5.4, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: SAZONALIDADE — BOX (19 GCMs) + Obs + Ensemble\n",
    "# =============================================================================\n",
    "def plot_sazonal_box_modelos_inset(\n",
    "    ax_in: plt.Axes,\n",
    "    df_season: pd.DataFrame,\n",
    "    estacao: str,\n",
    "    horizonte_sim: str,\n",
    "    horizonte_obs: str = \"REF_1980_2023\",\n",
    "    show_obs: bool = True,\n",
    "    show_ens: bool = True,\n",
    "    ylog: bool = False\n",
    ") -> None:\n",
    "    dfe = df_season[df_season[EST_COL].astype(str) == str(estacao)].copy()\n",
    "    if dfe.empty:\n",
    "        return\n",
    "\n",
    "    dfe[MES_COL] = pd.to_numeric(dfe[MES_COL], errors=\"coerce\")\n",
    "    dfe[Q_COL] = pd.to_numeric(dfe[Q_COL], errors=\"coerce\")\n",
    "\n",
    "    # Boxplots: GCMs (distribuição intermodelo)\n",
    "    gcm = dfe[(dfe[FONTE_COL] == \"GCM\") & (dfe[HORIZ_COL] == horizonte_sim)].copy()\n",
    "\n",
    "    boxes = []\n",
    "    for m in range(1, 13):\n",
    "        vals = gcm.loc[gcm[MES_COL] == m, Q_COL].dropna().values.astype(float)\n",
    "        boxes.append(vals)\n",
    "\n",
    "    ax_in.boxplot(\n",
    "        boxes,\n",
    "        positions=np.arange(1, 13),\n",
    "        widths=0.55,\n",
    "        showfliers=False\n",
    "    )\n",
    "\n",
    "    # Observado (linha)\n",
    "    if show_obs:\n",
    "        obs = dfe[\n",
    "            (dfe[FONTE_COL] == \"OBS\") &\n",
    "            (dfe[MODELO_COL] == \"OBS\") &\n",
    "            (dfe[HORIZ_COL] == horizonte_obs)\n",
    "        ].dropna(subset=[MES_COL, Q_COL]).sort_values(MES_COL)\n",
    "\n",
    "        if not obs.empty:\n",
    "            ax_in.plot(obs[MES_COL], obs[Q_COL], color=\"black\", lw=1.2, label=\"Obs\")\n",
    "\n",
    "    # Ensemble mean (linha)\n",
    "    if show_ens:\n",
    "        ens = dfe[\n",
    "            (dfe[FONTE_COL] == \"ENSEMBLE\") &\n",
    "            (dfe[MODELO_COL] == \"ENSEMBLE_MEAN\") &\n",
    "            (dfe[HORIZ_COL] == horizonte_sim)\n",
    "        ].dropna(subset=[MES_COL, Q_COL]).sort_values(MES_COL)\n",
    "\n",
    "        if not ens.empty:\n",
    "            ax_in.plot(ens[MES_COL], ens[Q_COL], lw=1.2, label=\"Ensemble\")\n",
    "\n",
    "    ax_in.set_xlim(0.5, 12.5)\n",
    "    ax_in.set_xticks([1, 3, 5, 7, 9, 11])\n",
    "    ax_in.set_xlabel(\"Mês\", fontsize=6)\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.set_title(str(estacao), fontsize=7, pad=2)\n",
    "    ax_in.tick_params(labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "\n",
    "    if ylog:\n",
    "        ymin = np.inf\n",
    "        ymax = 0.0\n",
    "        for arr in boxes:\n",
    "            if arr.size:\n",
    "                arrp = arr[arr > 0]\n",
    "                if arrp.size:\n",
    "                    ymin = min(ymin, float(arrp.min()))\n",
    "                    ymax = max(ymax, float(arrp.max()))\n",
    "        if np.isfinite(ymin) and ymax > 0:\n",
    "            ax_in.set_yscale(\"log\")\n",
    "            ax_in.set_ylim(max(ymin, 0.01), ymax * 1.2)\n",
    "\n",
    "    handles, labels = ax_in.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax_in.legend(fontsize=5.2, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: SAZONALIDADE — VIOLIN/BOX INTERANUAL (mantido)\n",
    "# =============================================================================\n",
    "def plot_sazonal_violin_interanual_inset(\n",
    "    ax_in: plt.Axes,\n",
    "    df_box: pd.DataFrame,\n",
    "    estacao: str,\n",
    "    horizonte_sim: str,\n",
    "    horizonte_obs: str,\n",
    "    sim_fonte: str,\n",
    "    sim_modelo: str,\n",
    "    ylog: bool = False\n",
    ") -> None:\n",
    "    dfe = df_box[df_box[EST_COL].astype(str) == str(estacao)].copy()\n",
    "    if dfe.empty:\n",
    "        return\n",
    "\n",
    "    dfe[MES_COL] = pd.to_numeric(dfe[MES_COL], errors=\"coerce\")\n",
    "    dfe[Q_COL_BOX] = pd.to_numeric(dfe[Q_COL_BOX], errors=\"coerce\")\n",
    "\n",
    "    sim = dfe[\n",
    "        (dfe[FONTE_COL] == sim_fonte) &\n",
    "        (dfe[MODELO_COL] == sim_modelo) &\n",
    "        (dfe[HORIZ_COL] == horizonte_sim)\n",
    "    ].copy()\n",
    "\n",
    "    boxes = []\n",
    "    sim_med = []\n",
    "    for m in range(1, 13):\n",
    "        vals = sim.loc[sim[MES_COL] == m, Q_COL_BOX].dropna().values.astype(float)\n",
    "        boxes.append(vals)\n",
    "        sim_med.append(np.nanmean(vals) if vals.size else np.nan)\n",
    "    sim_med = np.array(sim_med, dtype=float)\n",
    "\n",
    "    x = np.arange(1, 13)\n",
    "\n",
    "    vparts = ax_in.violinplot(\n",
    "        boxes,\n",
    "        positions=x,\n",
    "        widths=0.85,\n",
    "        showmeans=False,\n",
    "        showmedians=False,\n",
    "        showextrema=False\n",
    "    )\n",
    "    for i, body in enumerate(vparts[\"bodies\"]):\n",
    "        color = MONTH_CMAP(i)\n",
    "        body.set_facecolor(color)\n",
    "        body.set_edgecolor(\"black\")\n",
    "        body.set_alpha(0.55)\n",
    "        body.set_linewidth(0.6)\n",
    "\n",
    "    ax_in.boxplot(\n",
    "        boxes,\n",
    "        positions=x,\n",
    "        widths=0.22,\n",
    "        showfliers=False,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=\"white\", edgecolor=\"black\", linewidth=0.9),\n",
    "        medianprops=dict(color=\"black\", linewidth=1.0),\n",
    "        whiskerprops=dict(color=\"black\", linewidth=0.9),\n",
    "        capprops=dict(color=\"black\", linewidth=0.9),\n",
    "    )\n",
    "\n",
    "    obs = dfe[\n",
    "        (dfe[FONTE_COL] == \"OBS\") &\n",
    "        (dfe[MODELO_COL] == \"OBS\") &\n",
    "        (dfe[HORIZ_COL] == horizonte_obs)\n",
    "    ].copy()\n",
    "\n",
    "    obs_med = []\n",
    "    for m in range(1, 13):\n",
    "        vals = obs.loc[obs[MES_COL] == m, Q_COL_BOX].dropna().values.astype(float)\n",
    "        obs_med.append(np.nanmean(vals) if vals.size else np.nan)\n",
    "    obs_med = np.array(obs_med, dtype=float)\n",
    "\n",
    "    def _plot_smooth_line(xv, yv, label, color=None, linestyle=\"-\"):\n",
    "        mask = np.isfinite(yv)\n",
    "        if mask.sum() < 3:\n",
    "            ax_in.plot(xv[mask], yv[mask], label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "            return\n",
    "        try:\n",
    "            from scipy.interpolate import PchipInterpolator\n",
    "            xs = np.linspace(1, 12, 240)\n",
    "            f = PchipInterpolator(xv[mask], yv[mask])\n",
    "            ys = f(xs)\n",
    "            ax_in.plot(xs, ys, label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "        except Exception:\n",
    "            ax_in.plot(xv[mask], yv[mask], label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "\n",
    "    _plot_smooth_line(x, sim_med, label=f\"{sim_modelo} (mediana)\", color=None, linestyle=\"-\")\n",
    "    _plot_smooth_line(x, obs_med, label=\"Obs (mediana)\", color=\"black\", linestyle=\"-\")\n",
    "\n",
    "    ax_in.set_xlim(0.5, 12.5)\n",
    "    ax_in.set_xticks(np.arange(1, 13))\n",
    "    ax_in.set_xticklabels(MONTH_LABELS, fontsize=5.2, rotation=35, ha=\"right\")\n",
    "    ax_in.set_xlabel(\"\")\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.set_title(str(estacao), fontsize=7, pad=2)\n",
    "    ax_in.tick_params(axis=\"y\", labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "\n",
    "    if ylog:\n",
    "        ymin = np.inf\n",
    "        ymax = 0.0\n",
    "        for arr in boxes:\n",
    "            if arr.size:\n",
    "                arrp = arr[arr > 0]\n",
    "                if arrp.size:\n",
    "                    ymin = min(ymin, float(arrp.min()))\n",
    "                    ymax = max(ymax, float(arrp.max()))\n",
    "        for v in np.r_[sim_med, obs_med]:\n",
    "            if np.isfinite(v) and v > 0:\n",
    "                ymin = min(ymin, float(v))\n",
    "                ymax = max(ymax, float(v))\n",
    "\n",
    "        if np.isfinite(ymin) and ymax > 0:\n",
    "            ax_in.set_yscale(\"log\")\n",
    "            ax_in.set_ylim(max(ymin, 0.01), ymax * 1.2)\n",
    "\n",
    "    handles, labels = ax_in.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax_in.legend(fontsize=5.0, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÃO: desenha e salva 1 mapa (reusa exatamente a mesma estética)\n",
    "# =============================================================================\n",
    "def render_map(\n",
    "    gdf_minis: gpd.GeoDataFrame,\n",
    "    gdf_sub: gpd.GeoDataFrame,\n",
    "    gdf_hidro: gpd.GeoDataFrame,\n",
    "    gdf_cid: gpd.GeoDataFrame,\n",
    "    gdf_est: gpd.GeoDataFrame,\n",
    "    code_field: str,\n",
    "    est_fig: Dict[str, Tuple[float, float]],\n",
    "    plot_kind: str,\n",
    "    out_png: Path,\n",
    "    df_fdc: Optional[pd.DataFrame] = None,\n",
    "    df_season: Optional[pd.DataFrame] = None,\n",
    "    df_box: Optional[pd.DataFrame] = None,\n",
    "    fdc_modelo: Optional[str] = None,\n",
    "    violin_sim_fonte: Optional[str] = None,\n",
    "    violin_sim_modelo: Optional[str] = None,\n",
    ") -> None:\n",
    "    fig = plt.figure(figsize=FIGSIZE, dpi=DPI)\n",
    "    ax = fig.add_axes(AX_RECT)\n",
    "\n",
    "    gdf_minis.boundary.plot(ax=ax, color=COLOR_MINIS, linewidth=LW_MINIS, alpha=0.55, zorder=1)\n",
    "\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub.plot(\n",
    "            ax=ax,\n",
    "            column=\"SB_LBL\",\n",
    "            alpha=ALPHA_SUB_FILL,\n",
    "            linewidth=LW_SUB_EDGE,\n",
    "            edgecolor=COLOR_SUB_EDGE,\n",
    "            zorder=2,\n",
    "            legend=False\n",
    "        )\n",
    "    else:\n",
    "        gdf_sub.boundary.plot(ax=ax, color=COLOR_SUB_EDGE, linewidth=LW_SUB_EDGE, zorder=2)\n",
    "\n",
    "    plot_hidrografia(ax, gdf_hidro)\n",
    "    plot_cidades(ax, gdf_cid, nome_field=\"CID_NM\")\n",
    "    plot_estacoes(ax, gdf_est, code_field=code_field)\n",
    "\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub_tmp = gdf_sub.copy()\n",
    "        gdf_sub_tmp[\"centroid\"] = gdf_sub_tmp.geometry.centroid\n",
    "        for _, r in gdf_sub_tmp.iterrows():\n",
    "            ax.annotate(\n",
    "                str(r[\"SB_LBL\"]),\n",
    "                xy=(r[\"centroid\"].x, r[\"centroid\"].y),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                fontsize=10, fontweight=\"bold\",\n",
    "                color=\"#7a0000\", zorder=10\n",
    "            )\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    for st, center in INSET_POS.items():\n",
    "        if st not in est_fig:\n",
    "            continue\n",
    "\n",
    "        ax_in = make_inset(fig, center, INSET_W, INSET_H)\n",
    "\n",
    "        if plot_kind == \"fdc\":\n",
    "            if df_fdc is None:\n",
    "                continue\n",
    "            modelo = fdc_modelo if fdc_modelo is not None else MODELO_PLOT\n",
    "\n",
    "            df_st = df_fdc[\n",
    "                (df_fdc[\"estacao_obs\"].astype(str) == str(st)) &\n",
    "                (df_fdc[\"modelo\"].astype(str) == str(modelo)) &\n",
    "                (df_fdc[\"horizonte\"].astype(str) == str(HORIZONTE_PLOT))\n",
    "            ].copy()\n",
    "            if df_st.empty:\n",
    "                continue\n",
    "            plot_fdc_inset(ax_in, df_st, title=st)\n",
    "\n",
    "        elif plot_kind == \"seasonal_box_gcms\":\n",
    "            if df_season is None:\n",
    "                continue\n",
    "            plot_sazonal_box_modelos_inset(\n",
    "                ax_in=ax_in,\n",
    "                df_season=df_season,\n",
    "                estacao=st,\n",
    "                horizonte_sim=HORIZONTE_SIM,\n",
    "                horizonte_obs=HORIZONTE_OBS,\n",
    "                show_obs=SHOW_OBS,\n",
    "                show_ens=SHOW_ENSEMBLE,\n",
    "                ylog=SEASON_YLOG\n",
    "            )\n",
    "\n",
    "        else:  # seasonal_violin_interannual\n",
    "            if df_box is None:\n",
    "                continue\n",
    "            sim_fonte = violin_sim_fonte if violin_sim_fonte is not None else \"ENSEMBLE\"\n",
    "            sim_modelo = violin_sim_modelo if violin_sim_modelo is not None else \"ENSEMBLE_MEAN\"\n",
    "\n",
    "            plot_sazonal_violin_interanual_inset(\n",
    "                ax_in=ax_in,\n",
    "                df_box=df_box,\n",
    "                estacao=st,\n",
    "                horizonte_sim=HORIZONTE_SIM,\n",
    "                horizonte_obs=HORIZONTE_OBS,\n",
    "                sim_fonte=sim_fonte,\n",
    "                sim_modelo=sim_modelo,\n",
    "                ylog=SEASON_YLOG\n",
    "            )\n",
    "\n",
    "        x_st, y_st = est_fig[st]\n",
    "        x0, y0 = nearest_corner_of_inset(center, INSET_W, INSET_H, (x_st, y_st))\n",
    "        fig.lines.append(plt.Line2D(\n",
    "            [x0, x_st], [y0, y_st],\n",
    "            transform=fig.transFigure,\n",
    "            color=CALL_OUT_COLOR,\n",
    "            linewidth=CALL_OUT_LW,\n",
    "            alpha=CALL_OUT_ALPHA\n",
    "        ))\n",
    "\n",
    "    fig.savefig(out_png, dpi=DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Figura salva: {out_png}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "def main() -> None:\n",
    "    meta = json.loads(BASE_META.read_text(encoding=\"utf-8\"))\n",
    "    code_field = meta[\"station_code_aux_field\"]  # \"_cod_str\"\n",
    "\n",
    "    # Ler camadas consolidadas\n",
    "    gdf_minis = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"minis\"])\n",
    "    gdf_sub   = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"subbacias\"])\n",
    "    gdf_hidro = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"hidrografia\"])\n",
    "    gdf_cid   = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"cidades\"])\n",
    "    gdf_est   = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"estacoes\"])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Estações em coords de figura (ax temporário)\n",
    "    # -------------------------------------------------------------------------\n",
    "    fig_tmp = plt.figure(figsize=FIGSIZE, dpi=DPI)\n",
    "    ax_tmp = fig_tmp.add_axes(AX_RECT)\n",
    "    gdf_minis.boundary.plot(ax=ax_tmp, color=COLOR_MINIS, linewidth=LW_MINIS, alpha=0.55, zorder=1)\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub.plot(ax=ax_tmp, column=\"SB_LBL\", alpha=ALPHA_SUB_FILL,\n",
    "                     linewidth=LW_SUB_EDGE, edgecolor=COLOR_SUB_EDGE,\n",
    "                     zorder=2, legend=False)\n",
    "    else:\n",
    "        gdf_sub.boundary.plot(ax=ax_tmp, color=COLOR_SUB_EDGE, linewidth=LW_SUB_EDGE, zorder=2)\n",
    "    plot_hidrografia(ax_tmp, gdf_hidro)\n",
    "    plot_cidades(ax_tmp, gdf_cid, nome_field=\"CID_NM\")\n",
    "    plot_estacoes(ax_tmp, gdf_est, code_field=code_field)\n",
    "    ax_tmp.set_axis_off()\n",
    "\n",
    "    est_fig: Dict[str, Tuple[float, float]] = {}\n",
    "    for _, r in gdf_est.iterrows():\n",
    "        cod = str(r.get(code_field, \"\")).strip()\n",
    "        if cod:\n",
    "            est_fig[cod] = data_to_figcoords(ax_tmp, r.geometry.x, r.geometry.y)\n",
    "\n",
    "    plt.close(fig_tmp)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Ler dados conforme modo\n",
    "    # -------------------------------------------------------------------------\n",
    "    plot_kind = PLOT_KIND.lower().strip()\n",
    "    print(f\"[INFO] PLOT_KIND = {plot_kind}\")\n",
    "    print(f\"[INFO] GENERATE_APPENDIX_PER_MODEL = {GENERATE_APPENDIX_PER_MODEL}\")\n",
    "    print(f\"[INFO] OUT_APPENDIX_DIR = {OUT_APPENDIX_DIR}\")\n",
    "\n",
    "    if plot_kind == \"fdc\":\n",
    "        df_fdc = pd.read_csv(CSV_FDC, sep=FDC_SEP, dtype=str)\n",
    "\n",
    "        # normaliza\n",
    "        for c in [\"estacao_obs\", \"modelo\", \"horizonte\"]:\n",
    "            if c in df_fdc.columns:\n",
    "                df_fdc[c] = df_fdc[c].astype(str).str.strip()\n",
    "\n",
    "        # numéricos\n",
    "        df_fdc[EXC_COL] = pd.to_numeric(df_fdc[EXC_COL], errors=\"coerce\")\n",
    "        df_fdc[QSIM_COL] = pd.to_numeric(df_fdc[QSIM_COL], errors=\"coerce\")\n",
    "        if QOBS_COL in df_fdc.columns:\n",
    "            df_fdc[QOBS_COL] = pd.to_numeric(df_fdc[QOBS_COL], errors=\"coerce\")\n",
    "\n",
    "        # DIAG\n",
    "        print(\"[DIAG][FDC] colunas:\", list(df_fdc.columns))\n",
    "        print(\"[DIAG][FDC] horizontes únicos (amostra):\", sorted(df_fdc[\"horizonte\"].dropna().unique())[:30], \"...\")\n",
    "        print(\"[DIAG][FDC] modelos únicos (amostra):\", sorted(df_fdc[\"modelo\"].dropna().unique())[:30], \"...\")\n",
    "\n",
    "        # 1) mapa principal (ensemble)\n",
    "        out_main = OUT_DIR / f\"MAPA_FDC_{MODELO_PLOT}_{HORIZONTE_PLOT}_LAYOUT_MANUAL.png\"\n",
    "        render_map(\n",
    "            gdf_minis=gdf_minis, gdf_sub=gdf_sub, gdf_hidro=gdf_hidro, gdf_cid=gdf_cid, gdf_est=gdf_est,\n",
    "            code_field=code_field, est_fig=est_fig,\n",
    "            plot_kind=plot_kind, out_png=out_main,\n",
    "            df_fdc=df_fdc, fdc_modelo=MODELO_PLOT\n",
    "        )\n",
    "\n",
    "        # 2) apêndice: 1 mapa por GCM\n",
    "        if GENERATE_APPENDIX_PER_MODEL:\n",
    "            df_h = df_fdc[df_fdc[\"horizonte\"] == HORIZONTE_PLOT].copy()\n",
    "            if df_h.empty:\n",
    "                print(f\"[WARN][FDC] Nenhuma linha com horizonte='{HORIZONTE_PLOT}'. Usando arquivo inteiro (fallback).\")\n",
    "                df_h = df_fdc\n",
    "\n",
    "            # se existir coluna 'fonte', tenta filtrar fonte==GCM; senão faz por exclusão\n",
    "            if \"fonte\" in df_h.columns:\n",
    "                df_h[\"fonte\"] = df_h[\"fonte\"].astype(str).str.strip()\n",
    "                fontes = sorted(df_h[\"fonte\"].dropna().unique())\n",
    "                print(\"[DIAG][FDC] fontes únicas:\", fontes)\n",
    "\n",
    "                df_gcm = df_h[df_h[\"fonte\"].str.upper() == \"GCM\"].copy()\n",
    "                if df_gcm.empty:\n",
    "                    print(\"[WARN][FDC] Não encontrei fonte=='GCM' no CSV FDC. Vou usar fallback por exclusão (OBS/ENSEMBLE).\")\n",
    "                    df_gcm = df_h\n",
    "            else:\n",
    "                df_gcm = df_h\n",
    "\n",
    "            mlist = sorted(set(df_gcm[\"modelo\"].dropna().unique()))\n",
    "            # remove ensemble/obs e o modelo principal\n",
    "            mlist = [m for m in mlist if (m != MODELO_PLOT) and (not _looks_like_ensemble_or_obs(m))]\n",
    "\n",
    "            print(f\"[INFO][FDC] Modelos GCM para apêndice = {len(mlist)}\")\n",
    "            if not mlist:\n",
    "                print(\"[WARN][FDC] Lista de GCMs vazia. Verifique o DIAG acima para nomes reais.\")\n",
    "            else:\n",
    "                for m in mlist:\n",
    "                    m_safe = _sanitize_name(m)\n",
    "                    out_mod = OUT_APPENDIX_DIR / f\"MAPA_FDC_{m_safe}_{HORIZONTE_PLOT}_LAYOUT_MANUAL.png\"\n",
    "                    render_map(\n",
    "                        gdf_minis=gdf_minis, gdf_sub=gdf_sub, gdf_hidro=gdf_hidro, gdf_cid=gdf_cid, gdf_est=gdf_est,\n",
    "                        code_field=code_field, est_fig=est_fig,\n",
    "                        plot_kind=plot_kind, out_png=out_mod,\n",
    "                        df_fdc=df_fdc, fdc_modelo=m\n",
    "                    )\n",
    "\n",
    "    elif plot_kind == \"seasonal_box_gcms\":\n",
    "        df_season = pd.read_csv(CSV_SEASON, sep=SEASON_SEP, dtype=str)\n",
    "\n",
    "        df_season[EST_COL] = df_season[EST_COL].astype(str).str.strip()\n",
    "        df_season[HORIZ_COL] = df_season[HORIZ_COL].astype(str).str.strip()\n",
    "        df_season[FONTE_COL] = df_season[FONTE_COL].astype(str).str.strip()\n",
    "        df_season[MODELO_COL] = df_season[MODELO_COL].astype(str).str.strip()\n",
    "\n",
    "        df_season[MES_COL] = pd.to_numeric(df_season[MES_COL], errors=\"coerce\")\n",
    "        df_season[Q_COL] = pd.to_numeric(df_season[Q_COL], errors=\"coerce\")\n",
    "\n",
    "        # DIAG (ajuda a não ter “pasta vazia”)\n",
    "        print(\"[DIAG][SEASON-BOX] horizontes únicos (amostra):\", sorted(df_season[HORIZ_COL].dropna().unique())[:30], \"...\")\n",
    "        print(\"[DIAG][SEASON-BOX] fontes únicas:\", sorted(df_season[FONTE_COL].dropna().unique()))\n",
    "\n",
    "        out_main = OUT_DIR / f\"MAPA_SAZ_BOX_{HORIZONTE_SIM}_LAYOUT_MANUAL.png\"\n",
    "        render_map(\n",
    "            gdf_minis=gdf_minis, gdf_sub=gdf_sub, gdf_hidro=gdf_hidro, gdf_cid=gdf_cid, gdf_est=gdf_est,\n",
    "            code_field=code_field, est_fig=est_fig,\n",
    "            plot_kind=plot_kind, out_png=out_main,\n",
    "            df_season=df_season\n",
    "        )\n",
    "\n",
    "        if GENERATE_APPENDIX_PER_MODEL:\n",
    "            print(\"[INFO] seasonal_box_gcms: não gera mapas por modelo (box = distribuição intermodelo).\")\n",
    "\n",
    "    elif plot_kind == \"seasonal_violin_interannual\":\n",
    "        df_box = pd.read_csv(CSV_SEASON_BOX, sep=SEASON_SEP, dtype=str)\n",
    "\n",
    "        df_box[EST_COL] = df_box[EST_COL].astype(str).str.strip()\n",
    "        df_box[HORIZ_COL] = df_box[HORIZ_COL].astype(str).str.strip()\n",
    "        df_box[FONTE_COL] = df_box[FONTE_COL].astype(str).str.strip()\n",
    "        df_box[MODELO_COL] = df_box[MODELO_COL].astype(str).str.strip()\n",
    "\n",
    "        df_box[ANO_COL] = pd.to_numeric(df_box[ANO_COL], errors=\"coerce\")\n",
    "        df_box[MES_COL] = pd.to_numeric(df_box[MES_COL], errors=\"coerce\")\n",
    "        df_box[Q_COL_BOX] = pd.to_numeric(df_box[Q_COL_BOX], errors=\"coerce\")\n",
    "\n",
    "        print(\"[DIAG][VIOLIN] horizontes únicos (amostra):\", sorted(df_box[HORIZ_COL].dropna().unique())[:30], \"...\")\n",
    "        print(\"[DIAG][VIOLIN] fontes únicas:\", sorted(df_box[FONTE_COL].dropna().unique()))\n",
    "\n",
    "        # mapa principal (ENSEMBLE)\n",
    "        out_main = OUT_DIR / f\"MAPA_SAZ_VIOLIN_INTERANUAL_ENSEMBLE_{HORIZONTE_SIM}.png\"\n",
    "        render_map(\n",
    "            gdf_minis=gdf_minis, gdf_sub=gdf_sub, gdf_hidro=gdf_hidro, gdf_cid=gdf_cid, gdf_est=gdf_est,\n",
    "            code_field=code_field, est_fig=est_fig,\n",
    "            plot_kind=plot_kind, out_png=out_main,\n",
    "            df_box=df_box,\n",
    "            violin_sim_fonte=\"ENSEMBLE\",\n",
    "            violin_sim_modelo=\"ENSEMBLE_MEAN\"\n",
    "        )\n",
    "\n",
    "        # mapas individuais por modelo (GCM)\n",
    "        if GENERATE_APPENDIX_PER_MODEL:\n",
    "            modelos_appendix = sorted(set(\n",
    "                df_box.loc[\n",
    "                    (df_box[FONTE_COL] == \"GCM\") &\n",
    "                    (df_box[HORIZ_COL] == HORIZONTE_SIM),\n",
    "                    MODELO_COL\n",
    "                ].dropna().unique()\n",
    "            ))\n",
    "\n",
    "            print(f\"[INFO][VIOLIN] Modelos GCM para apêndice = {len(modelos_appendix)}\")\n",
    "            for m in modelos_appendix:\n",
    "                m_safe = _sanitize_name(m)\n",
    "                out_mod = OUT_APPENDIX_DIR / f\"MAPA_SAZ_VIOLIN_INTERANUAL_{m_safe}_{HORIZONTE_SIM}.png\"\n",
    "                render_map(\n",
    "                    gdf_minis=gdf_minis, gdf_sub=gdf_sub, gdf_hidro=gdf_hidro, gdf_cid=gdf_cid, gdf_est=gdf_est,\n",
    "                    code_field=code_field, est_fig=est_fig,\n",
    "                    plot_kind=plot_kind, out_png=out_mod,\n",
    "                    df_box=df_box,\n",
    "                    violin_sim_fonte=\"GCM\",\n",
    "                    violin_sim_modelo=m\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"PLOT_KIND deve ser: 'fdc', 'seasonal_box_gcms' ou 'seasonal_violin_interannual'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825644de-a1ab-4d44-8545-00e266e8dd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "SCRIPT 02 — MAPA FINAL + INSETS (FDC e SAZONALIDADE) — LAYOUT FIXO (manual)\n",
    "VERSÃO CORRIGIDA\n",
    "\n",
    "OBJETIVO (1 rodada):\n",
    "- Gerar TODOS os mapas possíveis:\n",
    "  (A) FDC: todos os horizontes, para ENSEMBLE e para TODOS os GCMs\n",
    "  (B) SAZONALIDADE BOX (GCMs): todos os horizontes (sem \"por modelo\", pois o box é intermodelo)\n",
    "  (C) SAZONALIDADE VIOLIN/BOX interanual: todos os horizontes, para ENSEMBLE e para TODOS os GCMs\n",
    "\n",
    "SAÍDAS (organizadas em pastas):\n",
    "OUT_DIR/\n",
    "  FDC/<HORIZONTE>/\n",
    "    ensemble/MAPA_FDC_ENSEMBLE_MEAN_<HORIZ>.png\n",
    "    modelos/MAPA_FDC_<GCM>_<HORIZ>.png\n",
    "\n",
    "  SAZONAL_BOX/<HORIZONTE>/\n",
    "    MAPA_SAZ_BOX_<HORIZ>.png\n",
    "\n",
    "  SAZONAL_VIOLIN_INTERANUAL/<HORIZONTE>/\n",
    "    ensemble/MAPA_SAZ_VIOLIN_ENS_<HORIZ>.png\n",
    "    modelos/MAPA_SAZ_VIOLIN_<GCM>_<HORIZ>.png\n",
    "\n",
    "CORREÇÕES APLICADAS:\n",
    "- Verificação e instalação automática de dependências (scipy)\n",
    "- Compatibilidade com diferentes versões do matplotlib\n",
    "- Encoding UTF-8 explícito em todos os CSVs\n",
    "- Melhor tratamento de erros e validações\n",
    "- Otimização de memória aprimorada\n",
    "- Mensagens de progresso mais detalhadas\n",
    "\n",
    "DPI=300 mantido.\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Suprimir warnings desnecessários\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICAÇÃO E INSTALAÇÃO DE DEPENDÊNCIAS\n",
    "# =============================================================================\n",
    "def verificar_scipy():\n",
    "    \"\"\"Verifica se scipy está instalado, caso contrário tenta instalar\"\"\"\n",
    "    try:\n",
    "        import scipy\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"[AVISO] scipy não encontrado. Tentando instalar...\")\n",
    "        try:\n",
    "            import subprocess\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scipy\"])\n",
    "            print(\"[OK] scipy instalado com sucesso!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] Não foi possível instalar scipy: {e}\")\n",
    "            print(\"[INFO] Interpolação suave será desabilitada.\")\n",
    "            return False\n",
    "\n",
    "SCIPY_DISPONIVEL = verificar_scipy()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENTRADAS: BASE (saída do Script 01)\n",
    "# =============================================================================\n",
    "BASE_DIR = Path(r\"E:\\Base_Cartografica_GPKG\\_base\")\n",
    "BASE_GPKG = BASE_DIR / \"final_base.gpkg\"\n",
    "BASE_META = BASE_DIR / \"base_meta.json\"\n",
    "\n",
    "# Saída (raiz)\n",
    "OUT_DIR = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\Figuras_FDC_2\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# LAYOUT FIGURA\n",
    "# =============================================================================\n",
    "# Convertendo 23cm x 14.5cm para polegadas (1 inch = 2.54 cm)\n",
    "FIGSIZE = (23 / 2.54, 15 / 2.54)  # 23cm x 14.5cm = ~9.06\" x 5.71\"\n",
    "DPI = 300\n",
    "AX_RECT = [0.05, 0.08, 0.90, 0.84]\n",
    "\n",
    "INSET_W = 0.21\n",
    "INSET_H = 0.18\n",
    "\n",
    "# =============================================================================\n",
    "# FDC\n",
    "# =============================================================================\n",
    "CSV_FDC = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\FDC_Projecoes_ssp585\\FDC_consolidado_obs_ref_e_futuro.csv\")\n",
    "FDC_SEP = \";\"\n",
    "EXC_COL = \"exc\"\n",
    "QSIM_COL = \"q_sim\"\n",
    "QOBS_COL = \"q_obs_ref\"\n",
    "FDC_YLOG = True\n",
    "\n",
    "# =============================================================================\n",
    "# SAZONALIDADE — BOX (GCMs) — CSV CONSOLIDADO (formato longo)\n",
    "# =============================================================================\n",
    "SEASON_DIR = Path(r\"E:\\RESULTADOS_AB2\\SSP5-85\\SAZONALIDADE\")\n",
    "CSV_SEASON = SEASON_DIR / \"SAZONALIDADE_mensal_consolidada.csv\"\n",
    "SEASON_SEP = \";\"\n",
    "\n",
    "EST_COL    = \"estacao_obs\"\n",
    "HORIZ_COL  = \"horizonte\"\n",
    "FONTE_COL  = \"fonte\"\n",
    "MODELO_COL = \"modelo\"\n",
    "MES_COL    = \"mes\"\n",
    "Q_COL      = \"Q_medio\"\n",
    "\n",
    "HORIZONTE_OBS = \"REF_1980_2023\"\n",
    "SHOW_OBS = True\n",
    "SHOW_ENSEMBLE = True\n",
    "SEASON_YLOG = False\n",
    "\n",
    "# Qual ensemble usar na climatologia (linha) do inset BOX\n",
    "SEASON_ENSEMBLE_MODEL_CLIM = \"ENSEMBLE_CLIM_POS_MEAN\"      # ou \"ENSEMBLE_CLIM_POS_MEDIAN\"\n",
    "\n",
    "# =============================================================================\n",
    "# SAZONALIDADE — VIOLIN/BOX INTERANUAL (OBS + ENSEMBLE + GCM)\n",
    "# =============================================================================\n",
    "CSV_SEASON_BOX = SEASON_DIR / \"SAZONALIDADE_boxplot_interanual_obs_ensemble.csv\"\n",
    "\n",
    "ANO_COL = \"ano\"\n",
    "Q_COL_BOX = \"Q_mensal\"\n",
    "\n",
    "# Qual ensemble usar no interanual (ano-mês)\n",
    "SEASON_ENSEMBLE_MODEL_INTERANUAL = \"ENSEMBLE_MENSAL_POS_MEAN\"  # ou \"ENSEMBLE_MENSAL_POS_MEDIAN\"\n",
    "\n",
    "# Compatibilidade com diferentes versões do matplotlib\n",
    "try:\n",
    "    MONTH_CMAP = mpl.colormaps[\"tab20\"]\n",
    "except (AttributeError, KeyError):\n",
    "    try:\n",
    "        MONTH_CMAP = plt.cm.get_cmap(\"tab20\")\n",
    "    except:\n",
    "        MONTH_CMAP = plt.cm.tab20\n",
    "\n",
    "MONTH_LABELS = [\"Jan\",\"Fev\",\"Mar\",\"Abr\",\"Mai\",\"Jun\",\"Jul\",\"Ago\",\"Set\",\"Out\",\"Nov\",\"Dez\"]\n",
    "\n",
    "# =============================================================================\n",
    "# POSIÇÕES FIXAS (slots) — coordenadas da FIGURA (0–1)\n",
    "# =============================================================================\n",
    "INSET_POS: Dict[str, Tuple[float, float]] = {\n",
    "    \"65208000\": (0.15, 0.86),\n",
    "    \"65060000\": (0.52, 0.88),\n",
    "    \"65035000\": (0.82, 0.89),\n",
    "    \"65310000\": (0.08, 0.55),\n",
    "    \"65155000\": (0.82, 0.55),\n",
    "    \"65220000\": (0.32, 0.12),\n",
    "    \"65295000\": (0.06, 0.18),\n",
    "    \"65175000\": (0.58, 0.15),\n",
    "    \"65095000\": (0.82, 0.28),\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# CARTOGRAFIA (mantém padrão)\n",
    "# =============================================================================\n",
    "COLOR_MINIS = \"#8a8a8a\"\n",
    "COLOR_SUB_EDGE = \"#cc0000\"\n",
    "\n",
    "COLOR_H_13 = \"#1f4e79\"\n",
    "COLOR_H_4  = \"#4f81bd\"\n",
    "COLOR_H_5  = \"#9dc3e6\"\n",
    "\n",
    "LW_MINIS = 0.25\n",
    "LW_SUB_EDGE = 1.10\n",
    "LW_H_13 = 0.75\n",
    "LW_H_4  = 0.95\n",
    "LW_H_5  = 1.10\n",
    "\n",
    "ALPHA_SUB_FILL = 0.22\n",
    "\n",
    "CALL_OUT_COLOR = \"crimson\"\n",
    "CALL_OUT_LW = 0.9\n",
    "CALL_OUT_ALPHA = 0.85\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HELPERS\n",
    "# =============================================================================\n",
    "def garantir_pasta(p: Path) -> None:\n",
    "    \"\"\"Cria pasta se não existir\"\"\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _sanitize_name(s: str) -> str:\n",
    "    \"\"\"Remove caracteres inválidos de nomes de arquivo\"\"\"\n",
    "    s = str(s).strip()\n",
    "    for ch in [\"/\", \"\\\\\", \":\", \"*\", \"?\", '\"', \"<\", \">\", \"|\"]:\n",
    "        s = s.replace(ch, \"_\")\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    return s\n",
    "\n",
    "def _looks_like_ensemble_or_obs(model_name: str) -> bool:\n",
    "    \"\"\"Verifica se o nome do modelo parece ser ensemble ou observado\"\"\"\n",
    "    m = str(model_name).strip().upper()\n",
    "    if m in {\"OBS\", \"OBS_REF\", \"OBSERVADO\", \"OBSERVED\"}:\n",
    "        return True\n",
    "    if \"ENSEMBLE\" in m:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def data_to_figcoords(ax, x, y) -> Tuple[float, float]:\n",
    "    \"\"\"Converte coordenadas de dados para coordenadas da figura\"\"\"\n",
    "    xy_disp = ax.transData.transform((x, y))\n",
    "    xy_fig = ax.figure.transFigure.inverted().transform(xy_disp)\n",
    "    return float(xy_fig[0]), float(xy_fig[1])\n",
    "\n",
    "def make_inset(fig, center_xy, w, h):\n",
    "    \"\"\"Cria um inset na figura\"\"\"\n",
    "    cx, cy = center_xy\n",
    "    left = cx - w / 2\n",
    "    bottom = cy - h / 2\n",
    "    return fig.add_axes([left, bottom, w, h])\n",
    "\n",
    "def inset_corners(center_xy, w, h):\n",
    "    \"\"\"Retorna os cantos de um inset\"\"\"\n",
    "    cx, cy = center_xy\n",
    "    left = cx - w/2\n",
    "    right = cx + w/2\n",
    "    bottom = cy - h/2\n",
    "    top = cy + h/2\n",
    "    return [(left, bottom), (left, top), (right, bottom), (right, top)]\n",
    "\n",
    "def nearest_corner_of_inset(center_xy, w, h, target_xy):\n",
    "    \"\"\"Encontra o canto mais próximo do inset em relação a um ponto\"\"\"\n",
    "    tx, ty = target_xy\n",
    "    corners = inset_corners(center_xy, w, h)\n",
    "    return min(corners, key=lambda p: (p[0]-tx)**2 + (p[1]-ty)**2)\n",
    "\n",
    "def detectar_campo_ordem(gdf_h: gpd.GeoDataFrame) -> Optional[str]:\n",
    "    \"\"\"Detecta o campo de ordem de Strahler na hidrografia\"\"\"\n",
    "    cols = list(gdf_h.columns)\n",
    "    if \"_ord2\" in cols:\n",
    "        return \"_ord2\"\n",
    "    if \"_ord\" in cols:\n",
    "        return \"_ord\"\n",
    "    lower_map = {c.lower(): c for c in cols}\n",
    "    candidatos = [\"nuordemcda\", \"nuordemdca\", \"nuordem\", \"ordem\", \"order\", \"ord\", \"strahler\", \"str_order\"]\n",
    "    for c in candidatos:\n",
    "        if c.lower() in lower_map:\n",
    "            return lower_map[c.lower()]\n",
    "    heur = [c for c in cols if (\"ord\" in c.lower()) or (\"strah\" in c.lower())]\n",
    "    return heur[0] if heur else None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# OTIMIZAÇÃO: hidrografia pré-processada 1x (evita assign/copy por figura)\n",
    "# =============================================================================\n",
    "def preparar_hidrografia(gdf_h: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Retorna hidrografia pronta para plot:\n",
    "    - com coluna _ord2 (int) e filtrada 1..5, se possível\n",
    "    - caso não haja campo de ordem, retorna o original (sem alteração)\n",
    "    \"\"\"\n",
    "    if gdf_h.empty:\n",
    "        return gdf_h\n",
    "\n",
    "    campo = detectar_campo_ordem(gdf_h)\n",
    "    if campo is None:\n",
    "        return gdf_h\n",
    "\n",
    "    if campo == \"_ord2\":\n",
    "        g = gdf_h\n",
    "    else:\n",
    "        ords = pd.to_numeric(gdf_h[campo], errors=\"coerce\").fillna(-1).astype(int)\n",
    "        g = gdf_h.copy()\n",
    "        g[\"_ord2\"] = ords.values\n",
    "\n",
    "    g = g[(g[\"_ord2\"] >= 1) & (g[\"_ord2\"] <= 5)].copy()\n",
    "    return g\n",
    "\n",
    "\n",
    "def plot_hidrografia(ax, gdf_h_prepared: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Não cria cópias internas: espera gdf_h já preparado.\n",
    "    \"\"\"\n",
    "    if gdf_h_prepared.empty:\n",
    "        return\n",
    "\n",
    "    if \"_ord2\" not in gdf_h_prepared.columns:\n",
    "        gdf_h_prepared.plot(ax=ax, color=COLOR_H_4, linewidth=0.8, alpha=0.9, zorder=3)\n",
    "        return\n",
    "\n",
    "    g13 = gdf_h_prepared[gdf_h_prepared[\"_ord2\"].isin([1, 2, 3])]\n",
    "    g4  = gdf_h_prepared[gdf_h_prepared[\"_ord2\"] == 4]\n",
    "    g5  = gdf_h_prepared[gdf_h_prepared[\"_ord2\"] == 5]\n",
    "\n",
    "    if len(g13):\n",
    "        g13.plot(ax=ax, color=COLOR_H_13, linewidth=LW_H_13, alpha=0.9, zorder=3)\n",
    "    if len(g4):\n",
    "        g4.plot(ax=ax, color=COLOR_H_4, linewidth=LW_H_4, alpha=0.7, zorder=3)\n",
    "    if len(g5):\n",
    "        g5.plot(ax=ax, color=COLOR_H_5, linewidth=LW_H_5, alpha=0.5, zorder=3)\n",
    "\n",
    "\n",
    "def plot_estacoes(ax, gdf_est: gpd.GeoDataFrame, code_field: str):\n",
    "    \"\"\"Plota estações no mapa\"\"\"\n",
    "    gdf_est.plot(ax=ax, marker=\"v\", markersize=70, color=\"black\",\n",
    "                 edgecolor=\"white\", linewidth=0.6, zorder=6)\n",
    "    \n",
    "    # Ajustes específicos para estações sobrepostas\n",
    "    ajustes_estacoes = {\n",
    "        \"65208000\": (-20, 10),   # Desloca esquerda e cima\n",
    "        \"65060000\": (6, -8),   # Desloca direita e baixo\n",
    "        \"65035000\": (5, -8),   # Desloca baixo\n",
    "    }\n",
    "    \n",
    "    for _, r in gdf_est.iterrows():\n",
    "        txt = str(r.get(code_field, \"\")).strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        \n",
    "        # Verifica se há ajuste específico para esta estação\n",
    "        if txt in ajustes_estacoes:\n",
    "            offset = ajustes_estacoes[txt]\n",
    "            ax.annotate(\n",
    "                txt,\n",
    "                xy=(r.geometry.x, r.geometry.y),\n",
    "                xytext=offset,\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "                zorder=7,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.15\", facecolor=\"white\", \n",
    "                         edgecolor=\"gray\", linewidth=0.3, alpha=0.85)\n",
    "            )\n",
    "        else:\n",
    "            # Posição padrão\n",
    "            ax.annotate(\n",
    "                txt,\n",
    "                xy=(r.geometry.x, r.geometry.y),\n",
    "                xytext=(4, 4),\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "                zorder=7,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.15\", facecolor=\"white\", \n",
    "                         edgecolor=\"gray\", linewidth=0.3, alpha=0.85)\n",
    "            )\n",
    "\n",
    "def plot_cidades(ax, gdf_cid: gpd.GeoDataFrame, nome_field: str):\n",
    "    \"\"\"Plota cidades no mapa\"\"\"\n",
    "    if gdf_cid.empty or nome_field not in gdf_cid.columns:\n",
    "        return\n",
    "    gdf_cid.plot(ax=ax, marker=\"o\", markersize=35, color=\"white\",\n",
    "                 edgecolor=\"black\", linewidth=0.8, zorder=7)\n",
    "    for _, r in gdf_cid.iterrows():\n",
    "        ax.annotate(\n",
    "            str(r[nome_field]),\n",
    "            xy=(r.geometry.x, r.geometry.y),\n",
    "            xytext=(5, -8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            color=\"black\",\n",
    "            zorder=8,\n",
    "        )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: FDC\n",
    "# =============================================================================\n",
    "def plot_fdc_inset(ax_in, df_fdc: pd.DataFrame, title: str):\n",
    "    \"\"\"Plota curva de permanência (FDC) no inset\"\"\"\n",
    "    df_fdc = df_fdc.sort_values(EXC_COL).copy()\n",
    "\n",
    "    def pos(s):\n",
    "        s = pd.to_numeric(s, errors=\"coerce\")\n",
    "        return s.where(s > 0)\n",
    "\n",
    "    x = pd.to_numeric(df_fdc[EXC_COL], errors=\"coerce\")\n",
    "    y_sim = pos(df_fdc[QSIM_COL])\n",
    "\n",
    "    if QOBS_COL in df_fdc.columns:\n",
    "        y_obs = pos(df_fdc[QOBS_COL])\n",
    "        if y_obs.notna().any():\n",
    "            ax_in.plot(x, y_obs, lw=1.2, color=\"black\", label=\"Obs\")\n",
    "\n",
    "    ax_in.plot(x, y_sim, lw=1.1, label=\"Sim\")\n",
    "\n",
    "    ax_in.set_xlim(0, 100)\n",
    "    if FDC_YLOG:\n",
    "        ax_in.set_yscale(\"log\")\n",
    "\n",
    "    ax_in.set_title(title, fontsize=7, pad=2)\n",
    "    ax_in.set_xlabel(\"Excedência (%)\", fontsize=6)\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.tick_params(labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "    ax_in.legend(fontsize=5.4, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# OTIMIZAÇÃO: precompute lookups para insets (evita filtros repetidos)\n",
    "# =============================================================================\n",
    "def build_fdc_lookup(df_fdc: pd.DataFrame) -> Dict[Tuple[str, str, str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    key = (horizonte, modelo, estacao_obs) -> df_st (com colunas necessárias)\n",
    "    \"\"\"\n",
    "    lookup: Dict[Tuple[str, str, str], pd.DataFrame] = {}\n",
    "    grp = df_fdc.groupby([\"horizonte\", \"modelo\", \"estacao_obs\"], sort=False)\n",
    "    for (h, m, st), g in grp:\n",
    "        gg = g[[EXC_COL, QSIM_COL, QOBS_COL]].copy() if QOBS_COL in g.columns else g[[EXC_COL, QSIM_COL]].copy()\n",
    "        lookup[(str(h), str(m), str(st))] = gg\n",
    "    return lookup\n",
    "\n",
    "def build_violin_lookup(df_box: pd.DataFrame) -> Dict[Tuple[str, str, str, str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    key = (horizonte, fonte, modelo, estacao_obs) -> df_est (mes/Q_mensal)\n",
    "    \"\"\"\n",
    "    lookup: Dict[Tuple[str, str, str, str], pd.DataFrame] = {}\n",
    "    grp = df_box.groupby([HORIZ_COL, FONTE_COL, MODELO_COL, EST_COL], sort=False)\n",
    "    for (h, fonte, m, st), g in grp:\n",
    "        gg = g[[MES_COL, Q_COL_BOX]].copy()\n",
    "        lookup[(str(h), str(fonte), str(m), str(st))] = gg\n",
    "    return lookup\n",
    "\n",
    "def build_season_box_lookup(df_season: pd.DataFrame) -> Dict[Tuple[str, str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    key = (horizonte, estacao_obs) -> df_est (fonte/modelo/mes/Q_medio)\n",
    "    \"\"\"\n",
    "    lookup: Dict[Tuple[str, str], pd.DataFrame] = {}\n",
    "    grp = df_season.groupby([HORIZ_COL, EST_COL], sort=False)\n",
    "    for (h, st), g in grp:\n",
    "        gg = g[[FONTE_COL, MODELO_COL, MES_COL, Q_COL]].copy()\n",
    "        lookup[(str(h), str(st))] = gg\n",
    "    return lookup\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: SAZONALIDADE — BOX (GCMs) + Obs + Ensemble\n",
    "# =============================================================================\n",
    "def plot_sazonal_box_modelos_inset_from_group(\n",
    "    ax_in: plt.Axes,\n",
    "    g_est: pd.DataFrame,\n",
    "    horizonte_sim: str,\n",
    "    horizonte_obs: str = \"REF_1980_2023\",\n",
    "    show_obs: bool = True,\n",
    "    show_ens: bool = True,\n",
    "    ylog: bool = False,\n",
    "    ensemble_model: str = \"ENSEMBLE_CLIM_POS_MEAN\",\n",
    ") -> None:\n",
    "    \"\"\"Plota sazonalidade em boxplot (GCMs) com obs e ensemble\"\"\"\n",
    "    if g_est is None or g_est.empty:\n",
    "        return\n",
    "\n",
    "    # g_est vem por (horiz, estacao) do lookup; não deve ter HORIZ_COL,\n",
    "    # mas mantemos o fallback se existir.\n",
    "    if HORIZ_COL in g_est.columns:\n",
    "        gcm = g_est[(g_est[FONTE_COL] == \"GCM\") & (g_est[HORIZ_COL] == horizonte_sim)]\n",
    "    else:\n",
    "        gcm = g_est[g_est[FONTE_COL] == \"GCM\"]\n",
    "\n",
    "    boxes = []\n",
    "    for m in range(1, 13):\n",
    "        vals = gcm.loc[gcm[MES_COL] == m, Q_COL].dropna().values.astype(float)\n",
    "        boxes.append(vals)\n",
    "\n",
    "    ax_in.boxplot(\n",
    "        boxes,\n",
    "        positions=np.arange(1, 13),\n",
    "        widths=0.55,\n",
    "        showfliers=False\n",
    "    )\n",
    "\n",
    "    if show_obs:\n",
    "        obs = g_est[(g_est[FONTE_COL] == \"OBS\") & (g_est[MODELO_COL] == \"OBS\")]\n",
    "        if not obs.empty:\n",
    "            obs = obs.dropna(subset=[MES_COL, Q_COL]).sort_values(MES_COL)\n",
    "            ax_in.plot(obs[MES_COL], obs[Q_COL], color=\"black\", lw=1.2, label=\"Obs\")\n",
    "\n",
    "    if show_ens:\n",
    "        ens = g_est[(g_est[FONTE_COL] == \"ENSEMBLE\") & (g_est[MODELO_COL] == ensemble_model)]\n",
    "        if not ens.empty:\n",
    "            ens = ens.dropna(subset=[MES_COL, Q_COL]).sort_values(MES_COL)\n",
    "            ax_in.plot(ens[MES_COL], ens[Q_COL], lw=1.2, label=\"Ensemble\")\n",
    "\n",
    "    ax_in.set_xlim(0.5, 12.5)\n",
    "    ax_in.set_xticks([1, 3, 5, 7, 9, 11])\n",
    "    ax_in.set_xlabel(\"Mês\", fontsize=6)\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.tick_params(labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "\n",
    "    if ylog:\n",
    "        ymin = np.inf\n",
    "        ymax = 0.0\n",
    "        for arr in boxes:\n",
    "            if arr.size:\n",
    "                arrp = arr[arr > 0]\n",
    "                if arrp.size:\n",
    "                    ymin = min(ymin, float(arrp.min()))\n",
    "                    ymax = max(ymax, float(arrp.max()))\n",
    "        if np.isfinite(ymin) and ymax > 0:\n",
    "            ax_in.set_yscale(\"log\")\n",
    "            ax_in.set_ylim(max(ymin, 0.01), ymax * 1.2)\n",
    "\n",
    "    handles, labels = ax_in.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax_in.legend(fontsize=5.2, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INSETS: SAZONALIDADE — VIOLIN/BOX INTERANUAL (linhas = MÉDIA)\n",
    "# =============================================================================\n",
    "def plot_sazonal_violin_interanual_inset_from_lookup(\n",
    "    ax_in: plt.Axes,\n",
    "    violin_lookup: Dict[Tuple[str, str, str, str], pd.DataFrame],\n",
    "    estacao: str,\n",
    "    horizonte_sim: str,\n",
    "    horizonte_obs: str,\n",
    "    sim_fonte: str,\n",
    "    sim_modelo: str,\n",
    "    ylog: bool = False\n",
    ") -> None:\n",
    "    \"\"\"Plota sazonalidade interanual com violin/boxplot\"\"\"\n",
    "    d_sim = violin_lookup.get((str(horizonte_sim), str(sim_fonte), str(sim_modelo), str(estacao)))\n",
    "    if d_sim is None or d_sim.empty:\n",
    "        return\n",
    "\n",
    "    boxes = []\n",
    "    sim_mean = []\n",
    "    for m in range(1, 13):\n",
    "        vals = d_sim.loc[d_sim[MES_COL] == m, Q_COL_BOX].dropna().values.astype(float)\n",
    "        boxes.append(vals)\n",
    "        sim_mean.append(np.nanmean(vals) if vals.size else np.nan)\n",
    "    sim_mean = np.array(sim_mean, dtype=float)\n",
    "\n",
    "    x = np.arange(1, 13)\n",
    "\n",
    "    vparts = ax_in.violinplot(\n",
    "        boxes,\n",
    "        positions=x,\n",
    "        widths=0.85,\n",
    "        showmeans=False,\n",
    "        showmedians=False,\n",
    "        showextrema=False\n",
    "    )\n",
    "    for i, body in enumerate(vparts[\"bodies\"]):\n",
    "        color = MONTH_CMAP(i)\n",
    "        body.set_facecolor(color)\n",
    "        body.set_edgecolor(\"black\")\n",
    "        body.set_alpha(0.55)\n",
    "        body.set_linewidth(0.6)\n",
    "\n",
    "    ax_in.boxplot(\n",
    "        boxes,\n",
    "        positions=x,\n",
    "        widths=0.22,\n",
    "        showfliers=False,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=\"white\", edgecolor=\"black\", linewidth=0.9),\n",
    "        medianprops=dict(color=\"black\", linewidth=1.0),\n",
    "        whiskerprops=dict(color=\"black\", linewidth=0.9),\n",
    "        capprops=dict(color=\"black\", linewidth=0.9),\n",
    "    )\n",
    "\n",
    "    d_obs = violin_lookup.get((str(horizonte_obs), \"OBS\", \"OBS\", str(estacao)))\n",
    "    obs_mean = np.full(12, np.nan, dtype=float)\n",
    "    if d_obs is not None and not d_obs.empty:\n",
    "        for m in range(1, 13):\n",
    "            vals = d_obs.loc[d_obs[MES_COL] == m, Q_COL_BOX].dropna().values.astype(float)\n",
    "            obs_mean[m-1] = np.nanmean(vals) if vals.size else np.nan\n",
    "\n",
    "    def _plot_smooth_line(xv, yv, label, color=None, linestyle=\"-\"):\n",
    "        \"\"\"Plota linha com interpolação suave se scipy disponível\"\"\"\n",
    "        mask = np.isfinite(yv)\n",
    "        if mask.sum() < 3:\n",
    "            ax_in.plot(xv[mask], yv[mask], label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "            return\n",
    "        \n",
    "        if not SCIPY_DISPONIVEL:\n",
    "            # Fallback: linha simples sem interpolação\n",
    "            ax_in.plot(xv[mask], yv[mask], label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            from scipy.interpolate import PchipInterpolator\n",
    "            xs = np.linspace(1, 12, 240)\n",
    "            f = PchipInterpolator(xv[mask], yv[mask])\n",
    "            ys = f(xs)\n",
    "            ax_in.plot(xs, ys, label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "        except Exception as e:\n",
    "            # Fallback em caso de erro na interpolação\n",
    "            ax_in.plot(xv[mask], yv[mask], label=label, color=color, lw=1.2, linestyle=linestyle)\n",
    "\n",
    "    # Nome simplificado para ensemble\n",
    "    if \"ENSEMBLE\" in str(sim_modelo).upper():\n",
    "        label_sim = \"Ensemble (média)\"\n",
    "    else:\n",
    "        label_sim = f\"{sim_modelo} (média)\"\n",
    "    \n",
    "    _plot_smooth_line(x, sim_mean, label=label_sim, color=None, linestyle=\"-\")\n",
    "    _plot_smooth_line(x, obs_mean, label=\"Obs (média)\", color=\"black\", linestyle=\"-\")\n",
    "\n",
    "    ax_in.set_xlim(0.5, 12.5)\n",
    "    ax_in.set_xticks(np.arange(1, 13))\n",
    "    ax_in.set_xticklabels(MONTH_LABELS, fontsize=5.2, rotation=35, ha=\"right\")\n",
    "    ax_in.set_xlabel(\"\")\n",
    "    ax_in.set_ylabel(\"Q (m³/s)\", fontsize=6)\n",
    "    ax_in.set_title(str(estacao), fontsize=7, pad=2)\n",
    "    ax_in.tick_params(axis=\"y\", labelsize=6, length=2)\n",
    "    ax_in.grid(True, alpha=0.22, linewidth=0.5)\n",
    "\n",
    "    if ylog:\n",
    "        ymin = np.inf\n",
    "        ymax = 0.0\n",
    "        for arr in boxes:\n",
    "            if arr.size:\n",
    "                arrp = arr[arr > 0]\n",
    "                if arrp.size:\n",
    "                    ymin = min(ymin, float(arrp.min()))\n",
    "                    ymax = max(ymax, float(arrp.max()))\n",
    "        for v in np.r_[sim_mean, obs_mean]:\n",
    "            if np.isfinite(v) and v > 0:\n",
    "                ymin = min(ymin, float(v))\n",
    "                ymax = max(ymax, float(v))\n",
    "\n",
    "        if np.isfinite(ymin) and ymax > 0:\n",
    "            ax_in.set_yscale(\"log\")\n",
    "            ax_in.set_ylim(max(ymin, 0.01), ymax * 1.2)\n",
    "\n",
    "    handles, labels = ax_in.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax_in.legend(fontsize=5.0, loc=\"best\", frameon=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNÇÃO: desenha e salva 1 mapa\n",
    "# =============================================================================\n",
    "def render_map(\n",
    "    gdf_minis: gpd.GeoDataFrame,\n",
    "    gdf_sub: gpd.GeoDataFrame,\n",
    "    gdf_hidro_prepared: gpd.GeoDataFrame,\n",
    "    gdf_cid: gpd.GeoDataFrame,\n",
    "    gdf_est: gpd.GeoDataFrame,\n",
    "    code_field: str,\n",
    "    est_fig: Dict[str, Tuple[float, float]],\n",
    "    out_png: Path,\n",
    "    kind: str,                 # \"fdc\" | \"seasonal_box_gcms\" | \"seasonal_violin_interannual\"\n",
    "    horizon: str,\n",
    "    # lookups\n",
    "    fdc_lookup: Optional[Dict[Tuple[str, str, str], pd.DataFrame]] = None,\n",
    "    season_box_lookup: Optional[Dict[Tuple[str, str], pd.DataFrame]] = None,\n",
    "    violin_lookup: Optional[Dict[Tuple[str, str, str, str], pd.DataFrame]] = None,\n",
    "    # seleção\n",
    "    model: Optional[str] = None,\n",
    "    sim_fonte: Optional[str] = None,\n",
    "    # sazonal\n",
    "    ensemble_model_clim: str = \"ENSEMBLE_CLIM_POS_MEAN\",\n",
    ") -> None:\n",
    "    \"\"\"Renderiza e salva um mapa completo com insets\"\"\"\n",
    "    fig = plt.figure(figsize=FIGSIZE, dpi=DPI)\n",
    "    ax = fig.add_axes(AX_RECT)\n",
    "\n",
    "    gdf_minis.boundary.plot(ax=ax, color=COLOR_MINIS, linewidth=LW_MINIS, alpha=0.55, zorder=1)\n",
    "\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub.plot(\n",
    "            ax=ax,\n",
    "            column=\"SB_LBL\",\n",
    "            alpha=ALPHA_SUB_FILL,\n",
    "            linewidth=LW_SUB_EDGE,\n",
    "            edgecolor=COLOR_SUB_EDGE,\n",
    "            zorder=2,\n",
    "            legend=False\n",
    "        )\n",
    "    else:\n",
    "        gdf_sub.boundary.plot(ax=ax, color=COLOR_SUB_EDGE, linewidth=LW_SUB_EDGE, zorder=2)\n",
    "\n",
    "    plot_hidrografia(ax, gdf_hidro_prepared)\n",
    "    plot_cidades(ax, gdf_cid, nome_field=\"CID_NM\")\n",
    "    plot_estacoes(ax, gdf_est, code_field=code_field)\n",
    "\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub_tmp = gdf_sub.copy()\n",
    "        gdf_sub_tmp[\"centroid\"] = gdf_sub_tmp.geometry.centroid\n",
    "        \n",
    "        # Dicionário de ajustes específicos (xytext offset)\n",
    "        ajustes_pos = {\n",
    "            \"SB-01\": (-10, -10),  # Desloca esquerda e para baixo\n",
    "            \"SB-09\": (-18, -15),  # Desloca esquerda e para baixo\n",
    "            \"SB-04\": (8, -19),    # Desloca para baixo\n",
    "            \"SB-03\": (8, 15),    # Desloca para direira e baixo\n",
    "            \"SB-02\": (0, -15),    # Desloca para baixo\n",
    "            \"SB-08\": (0, 15),    # Desloca para cima\n",
    "        }\n",
    "        \n",
    "        for _, r in gdf_sub_tmp.iterrows():\n",
    "            lbl = str(r[\"SB_LBL\"])\n",
    "            \n",
    "            # Verifica se há ajuste específico para este label\n",
    "            if lbl in ajustes_pos:\n",
    "                offset = ajustes_pos[lbl]\n",
    "                ax.annotate(\n",
    "                    lbl,\n",
    "                    xy=(r[\"centroid\"].x, r[\"centroid\"].y),\n",
    "                    xytext=offset,\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=10, fontweight=\"bold\",\n",
    "                    color=\"#7a0000\", zorder=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", \n",
    "                             edgecolor=\"#cc0000\", linewidth=0.4, alpha=0.75)\n",
    "                )\n",
    "            else:\n",
    "                # Outros labels mantêm posição central\n",
    "                ax.annotate(\n",
    "                    lbl,\n",
    "                    xy=(r[\"centroid\"].x, r[\"centroid\"].y),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=10, fontweight=\"bold\",\n",
    "                    color=\"#7a0000\", zorder=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", \n",
    "                             edgecolor=\"#cc0000\", linewidth=0.4, alpha=0.75)\n",
    "                )\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    for st, center in INSET_POS.items():\n",
    "        if st not in est_fig:\n",
    "            continue\n",
    "\n",
    "        ax_in = make_inset(fig, center, INSET_W, INSET_H)\n",
    "\n",
    "        if kind == \"fdc\":\n",
    "            if fdc_lookup is None or model is None:\n",
    "                continue\n",
    "            df_st = fdc_lookup.get((str(horizon), str(model), str(st)))\n",
    "            if df_st is None or df_st.empty:\n",
    "                continue\n",
    "            plot_fdc_inset(ax_in, df_st, title=st)\n",
    "\n",
    "        elif kind == \"seasonal_box_gcms\":\n",
    "            if season_box_lookup is None:\n",
    "                continue\n",
    "            g_est = season_box_lookup.get((str(horizon), str(st)))\n",
    "            if g_est is None or g_est.empty:\n",
    "                continue\n",
    "            plot_sazonal_box_modelos_inset_from_group(\n",
    "                ax_in=ax_in,\n",
    "                g_est=g_est,\n",
    "                horizonte_sim=str(horizon),\n",
    "                horizonte_obs=HORIZONTE_OBS,\n",
    "                show_obs=SHOW_OBS,\n",
    "                show_ens=SHOW_ENSEMBLE,\n",
    "                ylog=SEASON_YLOG,\n",
    "                ensemble_model=ensemble_model_clim,\n",
    "            )\n",
    "            ax_in.set_title(str(st), fontsize=7, pad=2)\n",
    "\n",
    "        elif kind == \"seasonal_violin_interannual\":\n",
    "            if violin_lookup is None or model is None or sim_fonte is None:\n",
    "                continue\n",
    "            plot_sazonal_violin_interanual_inset_from_lookup(\n",
    "                ax_in=ax_in,\n",
    "                violin_lookup=violin_lookup,\n",
    "                estacao=str(st),\n",
    "                horizonte_sim=str(horizon),\n",
    "                horizonte_obs=HORIZONTE_OBS,\n",
    "                sim_fonte=str(sim_fonte),\n",
    "                sim_modelo=str(model),\n",
    "                ylog=SEASON_YLOG\n",
    "            )\n",
    "            ax_in.set_title(str(st), fontsize=7, pad=2)\n",
    "        else:\n",
    "            raise ValueError(f\"kind inválido: {kind}\")\n",
    "\n",
    "        x_st, y_st = est_fig[st]\n",
    "        x0, y0 = nearest_corner_of_inset(center, INSET_W, INSET_H, (x_st, y_st))\n",
    "        fig.lines.append(plt.Line2D(\n",
    "            [x0, x_st], [y0, y_st],\n",
    "            transform=fig.transFigure,\n",
    "            color=CALL_OUT_COLOR,\n",
    "            linewidth=CALL_OUT_LW,\n",
    "            alpha=CALL_OUT_ALPHA\n",
    "        ))\n",
    "\n",
    "    fig.savefig(out_png, dpi=DPI, bbox_inches=\"tight\")\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN (AUTOMÁTICO)\n",
    "# =============================================================================\n",
    "def main() -> None:\n",
    "    \"\"\"Função principal: gera todos os mapas\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCRIPT 02 — GERAÇÃO DE MAPAS (VERSÃO CORRIGIDA)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Verificar arquivos de entrada\n",
    "    print(\"[1/8] Verificando arquivos de entrada...\")\n",
    "    if not BASE_GPKG.exists():\n",
    "        raise FileNotFoundError(f\"GPKG não encontrado: {BASE_GPKG}\")\n",
    "    if not BASE_META.exists():\n",
    "        raise FileNotFoundError(f\"Metadata não encontrado: {BASE_META}\")\n",
    "    if not CSV_FDC.exists():\n",
    "        raise FileNotFoundError(f\"CSV FDC não encontrado: {CSV_FDC}\")\n",
    "    if not CSV_SEASON.exists():\n",
    "        raise FileNotFoundError(f\"CSV Sazonalidade não encontrado: {CSV_SEASON}\")\n",
    "    if not CSV_SEASON_BOX.exists():\n",
    "        raise FileNotFoundError(f\"CSV Sazonalidade BOX não encontrado: {CSV_SEASON_BOX}\")\n",
    "    print(\"    ✓ Todos os arquivos encontrados!\\n\")\n",
    "    \n",
    "    # Carregar metadata\n",
    "    print(\"[2/8] Carregando metadata...\")\n",
    "    meta = json.loads(BASE_META.read_text(encoding=\"utf-8\"))\n",
    "    code_field = meta[\"station_code_aux_field\"]\n",
    "    print(f\"    ✓ Campo de código: {code_field}\\n\")\n",
    "\n",
    "    # Carregar camadas geoespaciais\n",
    "    print(\"[3/8] Carregando camadas geoespaciais...\")\n",
    "    gdf_minis = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"minis\"])\n",
    "    print(f\"    ✓ Minibacias: {len(gdf_minis)} features\")\n",
    "    \n",
    "    gdf_sub = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"subbacias\"])\n",
    "    print(f\"    ✓ Subbacias: {len(gdf_sub)} features\")\n",
    "    \n",
    "    gdf_hidro_raw = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"hidrografia\"])\n",
    "    gdf_hidro = preparar_hidrografia(gdf_hidro_raw)\n",
    "    print(f\"    ✓ Hidrografia: {len(gdf_hidro)} features\")\n",
    "    \n",
    "    gdf_cid = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"cidades\"])\n",
    "    print(f\"    ✓ Cidades: {len(gdf_cid)} features\")\n",
    "    \n",
    "    gdf_est = gpd.read_file(BASE_GPKG, layer=meta[\"layers\"][\"estacoes\"])\n",
    "    print(f\"    ✓ Estações: {len(gdf_est)} features\\n\")\n",
    "\n",
    "    # Calcular posições das estações em coordenadas de figura\n",
    "    print(\"[4/8] Calculando posições das estações...\")\n",
    "    fig_tmp = plt.figure(figsize=FIGSIZE, dpi=DPI)\n",
    "    ax_tmp = fig_tmp.add_axes(AX_RECT)\n",
    "    gdf_minis.boundary.plot(ax=ax_tmp, color=COLOR_MINIS, linewidth=LW_MINIS, alpha=0.55, zorder=1)\n",
    "    if \"SB_LBL\" in gdf_sub.columns:\n",
    "        gdf_sub.plot(ax=ax_tmp, column=\"SB_LBL\", alpha=ALPHA_SUB_FILL,\n",
    "                     linewidth=LW_SUB_EDGE, edgecolor=COLOR_SUB_EDGE,\n",
    "                     zorder=2, legend=False)\n",
    "    else:\n",
    "        gdf_sub.boundary.plot(ax=ax_tmp, color=COLOR_SUB_EDGE, linewidth=LW_SUB_EDGE, zorder=2)\n",
    "    plot_hidrografia(ax_tmp, gdf_hidro)\n",
    "    plot_cidades(ax_tmp, gdf_cid, nome_field=\"CID_NM\")\n",
    "    plot_estacoes(ax_tmp, gdf_est, code_field=code_field)\n",
    "    ax_tmp.set_axis_off()\n",
    "\n",
    "    est_fig: Dict[str, Tuple[float, float]] = {}\n",
    "    for _, r in gdf_est.iterrows():\n",
    "        cod = str(r.get(code_field, \"\")).strip()\n",
    "        if cod:\n",
    "            est_fig[cod] = data_to_figcoords(ax_tmp, r.geometry.x, r.geometry.y)\n",
    "\n",
    "    fig_tmp.clf()\n",
    "    plt.close(fig_tmp)\n",
    "    plt.close(\"all\")\n",
    "    gc.collect()\n",
    "    print(f\"    ✓ {len(est_fig)} posições calculadas\\n\")\n",
    "\n",
    "    # Carregar CSVs com encoding UTF-8 explícito\n",
    "    print(\"[5/8] Carregando dados CSV...\")\n",
    "    df_fdc = pd.read_csv(CSV_FDC, sep=FDC_SEP, dtype=str, encoding='utf-8')\n",
    "    for c in [\"estacao_obs\", \"modelo\", \"horizonte\"]:\n",
    "        if c in df_fdc.columns:\n",
    "            df_fdc[c] = df_fdc[c].astype(str).str.strip()\n",
    "    df_fdc[EXC_COL] = pd.to_numeric(df_fdc[EXC_COL], errors=\"coerce\")\n",
    "    df_fdc[QSIM_COL] = pd.to_numeric(df_fdc[QSIM_COL], errors=\"coerce\")\n",
    "    if QOBS_COL in df_fdc.columns:\n",
    "        df_fdc[QOBS_COL] = pd.to_numeric(df_fdc[QOBS_COL], errors=\"coerce\")\n",
    "    print(f\"    ✓ FDC: {len(df_fdc)} registros\")\n",
    "\n",
    "    df_season = pd.read_csv(CSV_SEASON, sep=SEASON_SEP, dtype=str, encoding='utf-8')\n",
    "    for c in [EST_COL, HORIZ_COL, FONTE_COL, MODELO_COL]:\n",
    "        if c in df_season.columns:\n",
    "            df_season[c] = df_season[c].astype(str).str.strip()\n",
    "    df_season[MES_COL] = pd.to_numeric(df_season[MES_COL], errors=\"coerce\")\n",
    "    df_season[Q_COL] = pd.to_numeric(df_season[Q_COL], errors=\"coerce\")\n",
    "    print(f\"    ✓ Sazonalidade: {len(df_season)} registros\")\n",
    "\n",
    "    df_box = pd.read_csv(CSV_SEASON_BOX, sep=SEASON_SEP, dtype=str, encoding='utf-8')\n",
    "    for c in [EST_COL, HORIZ_COL, FONTE_COL, MODELO_COL]:\n",
    "        if c in df_box.columns:\n",
    "            df_box[c] = df_box[c].astype(str).str.strip()\n",
    "    df_box[ANO_COL] = pd.to_numeric(df_box[ANO_COL], errors=\"coerce\")\n",
    "    df_box[MES_COL] = pd.to_numeric(df_box[MES_COL], errors=\"coerce\")\n",
    "    df_box[Q_COL_BOX] = pd.to_numeric(df_box[Q_COL_BOX], errors=\"coerce\")\n",
    "    print(f\"    ✓ Sazonalidade BOX: {len(df_box)} registros\\n\")\n",
    "\n",
    "    # Detectar e ajustar modelos ensemble\n",
    "    print(\"[6/8] Detectando modelos ensemble...\")\n",
    "    ens_clim_candidates = sorted(df_season.loc[df_season[FONTE_COL] == \"ENSEMBLE\", MODELO_COL].dropna().unique())\n",
    "    ens_int_candidates = sorted(df_box.loc[df_box[FONTE_COL] == \"ENSEMBLE\", MODELO_COL].dropna().unique())\n",
    "\n",
    "    ensemble_model_clim = SEASON_ENSEMBLE_MODEL_CLIM\n",
    "    if ensemble_model_clim not in ens_clim_candidates and ens_clim_candidates:\n",
    "        if \"ENSEMBLE_CLIM_POS_MEAN\" in ens_clim_candidates:\n",
    "            ensemble_model_clim = \"ENSEMBLE_CLIM_POS_MEAN\"\n",
    "        else:\n",
    "            ensemble_model_clim = ens_clim_candidates[0]\n",
    "        print(f\"    ⚠ Ensemble climatologia ajustado para: {ensemble_model_clim}\")\n",
    "\n",
    "    violin_model_ens = SEASON_ENSEMBLE_MODEL_INTERANUAL\n",
    "    if violin_model_ens not in ens_int_candidates and ens_int_candidates:\n",
    "        if \"ENSEMBLE_MENSAL_POS_MEAN\" in ens_int_candidates:\n",
    "            violin_model_ens = \"ENSEMBLE_MENSAL_POS_MEAN\"\n",
    "        else:\n",
    "            violin_model_ens = ens_int_candidates[0]\n",
    "        print(f\"    ⚠ Ensemble interanual ajustado para: {violin_model_ens}\")\n",
    "    \n",
    "    print(f\"    ✓ Ensemble climatologia: {ensemble_model_clim}\")\n",
    "    print(f\"    ✓ Ensemble interanual: {violin_model_ens}\\n\")\n",
    "\n",
    "    # Construir lookups\n",
    "    print(\"[7/8] Construindo lookups (otimização)...\")\n",
    "    fdc_lookup = build_fdc_lookup(df_fdc)\n",
    "    print(f\"    ✓ FDC lookup: {len(fdc_lookup)} combinações\")\n",
    "    \n",
    "    violin_lookup = build_violin_lookup(df_box)\n",
    "    print(f\"    ✓ Violin lookup: {len(violin_lookup)} combinações\")\n",
    "    \n",
    "    season_box_lookup = build_season_box_lookup(df_season)\n",
    "    print(f\"    ✓ Season box lookup: {len(season_box_lookup)} combinações\")\n",
    "    gc.collect()\n",
    "    print()\n",
    "\n",
    "    # Listar horizontes e modelos\n",
    "    horizons_fdc = sorted([h for h in df_fdc[\"horizonte\"].dropna().unique() if h != HORIZONTE_OBS])\n",
    "    horizons_box = sorted([h for h in df_season[HORIZ_COL].dropna().unique() if h != HORIZONTE_OBS])\n",
    "    horizons_violin = sorted([h for h in df_box[HORIZ_COL].dropna().unique() if h != HORIZONTE_OBS])\n",
    "\n",
    "    fdc_models_all = sorted(df_fdc[\"modelo\"].dropna().unique())\n",
    "    fdc_models_gcm = [m for m in fdc_models_all if not _looks_like_ensemble_or_obs(m)]\n",
    "\n",
    "    fdc_model_ens = \"ENSEMBLE_MEAN\"\n",
    "    if fdc_model_ens not in fdc_models_all:\n",
    "        ens_candidates = [m for m in fdc_models_all if \"ENSEMBLE\" in str(m).upper()]\n",
    "        if ens_candidates:\n",
    "            fdc_model_ens = ens_candidates[0]\n",
    "\n",
    "    violin_models_gcm = sorted(df_box.loc[df_box[FONTE_COL] == \"GCM\", MODELO_COL].dropna().unique())\n",
    "\n",
    "    # Criar estrutura de pastas\n",
    "    out_fdc_root = OUT_DIR / \"FDC\"\n",
    "    out_box_root = OUT_DIR / \"SAZONAL_BOX\"\n",
    "    out_violin_root = OUT_DIR / \"SAZONAL_VIOLIN_INTERANUAL\"\n",
    "    garantir_pasta(out_fdc_root)\n",
    "    garantir_pasta(out_box_root)\n",
    "    garantir_pasta(out_violin_root)\n",
    "\n",
    "    print(\"[8/8] Iniciando geração de mapas...\\n\")\n",
    "    print(\"=\"*80)\n",
    "    nfig = 0\n",
    "\n",
    "    # FDC\n",
    "    print(f\"\\n[FDC] Gerando mapas para {len(horizons_fdc)} horizontes...\")\n",
    "    for i_h, h in enumerate(horizons_fdc, 1):\n",
    "        print(f\"  [{i_h}/{len(horizons_fdc)}] Horizonte: {h}\")\n",
    "        h_dir = out_fdc_root / h\n",
    "        dir_ens = h_dir / \"ensemble\"\n",
    "        dir_mod = h_dir / \"modelos\"\n",
    "        garantir_pasta(dir_ens)\n",
    "        garantir_pasta(dir_mod)\n",
    "\n",
    "        # Ensemble\n",
    "        out_png_ens = dir_ens / f\"MAPA_FDC_{_sanitize_name(fdc_model_ens)}_{h}.png\"\n",
    "        render_map(\n",
    "            gdf_minis, gdf_sub, gdf_hidro, gdf_cid, gdf_est, code_field, est_fig,\n",
    "            out_png=out_png_ens, kind=\"fdc\", horizon=h,\n",
    "            fdc_lookup=fdc_lookup, model=fdc_model_ens,\n",
    "            ensemble_model_clim=ensemble_model_clim\n",
    "        )\n",
    "        nfig += 1\n",
    "        if nfig % 20 == 0:\n",
    "            plt.close(\"all\")\n",
    "            gc.collect()\n",
    "\n",
    "        # Modelos individuais\n",
    "        for i_m, m in enumerate(fdc_models_gcm, 1):\n",
    "            m_safe = _sanitize_name(m)\n",
    "            out_png_m = dir_mod / f\"MAPA_FDC_{m_safe}_{h}.png\"\n",
    "            render_map(\n",
    "                gdf_minis, gdf_sub, gdf_hidro, gdf_cid, gdf_est, code_field, est_fig,\n",
    "                out_png=out_png_m, kind=\"fdc\", horizon=h,\n",
    "                fdc_lookup=fdc_lookup, model=m,\n",
    "                ensemble_model_clim=ensemble_model_clim\n",
    "            )\n",
    "            nfig += 1\n",
    "            if nfig % 20 == 0:\n",
    "                plt.close(\"all\")\n",
    "                gc.collect()\n",
    "        print(f\"      ✓ Ensemble + {len(fdc_models_gcm)} modelos concluídos ({nfig} mapas total)\")\n",
    "\n",
    "    # SAZONALIDADE BOX\n",
    "    print(f\"\\n[SAZONAL BOX] Gerando mapas para {len(horizons_box)} horizontes...\")\n",
    "    for i_h, h in enumerate(horizons_box, 1):\n",
    "        print(f\"  [{i_h}/{len(horizons_box)}] Horizonte: {h}\")\n",
    "        h_dir = out_box_root / h\n",
    "        garantir_pasta(h_dir)\n",
    "        out_png = h_dir / f\"MAPA_SAZ_BOX_{h}.png\"\n",
    "        render_map(\n",
    "            gdf_minis, gdf_sub, gdf_hidro, gdf_cid, gdf_est, code_field, est_fig,\n",
    "            out_png=out_png, kind=\"seasonal_box_gcms\", horizon=h,\n",
    "            season_box_lookup=season_box_lookup,\n",
    "            ensemble_model_clim=ensemble_model_clim\n",
    "        )\n",
    "        nfig += 1\n",
    "        if nfig % 20 == 0:\n",
    "            plt.close(\"all\")\n",
    "            gc.collect()\n",
    "        print(f\"      ✓ Concluído ({nfig} mapas total)\")\n",
    "\n",
    "    # SAZONALIDADE VIOLIN\n",
    "    print(f\"\\n[SAZONAL VIOLIN] Gerando mapas para {len(horizons_violin)} horizontes...\")\n",
    "    for i_h, h in enumerate(horizons_violin, 1):\n",
    "        print(f\"  [{i_h}/{len(horizons_violin)}] Horizonte: {h}\")\n",
    "        h_dir = out_violin_root / h\n",
    "        dir_ens = h_dir / \"ensemble\"\n",
    "        dir_mod = h_dir / \"modelos\"\n",
    "        garantir_pasta(dir_ens)\n",
    "        garantir_pasta(dir_mod)\n",
    "\n",
    "        # Ensemble\n",
    "        out_png_ens = dir_ens / f\"MAPA_SAZ_VIOLIN_ENS_{h}.png\"\n",
    "        render_map(\n",
    "            gdf_minis, gdf_sub, gdf_hidro, gdf_cid, gdf_est, code_field, est_fig,\n",
    "            out_png=out_png_ens, kind=\"seasonal_violin_interannual\", horizon=h,\n",
    "            violin_lookup=violin_lookup, model=violin_model_ens, sim_fonte=\"ENSEMBLE\",\n",
    "            ensemble_model_clim=ensemble_model_clim\n",
    "        )\n",
    "        nfig += 1\n",
    "        if nfig % 20 == 0:\n",
    "            plt.close(\"all\")\n",
    "            gc.collect()\n",
    "\n",
    "        # Modelos individuais\n",
    "        for i_m, m in enumerate(violin_models_gcm, 1):\n",
    "            m_safe = _sanitize_name(m)\n",
    "            out_png_m = dir_mod / f\"MAPA_SAZ_VIOLIN_{m_safe}_{h}.png\"\n",
    "            render_map(\n",
    "                gdf_minis, gdf_sub, gdf_hidro, gdf_cid, gdf_est, code_field, est_fig,\n",
    "                out_png=out_png_m, kind=\"seasonal_violin_interannual\", horizon=h,\n",
    "                violin_lookup=violin_lookup, model=m, sim_fonte=\"GCM\",\n",
    "                ensemble_model_clim=ensemble_model_clim\n",
    "            )\n",
    "            nfig += 1\n",
    "            if nfig % 20 == 0:\n",
    "                plt.close(\"all\")\n",
    "                gc.collect()\n",
    "        print(f\"      ✓ Ensemble + {len(violin_models_gcm)} modelos concluídos ({nfig} mapas total)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ RODADA COMPLETA FINALIZADA COM SUCESSO!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nEstatísticas finais:\")\n",
    "    print(f\"  • Total de mapas gerados: {nfig}\")\n",
    "    print(f\"  • Ensemble climatologia: {ensemble_model_clim}\")\n",
    "    print(f\"  • Ensemble interanual: {violin_model_ens}\")\n",
    "    print(f\"  • Diretório de saída: {OUT_DIR}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERRO FATAL: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84588516-e9ac-4ca5-9056-0c3d631bb1ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "COMPARATIVO — FDC + SAZONALIDADE (CENÁRIOS x ABORDAGENS) - LEGENDAS PADRÃO\n",
    "Legendas no formato: SSP2-4.5 — AB1, SSP2-4.5 — AB2, SSP5-8.5 — AB1, SSP5-8.5 — AB2\n",
    "\n",
    "CORREÇÃO (REF NÃO ENCONTRADA):\n",
    "- O filtro de referência estava frágil (dependia de \"horizonte\" com padrões específicos e, às vezes, de \"fonte\").\n",
    "- Em muitos consolidados, a referência pode aparecer como:\n",
    "  * horizonte diferente do esperado (ex.: \"HIST\", \"HISTORICO\", \"REF (1980-2023)\", etc.)\n",
    "  * \"OBS\" em \"modelo\" (e não em \"fonte\"), ou até sem coluna \"fonte\"\n",
    "  * q_obs_ref preenchido em várias linhas (às vezes repetido por horizonte/modelo)\n",
    "- Além disso, faltava filtrar também por codigo_mini ao buscar a referência.\n",
    "\n",
    "Nesta versão:\n",
    "- Detecta referência por múltiplas regras (horizonte + OBS/fonte/modelo + fallback por q_obs_ref)\n",
    "- Filtra por (estacao_obs, codigo_mini)\n",
    "- Mantém o comportamento original de plot, apenas tornando a referência robusta.\n",
    "\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "OUT_DIR = Path(r\"E:\\RESULTADOS_COMPARATIVO_FDC_SAZ\")\n",
    "(OUT_DIR / \"tables\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"figures\" / \"FDC\").mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"figures\" / \"SAZONAL\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mapeamento de cenários para rótulo final\n",
    "SCN_LABEL = {\"SSP2_45\": \"SSP2-4.5\", \"SSP5_85\": \"SSP5-8.5\"}\n",
    "\n",
    "# PALETA DE CORES FIXA - uma cor para cada combinação Cenário-Abordagem\n",
    "COLOR_PALETTE = {\n",
    "    \"SSP2-4.5 — AB1\": \"#1f77b4\",  # Azul médio\n",
    "    \"SSP2-4.5 — AB2\": \"#4d9de0\",  # Azul claro\n",
    "    \"SSP5-8.5 — AB1\": \"#d62728\",  # Vermelho\n",
    "    \"SSP5-8.5 — AB2\": \"#ff7f0e\",  # Laranja\n",
    "}\n",
    "\n",
    "# CONFIGURAÇÃO DA LINHA DE REFERÊNCIA (1980-2023)\n",
    "REF_COLOR = \"#808080\"  # Cinza\n",
    "REF_LINESTYLE = \"--\"   # Tracejado\n",
    "REF_LINEWIDTH = 1.5\n",
    "REF_ALPHA = 0.7\n",
    "REF_LABEL = \"Referência (1980-2023)\"\n",
    "REF_ZORDER = 1  # Atrás das linhas de projeção\n",
    "\n",
    "# ---- Detecção robusta de referência ----\n",
    "REF_YEAR_START = 1980\n",
    "REF_YEAR_END = 2023\n",
    "\n",
    "# (mantido, mas agora é só uma das pistas)\n",
    "REF_HORIZONTE_PATTERNS = [\"REF_1980_2023\", \"REF_1980\", \"1980_2023\"]\n",
    "\n",
    "# Palavras-chave adicionais comuns em consolidados\n",
    "REF_HZ_KEYWORDS = [\n",
    "    \"REF\", \"HIST\", \"HISTOR\", \"BASE\", \"OBS_REF\", \"REFER\", \"CALIB\", \"VALID\"\n",
    "]\n",
    "\n",
    "# OBS em colunas possíveis\n",
    "OBS_HINTS = [\"OBS\", \"OBSERV\", \"OBSERVED\"]\n",
    "\n",
    "# Ensemble (nomes podem variar entre AB1/AB2; vamos filtrar por \"contém\")\n",
    "FDC_ENSEMBLE_HINTS = [\"ENSEMBLE\", \"MEAN\"]      # em \"modelo\"\n",
    "SAZ_ENSEMBLE_HINTS = [\"ENSEMBLE\", \"MEAN\"]      # em \"modelo\"\n",
    "SAZ_FONTE_HINTS    = [\"ENSEMBLE\"]              # em \"fonte\"\n",
    "\n",
    "FDC_PKEYS = [5, 10, 50, 90, 95]  # em %\n",
    "MONTH_ORDER = list(range(1, 13))\n",
    "MONTH_LABELS_PT = [\"Jan\",\"Fev\",\"Mar\",\"Abr\",\"Mai\",\"Jun\",\"Jul\",\"Ago\",\"Set\",\"Out\",\"Nov\",\"Dez\"]\n",
    "\n",
    "EPS = 1e-9\n",
    "USE_LOGY_FDC = True\n",
    "\n",
    "# --- caminhos (use o padrão com \"_\"; fallback tenta \"-\") ---\n",
    "INPUTS = [\n",
    "    (\"AB1\", \"SSP2_45\",\n",
    "     r\"E:\\RESULTADOS_AB1\\SSP2_45\\Sazonalidade\\SAZONALIDADE_mensal_consolidada.csv\",\n",
    "     r\"E:\\RESULTADOS_AB1\\SSP2_45\\FDC_Projecoes_ssp245\\FDC_consolidado_obs_ref_e_futuro.csv\"),\n",
    "    (\"AB1\", \"SSP5_85\",\n",
    "     r\"E:\\RESULTADOS_AB1\\SSP5_85\\Sazonalidade\\SAZONALIDADE_mensal_consolidada.csv\",\n",
    "     r\"E:\\RESULTADOS_AB1\\SSP5_85\\FDC_Projecoes_ssp585\\FDC_consolidado_obs_ref_e_futuro.csv\"),\n",
    "\n",
    "    (\"AB2\", \"SSP2_45\",\n",
    "     r\"E:\\RESULTADOS_AB2\\SSP2_45\\Sazonalidade\\SAZONALIDADE_mensal_consolidada.csv\",\n",
    "     r\"E:\\RESULTADOS_AB2\\SSP2_45\\FDC_Projecoes_ssp245\\FDC_consolidado_obs_ref_e_futuro.csv\"),\n",
    "    (\"AB2\", \"SSP5_85\",\n",
    "     r\"E:\\RESULTADOS_AB2\\SSP5_85\\Sazonalidade\\SAZONALIDADE_mensal_consolidada.csv\",\n",
    "     r\"E:\\RESULTADOS_AB2\\SSP5_85\\FDC_Projecoes_ssp585\\FDC_consolidado_obs_ref_e_futuro.csv\"),\n",
    "]\n",
    "\n",
    "try:\n",
    "    from scipy.interpolate import PchipInterpolator\n",
    "    USE_PCHIP = True\n",
    "except Exception:\n",
    "    USE_PCHIP = False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PATH HELPERS\n",
    "# =============================================================================\n",
    "\n",
    "def resolve_path(p: str) -> Path:\n",
    "    \"\"\"\n",
    "    Tenta encontrar o arquivo mesmo que você tenha '_' vs '-' no caminho.\n",
    "    \"\"\"\n",
    "    path = Path(p)\n",
    "    if path.exists():\n",
    "        return path\n",
    "\n",
    "    alt = p.replace(\"SSP2_45\", \"SSP2-45\").replace(\"SSP5_85\", \"SSP5-85\")\n",
    "    alt_path = Path(alt)\n",
    "    if alt_path.exists():\n",
    "        return alt_path\n",
    "\n",
    "    alt2 = p.replace(\"SSP2-45\", \"SSP2_45\").replace(\"SSP5-85\", \"SSP5_85\")\n",
    "    alt2_path = Path(alt2)\n",
    "    if alt2_path.exists():\n",
    "        return alt2_path\n",
    "\n",
    "    raise FileNotFoundError(f\"Arquivo não encontrado:\\n- {p}\\n- {alt}\\n- {alt2}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NORMALIZAÇÃO\n",
    "# =============================================================================\n",
    "\n",
    "def norm_str(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.strip()\n",
    "\n",
    "def norm_horizon(s: pd.Series) -> pd.Series:\n",
    "    # remove espaços duplicados, padroniza separadores\n",
    "    x = s.astype(str).str.strip()\n",
    "    x = x.str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "    x = x.str.replace(\"-\", \"_\", regex=False)\n",
    "    return x\n",
    "\n",
    "def to_int64(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def contains_all(text: pd.Series, hints: List[str]) -> pd.Series:\n",
    "    t = text.astype(str).str.upper()\n",
    "    m = pd.Series(True, index=text.index)\n",
    "    for h in hints:\n",
    "        m &= t.str.contains(h.upper(), na=False)\n",
    "    return m\n",
    "\n",
    "def contains_any(text: pd.Series, hints: List[str]) -> pd.Series:\n",
    "    t = text.astype(str).str.upper()\n",
    "    m = pd.Series(False, index=text.index)\n",
    "    for h in hints:\n",
    "        m |= t.str.contains(h.upper(), na=False)\n",
    "    return m\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# LOADERS\n",
    "# =============================================================================\n",
    "\n",
    "def load_fdc(path: str, approach: str, scn_code: str) -> pd.DataFrame:\n",
    "    p = resolve_path(path)\n",
    "    df = pd.read_csv(p, sep=\";\")\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"Approach\"] = approach\n",
    "    out[\"Scenario\"] = SCN_LABEL.get(scn_code, scn_code)\n",
    "\n",
    "    # normalizações\n",
    "    for c in [\"modelo\", \"horizonte\", \"nome_estacao\", \"fonte\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = norm_str(out[c])\n",
    "\n",
    "    if \"horizonte\" in out.columns:\n",
    "        out[\"horizonte\"] = norm_horizon(out[\"horizonte\"])\n",
    "\n",
    "    out[\"estacao_obs\"] = to_int64(out[\"estacao_obs\"])\n",
    "    out[\"codigo_mini\"] = to_int64(out[\"codigo_mini\"])\n",
    "\n",
    "    out[\"exc\"] = pd.to_numeric(out[\"exc\"], errors=\"coerce\")\n",
    "\n",
    "    # colunas podem ou não existir\n",
    "    if \"q_obs_ref\" in out.columns:\n",
    "        out[\"q_obs_ref\"] = pd.to_numeric(out[\"q_obs_ref\"], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"q_obs_ref\"] = np.nan\n",
    "\n",
    "    if \"q_sim\" in out.columns:\n",
    "        out[\"q_sim\"] = pd.to_numeric(out[\"q_sim\"], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"q_sim\"] = np.nan\n",
    "\n",
    "    # exige campos mínimos para FDC de projeção (q_sim)\n",
    "    out = out.dropna(subset=[\"estacao_obs\", \"codigo_mini\", \"horizonte\", \"exc\"])\n",
    "    # NOTE: não dropa por q_sim aqui, pois OBS/ref pode ter q_obs_ref e q_sim vazio\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_saz(path: str, approach: str, scn_code: str) -> pd.DataFrame:\n",
    "    p = resolve_path(path)\n",
    "    df = pd.read_csv(p, sep=\";\")\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"Approach\"] = approach\n",
    "    out[\"Scenario\"] = SCN_LABEL.get(scn_code, scn_code)\n",
    "\n",
    "    # normalizações\n",
    "    for c in [\"fonte\", \"modelo\", \"horizonte\", \"nome_estacao\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = norm_str(out[c])\n",
    "\n",
    "    if \"horizonte\" in out.columns:\n",
    "        out[\"horizonte\"] = norm_horizon(out[\"horizonte\"])\n",
    "\n",
    "    out[\"estacao_obs\"] = to_int64(out[\"estacao_obs\"])\n",
    "    out[\"codigo_mini\"] = to_int64(out[\"codigo_mini\"])\n",
    "\n",
    "    out[\"mes\"] = to_int64(out[\"mes\"])\n",
    "    out[\"Q_medio\"] = pd.to_numeric(out[\"Q_medio\"], errors=\"coerce\")\n",
    "\n",
    "    out = out.dropna(subset=[\"estacao_obs\", \"codigo_mini\", \"horizonte\", \"mes\", \"Q_medio\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HELPERS — REFERÊNCIA ROBUSTA\n",
    "# =============================================================================\n",
    "\n",
    "def is_reference_horizon(hz_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Identifica se o horizonte é do período de referência (1980-2023).\n",
    "    Faz checagens por:\n",
    "    - padrões antigos (REF_1980_2023 etc.)\n",
    "    - palavras-chave (REF, HIST...)\n",
    "    - regex contendo 1980 e 2023 (mesmo com separadores variados)\n",
    "    \"\"\"\n",
    "    hz = hz_series.astype(str).fillna(\"\").str.upper()\n",
    "\n",
    "    # 1) padrões explícitos (mantido)\n",
    "    mask = pd.Series(False, index=hz_series.index)\n",
    "    for pattern in REF_HORIZONTE_PATTERNS:\n",
    "        mask |= hz.str.contains(pattern.upper(), na=False)\n",
    "\n",
    "    # 2) palavras-chave comuns\n",
    "    mask |= contains_any(hz, REF_HZ_KEYWORDS)\n",
    "\n",
    "    # 3) regex para capturar 1980...2023, aceitando qualquer separador\n",
    "    # (como já normalizamos '-' para '_' em muitos casos, isso pega ambos)\n",
    "    mask |= hz.str.contains(rf\"{REF_YEAR_START}.*{REF_YEAR_END}\", regex=True, na=False)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def is_obs_like(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Identifica linhas associadas a observado (OBS).\n",
    "    Tenta em 'fonte' e também em 'modelo' (muitos consolidados usam OBS em modelo).\n",
    "    Se não existir coluna, retorna False.\n",
    "    \"\"\"\n",
    "    m = pd.Series(False, index=df.index)\n",
    "\n",
    "    if \"fonte\" in df.columns:\n",
    "        m |= contains_any(df[\"fonte\"], OBS_HINTS)\n",
    "\n",
    "    if \"modelo\" in df.columns:\n",
    "        m |= contains_any(df[\"modelo\"], OBS_HINTS)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def get_reference_fdc_curve(fdc: pd.DataFrame, est: int, mini: int) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retorna curva FDC de referência (exc x Q) para uma estação/minibacia.\n",
    "\n",
    "    Estratégia (prioridade):\n",
    "    A) (horizonte referência) AND (OBS-like em fonte/modelo) AND (q_obs_ref disponível)\n",
    "    B) (horizonte referência) AND (OBS-like) usando q_sim se q_obs_ref não existir\n",
    "    C) fallback por q_obs_ref preenchido (independente de horizonte/fonte), filtrando est+mini\n",
    "    \"\"\"\n",
    "    df = fdc[(fdc[\"estacao_obs\"] == est) & (fdc[\"codigo_mini\"] == mini)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    hz_ref = is_reference_horizon(df[\"horizonte\"])\n",
    "    obs_like = is_obs_like(df)\n",
    "\n",
    "    # A) referência + OBS + q_obs_ref\n",
    "    if \"q_obs_ref\" in df.columns and df[\"q_obs_ref\"].notna().any():\n",
    "        mA = hz_ref & obs_like & df[\"q_obs_ref\"].notna()\n",
    "        if mA.any():\n",
    "            ref = (\n",
    "                df.loc[mA, [\"exc\", \"q_obs_ref\"]]\n",
    "                .dropna()\n",
    "                .groupby(\"exc\", as_index=False)[\"q_obs_ref\"].mean()\n",
    "                .sort_values(\"exc\")\n",
    "                .rename(columns={\"q_obs_ref\": \"q_ref\"})\n",
    "            )\n",
    "            if not ref.empty:\n",
    "                return ref\n",
    "\n",
    "    # B) referência + OBS usando q_sim\n",
    "    if \"q_sim\" in df.columns and df[\"q_sim\"].notna().any():\n",
    "        mB = hz_ref & obs_like & df[\"q_sim\"].notna()\n",
    "        if mB.any():\n",
    "            ref = (\n",
    "                df.loc[mB, [\"exc\", \"q_sim\"]]\n",
    "                .dropna()\n",
    "                .groupby(\"exc\", as_index=False)[\"q_sim\"].mean()\n",
    "                .sort_values(\"exc\")\n",
    "                .rename(columns={\"q_sim\": \"q_ref\"})\n",
    "            )\n",
    "            if not ref.empty:\n",
    "                return ref\n",
    "\n",
    "    # C) fallback: qualquer linha com q_obs_ref preenchido\n",
    "    if \"q_obs_ref\" in df.columns and df[\"q_obs_ref\"].notna().any():\n",
    "        mC = df[\"q_obs_ref\"].notna()\n",
    "        ref = (\n",
    "            df.loc[mC, [\"exc\", \"q_obs_ref\"]]\n",
    "            .dropna()\n",
    "            .groupby(\"exc\", as_index=False)[\"q_obs_ref\"].mean()\n",
    "            .sort_values(\"exc\")\n",
    "            .rename(columns={\"q_obs_ref\": \"q_ref\"})\n",
    "        )\n",
    "        if not ref.empty:\n",
    "            return ref\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_reference_saz_monthly(saz: pd.DataFrame, est: int, mini: int) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retorna sazonalidade de referência (mes x Q_medio) para uma estação/minibacia.\n",
    "\n",
    "    Estratégia:\n",
    "    A) horizonte referência AND OBS-like (fonte/modelo)\n",
    "    B) fallback: OBS-like independente de horizonte\n",
    "    \"\"\"\n",
    "    df = saz[(saz[\"estacao_obs\"] == est) & (saz[\"codigo_mini\"] == mini)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    hz_ref = is_reference_horizon(df[\"horizonte\"])\n",
    "    obs_like = is_obs_like(df)\n",
    "\n",
    "    mA = hz_ref & obs_like\n",
    "    if mA.any():\n",
    "        ref = (\n",
    "            df.loc[mA, [\"mes\", \"Q_medio\"]]\n",
    "            .dropna()\n",
    "            .groupby(\"mes\", as_index=False)[\"Q_medio\"].mean()\n",
    "            .sort_values(\"mes\")\n",
    "        )\n",
    "        if not ref.empty:\n",
    "            return ref\n",
    "\n",
    "    mB = obs_like\n",
    "    if mB.any():\n",
    "        ref = (\n",
    "            df.loc[mB, [\"mes\", \"Q_medio\"]]\n",
    "            .dropna()\n",
    "            .groupby(\"mes\", as_index=False)[\"Q_medio\"].mean()\n",
    "            .sort_values(\"mes\")\n",
    "        )\n",
    "        if not ref.empty:\n",
    "            return ref\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def format_horizonte(hz: str) -> str:\n",
    "    hz_clean = str(hz).replace(\"TOTAL_\", \"\").replace(\"_\", \"-\")\n",
    "    return f\"({hz_clean})\"\n",
    "\n",
    "\n",
    "def pct_change(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    return (b - a) / (np.abs(a) + EPS) * 100.0\n",
    "\n",
    "def abs_change(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    return (b - a)\n",
    "\n",
    "def interp_q_at_exc(g: pd.DataFrame, exc_targets: List[float], qcol: str) -> Dict[float, float]:\n",
    "    g2 = g.sort_values(\"exc\")\n",
    "    x = g2[\"exc\"].to_numpy()\n",
    "    y = g2[qcol].to_numpy()\n",
    "    if len(x) < 2:\n",
    "        return {pk: np.nan for pk in exc_targets}\n",
    "    return {pk: float(np.interp(pk, x, y)) for pk in exc_targets}\n",
    "\n",
    "\n",
    "def build_master_frames() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    fdc_all, saz_all = [], []\n",
    "    for approach, scn_code, saz_path, fdc_path in INPUTS:\n",
    "        fdc_all.append(load_fdc(fdc_path, approach, scn_code))\n",
    "        saz_all.append(load_saz(saz_path, approach, scn_code))\n",
    "\n",
    "    fdc = pd.concat(fdc_all, ignore_index=True)\n",
    "    saz = pd.concat(saz_all, ignore_index=True)\n",
    "\n",
    "    # Se SAZ não tem nome_estacao, pegar do FDC\n",
    "    if \"nome_estacao\" not in saz.columns or saz[\"nome_estacao\"].isna().all():\n",
    "        nome_map = fdc[[\"estacao_obs\", \"nome_estacao\"]].drop_duplicates().dropna()\n",
    "        nome_map = nome_map.groupby(\"estacao_obs\")[\"nome_estacao\"].first().to_dict()\n",
    "        saz[\"nome_estacao\"] = saz[\"estacao_obs\"].map(nome_map)\n",
    "        saz[\"nome_estacao\"] = saz[\"nome_estacao\"].fillna(saz[\"estacao_obs\"].astype(str))\n",
    "\n",
    "    return fdc, saz\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FILTROS ENSEMBLE (ROBUSTOS)\n",
    "# =============================================================================\n",
    "\n",
    "def filter_fdc_ensemble(fdc: pd.DataFrame) -> pd.DataFrame:\n",
    "    # modelo contém ENSEMBLE e MEAN\n",
    "    if \"modelo\" not in fdc.columns:\n",
    "        return fdc.iloc[0:0].copy()\n",
    "    m = contains_all(fdc[\"modelo\"], FDC_ENSEMBLE_HINTS)\n",
    "    # para projeção, exigimos q_sim\n",
    "    out = fdc[m].copy()\n",
    "    out = out.dropna(subset=[\"q_sim\"])\n",
    "    return out\n",
    "\n",
    "def filter_saz_ensemble(saz: pd.DataFrame) -> pd.DataFrame:\n",
    "    # requer colunas típicas\n",
    "    if \"modelo\" not in saz.columns or \"fonte\" not in saz.columns:\n",
    "        return saz.iloc[0:0].copy()\n",
    "    m_model = contains_all(saz[\"modelo\"], SAZ_ENSEMBLE_HINTS)\n",
    "    m_fonte = contains_all(saz[\"fonte\"], SAZ_FONTE_HINTS)\n",
    "    return saz[m_model & m_fonte].copy()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TABELAS\n",
    "# =============================================================================\n",
    "\n",
    "def summarize_fdc_pkeys(fdc: pd.DataFrame) -> pd.DataFrame:\n",
    "    f = filter_fdc_ensemble(fdc)\n",
    "\n",
    "    rows = []\n",
    "    keys = [\"estacao_obs\", \"codigo_mini\", \"nome_estacao\", \"horizonte\", \"Approach\", \"Scenario\"]\n",
    "    for grp, g in f.groupby(keys):\n",
    "        q_map = interp_q_at_exc(g, FDC_PKEYS, \"q_sim\")\n",
    "        for pk, qv in q_map.items():\n",
    "            rows.append((*grp, pk, qv))\n",
    "\n",
    "    base = pd.DataFrame(rows, columns=keys + [\"Pkey\", \"Q\"])\n",
    "\n",
    "    piv_scn = base.pivot_table(\n",
    "        index=[\"estacao_obs\",\"codigo_mini\",\"nome_estacao\",\"horizonte\",\"Approach\",\"Pkey\"],\n",
    "        columns=\"Scenario\", values=\"Q\", aggfunc=\"mean\"\n",
    "    ).reset_index()\n",
    "\n",
    "    if (\"SSP2-4.5\" in piv_scn.columns) and (\"SSP5-8.5\" in piv_scn.columns):\n",
    "        a = piv_scn[\"SSP2-4.5\"].to_numpy()\n",
    "        b = piv_scn[\"SSP5-8.5\"].to_numpy()\n",
    "        piv_scn[\"dAbs_SSP585_vs_SSP245\"] = abs_change(a, b)\n",
    "        piv_scn[\"dPct_SSP585_vs_SSP245\"] = pct_change(a, b)\n",
    "    else:\n",
    "        piv_scn[\"dAbs_SSP585_vs_SSP245\"] = np.nan\n",
    "        piv_scn[\"dPct_SSP585_vs_SSP245\"] = np.nan\n",
    "\n",
    "    out_merge = piv_scn.copy()\n",
    "    for scn in [\"SSP2-4.5\", \"SSP5-8.5\"]:\n",
    "        tmp = base[base[\"Scenario\"] == scn].pivot_table(\n",
    "            index=[\"estacao_obs\",\"codigo_mini\",\"nome_estacao\",\"horizonte\",\"Pkey\"],\n",
    "            columns=\"Approach\", values=\"Q\", aggfunc=\"mean\"\n",
    "        ).reset_index()\n",
    "\n",
    "        if (\"AB1\" in tmp.columns) and (\"AB2\" in tmp.columns):\n",
    "            a = tmp[\"AB1\"].to_numpy()\n",
    "            b = tmp[\"AB2\"].to_numpy()\n",
    "            tmp[f\"dAbs_AB2_vs_AB1_{scn}\"] = abs_change(a, b)\n",
    "            tmp[f\"dPct_AB2_vs_AB1_{scn}\"] = pct_change(a, b)\n",
    "        else:\n",
    "            tmp[f\"dAbs_AB2_vs_AB1_{scn}\"] = np.nan\n",
    "            tmp[f\"dPct_AB2_vs_AB1_{scn}\"] = np.nan\n",
    "\n",
    "        out_merge = out_merge.merge(\n",
    "            tmp[[\"estacao_obs\",\"codigo_mini\",\"nome_estacao\",\"horizonte\",\"Pkey\",\n",
    "                 f\"dAbs_AB2_vs_AB1_{scn}\", f\"dPct_AB2_vs_AB1_{scn}\"]],\n",
    "            on=[\"estacao_obs\",\"codigo_mini\",\"nome_estacao\",\"horizonte\",\"Pkey\"], how=\"left\"\n",
    "        )\n",
    "\n",
    "    return out_merge.sort_values([\"estacao_obs\",\"horizonte\",\"Approach\",\"Pkey\"])\n",
    "\n",
    "\n",
    "def summarize_saz_monthly(saz: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = filter_saz_ensemble(saz)\n",
    "\n",
    "    base = s[[\"estacao_obs\",\"codigo_mini\",\"horizonte\",\"Approach\",\"Scenario\",\"mes\",\"Q_medio\"]].copy()\n",
    "\n",
    "    piv_scn = base.pivot_table(\n",
    "        index=[\"estacao_obs\",\"codigo_mini\",\"horizonte\",\"Approach\",\"mes\"],\n",
    "        columns=\"Scenario\", values=\"Q_medio\", aggfunc=\"mean\"\n",
    "    ).reset_index()\n",
    "\n",
    "    if (\"SSP2-4.5\" in piv_scn.columns) and (\"SSP5-8.5\" in piv_scn.columns):\n",
    "        a = piv_scn[\"SSP2-4.5\"].to_numpy()\n",
    "        b = piv_scn[\"SSP5-8.5\"].to_numpy()\n",
    "        piv_scn[\"dAbs_SSP585_vs_SSP245\"] = abs_change(a, b)\n",
    "        piv_scn[\"dPct_SSP585_vs_SSP245\"] = pct_change(a, b)\n",
    "    else:\n",
    "        piv_scn[\"dAbs_SSP585_vs_SSP245\"] = np.nan\n",
    "        piv_scn[\"dPct_SSP585_vs_SSP245\"] = np.nan\n",
    "\n",
    "    out_merge = piv_scn.copy()\n",
    "    for scn in [\"SSP2-4.5\", \"SSP5-8.5\"]:\n",
    "        tmp = base[base[\"Scenario\"] == scn].pivot_table(\n",
    "            index=[\"estacao_obs\",\"codigo_mini\",\"horizonte\",\"mes\"],\n",
    "            columns=\"Approach\", values=\"Q_medio\", aggfunc=\"mean\"\n",
    "        ).reset_index()\n",
    "\n",
    "        if (\"AB1\" in tmp.columns) and (\"AB2\" in tmp.columns):\n",
    "            a = tmp[\"AB1\"].to_numpy()\n",
    "            b = tmp[\"AB2\"].to_numpy()\n",
    "            tmp[f\"dAbs_AB2_vs_AB1_{scn}\"] = abs_change(a, b)\n",
    "            tmp[f\"dPct_AB2_vs_AB1_{scn}\"] = pct_change(a, b)\n",
    "        else:\n",
    "            tmp[f\"dAbs_AB2_vs_AB1_{scn}\"] = np.nan\n",
    "            tmp[f\"dPct_AB2_vs_AB1_{scn}\"] = np.nan\n",
    "\n",
    "        out_merge = out_merge.merge(\n",
    "            tmp[[\"estacao_obs\",\"codigo_mini\",\"horizonte\",\"mes\",\n",
    "                 f\"dAbs_AB2_vs_AB1_{scn}\", f\"dPct_AB2_vs_AB1_{scn}\"]],\n",
    "            on=[\"estacao_obs\",\"codigo_mini\",\"horizonte\",\"mes\"], how=\"left\"\n",
    "        )\n",
    "\n",
    "    return out_merge.sort_values([\"estacao_obs\",\"horizonte\",\"Approach\",\"mes\"])\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FIGURAS - COM LEGENDAS PADRONIZADAS\n",
    "# =============================================================================\n",
    "\n",
    "def _apply_logy_if_possible(ax, series_list: List[pd.Series]) -> None:\n",
    "    if not USE_LOGY_FDC:\n",
    "        return\n",
    "    ok = True\n",
    "    for s in series_list:\n",
    "        if s is None or len(s) == 0:\n",
    "            continue\n",
    "        if np.nanmin(s.to_numpy()) <= 0:\n",
    "            ok = False\n",
    "            break\n",
    "    if ok:\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "def plot_fdc_compare(fdc: pd.DataFrame) -> None:\n",
    "    f = filter_fdc_ensemble(fdc)\n",
    "\n",
    "    out_dir = OUT_DIR / \"figures\" / \"FDC\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    id_cols = [\"estacao_obs\",\"codigo_mini\",\"nome_estacao\"]\n",
    "    for (est, mini, nome), g0 in f.groupby(id_cols):\n",
    "\n",
    "        # ---- REFERÊNCIA ROBUSTA (agora filtra est+mini e usa fallbacks) ----\n",
    "        ref_curve = get_reference_fdc_curve(fdc, int(est), int(mini))\n",
    "\n",
    "        if ref_curve is None or ref_curve.empty:\n",
    "            # Debug útil (sem confundir com máscaras globais)\n",
    "            hz_list = (\n",
    "                fdc[(fdc[\"estacao_obs\"] == est) & (fdc[\"codigo_mini\"] == mini)][\"horizonte\"]\n",
    "                .dropna().unique()\n",
    "            )\n",
    "            print(f\"\\n[FDC] Estação {est} ({nome}) mini={mini}\")\n",
    "            print(\"  ✗ Referência NÃO encontrada (após fallbacks).\")\n",
    "            print(\"  - Horizontes (est+mini):\")\n",
    "            for hz in hz_list:\n",
    "                print(f\"    - {hz}\")\n",
    "            if \"fonte\" in fdc.columns:\n",
    "                fontes = fdc[(fdc[\"estacao_obs\"] == est) & (fdc[\"codigo_mini\"] == mini)][\"fonte\"].dropna().unique()\n",
    "                print(f\"  - Fontes (est+mini): {list(fontes)[:20]}\")\n",
    "            if \"modelo\" in fdc.columns:\n",
    "                modelos = fdc[(fdc[\"estacao_obs\"] == est) & (fdc[\"codigo_mini\"] == mini)][\"modelo\"].dropna().unique()\n",
    "                # só imprime alguns\n",
    "                print(f\"  - Modelos (est+mini) [amostra]: {list(modelos)[:10]}\")\n",
    "        else:\n",
    "            print(f\"\\n[FDC] Estação {est} ({nome}) mini={mini} — ✓ Referência OK: {len(ref_curve)} pontos\")\n",
    "\n",
    "        for hz, gh in g0.groupby(\"horizonte\"):\n",
    "\n",
    "            fig = plt.figure(figsize=(13, 10))\n",
    "            axs = [fig.add_subplot(2,2,i+1) for i in range(4)]\n",
    "\n",
    "            # (1) AB1: cenários\n",
    "            ax = axs[0]\n",
    "            series_for_log = []\n",
    "\n",
    "            if ref_curve is not None and not ref_curve.empty:\n",
    "                ax.plot(\n",
    "                    ref_curve[\"exc\"], ref_curve[\"q_ref\"],\n",
    "                    color=REF_COLOR, linestyle=REF_LINESTYLE, linewidth=REF_LINEWIDTH,\n",
    "                    alpha=REF_ALPHA, label=REF_LABEL, zorder=REF_ZORDER\n",
    "                )\n",
    "                series_for_log.append(ref_curve[\"q_ref\"])\n",
    "\n",
    "            for scn in [\"SSP2-4.5\",\"SSP5-8.5\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==\"AB1\") & (gh[\"Scenario\"]==scn)].sort_values(\"exc\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                label = f\"{scn} — AB1\"\n",
    "                ax.plot(gg[\"exc\"], gg[\"q_sim\"], linewidth=2, label=label, color=COLOR_PALETTE[label], zorder=3)\n",
    "                series_for_log.append(gg[\"q_sim\"])\n",
    "\n",
    "            _apply_logy_if_possible(ax, series_for_log)\n",
    "            ax.set_title(\"AB1 — SSP2-4.5 vs SSP5-8.5\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Excedência (%)\")\n",
    "            ax.set_ylabel(\"Q (m³/s)\")\n",
    "            ax.grid(True, alpha=0.3, which=\"both\")\n",
    "            ax.legend()\n",
    "\n",
    "            # (2) AB2: cenários\n",
    "            ax = axs[1]\n",
    "            series_for_log = []\n",
    "\n",
    "            if ref_curve is not None and not ref_curve.empty:\n",
    "                ax.plot(\n",
    "                    ref_curve[\"exc\"], ref_curve[\"q_ref\"],\n",
    "                    color=REF_COLOR, linestyle=REF_LINESTYLE, linewidth=REF_LINEWIDTH,\n",
    "                    alpha=REF_ALPHA, label=REF_LABEL, zorder=REF_ZORDER\n",
    "                )\n",
    "                series_for_log.append(ref_curve[\"q_ref\"])\n",
    "\n",
    "            for scn in [\"SSP2-4.5\",\"SSP5-8.5\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==\"AB2\") & (gh[\"Scenario\"]==scn)].sort_values(\"exc\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                label = f\"{scn} — AB2\"\n",
    "                ax.plot(gg[\"exc\"], gg[\"q_sim\"], linewidth=2, label=label, color=COLOR_PALETTE[label], zorder=3)\n",
    "                series_for_log.append(gg[\"q_sim\"])\n",
    "\n",
    "            _apply_logy_if_possible(ax, series_for_log)\n",
    "            ax.set_title(\"AB2 — SSP2-4.5 vs SSP5-8.5\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Excedência (%)\")\n",
    "            ax.set_ylabel(\"Q (m³/s)\")\n",
    "            ax.grid(True, alpha=0.3, which=\"both\")\n",
    "            ax.legend()\n",
    "\n",
    "            # (3) SSP2-4.5: abordagens\n",
    "            ax = axs[2]\n",
    "            series_for_log = []\n",
    "\n",
    "            if ref_curve is not None and not ref_curve.empty:\n",
    "                ax.plot(\n",
    "                    ref_curve[\"exc\"], ref_curve[\"q_ref\"],\n",
    "                    color=REF_COLOR, linestyle=REF_LINESTYLE, linewidth=REF_LINEWIDTH,\n",
    "                    alpha=REF_ALPHA, label=REF_LABEL, zorder=REF_ZORDER\n",
    "                )\n",
    "                series_for_log.append(ref_curve[\"q_ref\"])\n",
    "\n",
    "            for ab in [\"AB1\",\"AB2\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==ab) & (gh[\"Scenario\"]==\"SSP2-4.5\")].sort_values(\"exc\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                label = f\"SSP2-4.5 — {ab}\"\n",
    "                ax.plot(gg[\"exc\"], gg[\"q_sim\"], linewidth=2, label=label, color=COLOR_PALETTE[label], zorder=3)\n",
    "                series_for_log.append(gg[\"q_sim\"])\n",
    "\n",
    "            _apply_logy_if_possible(ax, series_for_log)\n",
    "            ax.set_title(\"SSP2-4.5 — AB1 vs AB2\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Excedência (%)\")\n",
    "            ax.set_ylabel(\"Q (m³/s)\")\n",
    "            ax.grid(True, alpha=0.3, which=\"both\")\n",
    "            ax.legend()\n",
    "\n",
    "            # (4) SSP5-8.5: abordagens\n",
    "            ax = axs[3]\n",
    "            series_for_log = []\n",
    "\n",
    "            if ref_curve is not None and not ref_curve.empty:\n",
    "                ax.plot(\n",
    "                    ref_curve[\"exc\"], ref_curve[\"q_ref\"],\n",
    "                    color=REF_COLOR, linestyle=REF_LINESTYLE, linewidth=REF_LINEWIDTH,\n",
    "                    alpha=REF_ALPHA, label=REF_LABEL, zorder=REF_ZORDER\n",
    "                )\n",
    "                series_for_log.append(ref_curve[\"q_ref\"])\n",
    "\n",
    "            for ab in [\"AB1\",\"AB2\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==ab) & (gh[\"Scenario\"]==\"SSP5-8.5\")].sort_values(\"exc\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                label = f\"SSP5-8.5 — {ab}\"\n",
    "                ax.plot(gg[\"exc\"], gg[\"q_sim\"], linewidth=2, label=label, color=COLOR_PALETTE[label], zorder=3)\n",
    "                series_for_log.append(gg[\"q_sim\"])\n",
    "\n",
    "            _apply_logy_if_possible(ax, series_for_log)\n",
    "            ax.set_title(\"SSP5-8.5 — AB1 vs AB2\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Excedência (%)\")\n",
    "            ax.set_ylabel(\"Q (m³/s)\")\n",
    "            ax.grid(True, alpha=0.3, which=\"both\")\n",
    "            ax.legend()\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"FDC (Ensemble) — Estação {nome} | {est} | Horizonte {format_horizonte(hz)}\",\n",
    "                y=0.98, fontsize=14, fontweight='bold'\n",
    "            )\n",
    "            fig.tight_layout(rect=[0, 0, 1, 0.965])\n",
    "\n",
    "            fn = out_dir / f\"FDC_COMP_{est}_{mini}_{hz}.png\"\n",
    "            fig.savefig(fn, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_saz_compare(saz: pd.DataFrame) -> None:\n",
    "    s = filter_saz_ensemble(saz)\n",
    "\n",
    "    out_dir = OUT_DIR / \"figures\" / \"SAZONAL\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for (est, mini, nome_est), g0 in s.groupby([\"estacao_obs\",\"codigo_mini\",\"nome_estacao\"]):\n",
    "\n",
    "        # ---- REFERÊNCIA ROBUSTA (agora filtra est+mini e usa fallbacks) ----\n",
    "        ref_monthly = get_reference_saz_monthly(saz, int(est), int(mini))\n",
    "\n",
    "        if ref_monthly is None or ref_monthly.empty:\n",
    "            hz_list = (\n",
    "                saz[(saz[\"estacao_obs\"] == est) & (saz[\"codigo_mini\"] == mini)][\"horizonte\"]\n",
    "                .dropna().unique()\n",
    "            )\n",
    "            print(f\"\\n[SAZ] Estação {est} ({nome_est}) mini={mini}\")\n",
    "            print(\"  ✗ Referência NÃO encontrada (após fallbacks).\")\n",
    "            print(\"  - Horizontes (est+mini):\")\n",
    "            for hz in hz_list:\n",
    "                print(f\"    - {hz}\")\n",
    "            if \"fonte\" in saz.columns:\n",
    "                fontes = saz[(saz[\"estacao_obs\"] == est) & (saz[\"codigo_mini\"] == mini)][\"fonte\"].dropna().unique()\n",
    "                print(f\"  - Fontes (est+mini): {list(fontes)[:20]}\")\n",
    "            if \"modelo\" in saz.columns:\n",
    "                modelos = saz[(saz[\"estacao_obs\"] == est) & (saz[\"codigo_mini\"] == mini)][\"modelo\"].dropna().unique()\n",
    "                print(f\"  - Modelos (est+mini) [amostra]: {list(modelos)[:10]}\")\n",
    "        else:\n",
    "            print(f\"\\n[SAZ] Estação {est} ({nome_est}) mini={mini} — ✓ Referência OK: {len(ref_monthly)} meses\")\n",
    "\n",
    "        for hz, gh in g0.groupby(\"horizonte\"):\n",
    "\n",
    "            fig = plt.figure(figsize=(13, 10))\n",
    "            axs = [fig.add_subplot(2,2,i+1) for i in range(4)]\n",
    "\n",
    "            # função auxiliar para plotar a referência (suavizada)\n",
    "            def _plot_ref(ax_):\n",
    "                if ref_monthly is None or ref_monthly.empty:\n",
    "                    return\n",
    "                x_ref = ref_monthly[\"mes\"].to_numpy()\n",
    "                y_ref = ref_monthly[\"Q_medio\"].to_numpy()\n",
    "\n",
    "                if USE_PCHIP and len(x_ref) >= 4:\n",
    "                    x_dense = np.linspace(1, 12, 200)\n",
    "                    y_dense = PchipInterpolator(x_ref, y_ref)(x_dense)\n",
    "                    ax_.plot(\n",
    "                        x_dense, y_dense,\n",
    "                        color=REF_COLOR, linestyle=REF_LINESTYLE,\n",
    "                        linewidth=REF_LINEWIDTH, alpha=REF_ALPHA,\n",
    "                        label=REF_LABEL, zorder=REF_ZORDER\n",
    "                    )\n",
    "                    ax_.scatter(\n",
    "                        x_ref, y_ref,\n",
    "                        color=REF_COLOR, edgecolor=\"black\",\n",
    "                        linewidth=0.6, s=25, alpha=REF_ALPHA, zorder=REF_ZORDER\n",
    "                    )\n",
    "                else:\n",
    "                    ax_.plot(\n",
    "                        x_ref, y_ref,\n",
    "                        marker=\"o\", color=REF_COLOR, linestyle=REF_LINESTYLE,\n",
    "                        linewidth=REF_LINEWIDTH, alpha=REF_ALPHA,\n",
    "                        label=REF_LABEL, zorder=REF_ZORDER\n",
    "                    )\n",
    "\n",
    "            # (1) AB1: cenários\n",
    "            ax = axs[0]\n",
    "            _plot_ref(ax)\n",
    "\n",
    "            for scn in [\"SSP2-4.5\",\"SSP5-8.5\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==\"AB1\") & (gh[\"Scenario\"]==scn)].sort_values(\"mes\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                x = gg[\"mes\"].to_numpy()\n",
    "                y = gg[\"Q_medio\"].to_numpy()\n",
    "                label = f\"{scn} — AB1\"\n",
    "                color = COLOR_PALETTE[label]\n",
    "\n",
    "                if USE_PCHIP and len(x) >= 4:\n",
    "                    x_dense = np.linspace(1, 12, 200)\n",
    "                    y_dense = PchipInterpolator(x, y)(x_dense)\n",
    "                    ax.plot(x_dense, y_dense, linewidth=2, label=label, color=color, zorder=3)\n",
    "                    ax.scatter(x, y, color=color, edgecolor=\"black\", linewidth=0.6, s=35, zorder=3)\n",
    "                else:\n",
    "                    ax.plot(x, y, marker=\"o\", linewidth=2, label=label, color=color, zorder=3)\n",
    "\n",
    "            ax.set_title(\"AB1 — SSP2-4.5 vs SSP5-8.5\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Mês\")\n",
    "            ax.set_ylabel(\"Q média mensal (m³/s)\")\n",
    "            ax.set_xticks(MONTH_ORDER)\n",
    "            ax.set_xticklabels(MONTH_LABELS_PT)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "\n",
    "            # (2) AB2: cenários\n",
    "            ax = axs[1]\n",
    "            _plot_ref(ax)\n",
    "\n",
    "            for scn in [\"SSP2-4.5\",\"SSP5-8.5\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==\"AB2\") & (gh[\"Scenario\"]==scn)].sort_values(\"mes\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                x = gg[\"mes\"].to_numpy()\n",
    "                y = gg[\"Q_medio\"].to_numpy()\n",
    "                label = f\"{scn} — AB2\"\n",
    "                color = COLOR_PALETTE[label]\n",
    "\n",
    "                if USE_PCHIP and len(x) >= 4:\n",
    "                    x_dense = np.linspace(1, 12, 200)\n",
    "                    y_dense = PchipInterpolator(x, y)(x_dense)\n",
    "                    ax.plot(x_dense, y_dense, linewidth=2, label=label, color=color, zorder=3)\n",
    "                    ax.scatter(x, y, color=color, edgecolor=\"black\", linewidth=0.6, s=35, zorder=3)\n",
    "                else:\n",
    "                    ax.plot(x, y, marker=\"o\", linewidth=2, label=label, color=color, zorder=3)\n",
    "\n",
    "            ax.set_title(\"AB2 — SSP2-4.5 vs SSP5-8.5\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Mês\")\n",
    "            ax.set_ylabel(\"Q média mensal (m³/s)\")\n",
    "            ax.set_xticks(MONTH_ORDER)\n",
    "            ax.set_xticklabels(MONTH_LABELS_PT)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "\n",
    "            # (3) SSP2-4.5: abordagens\n",
    "            ax = axs[2]\n",
    "            _plot_ref(ax)\n",
    "\n",
    "            for ab in [\"AB1\",\"AB2\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==ab) & (gh[\"Scenario\"]==\"SSP2-4.5\")].sort_values(\"mes\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                x = gg[\"mes\"].to_numpy()\n",
    "                y = gg[\"Q_medio\"].to_numpy()\n",
    "                label = f\"SSP2-4.5 — {ab}\"\n",
    "                color = COLOR_PALETTE[label]\n",
    "\n",
    "                if USE_PCHIP and len(x) >= 4:\n",
    "                    x_dense = np.linspace(1, 12, 200)\n",
    "                    y_dense = PchipInterpolator(x, y)(x_dense)\n",
    "                    ax.plot(x_dense, y_dense, linewidth=2, label=label, color=color, zorder=3)\n",
    "                    ax.scatter(x, y, color=color, edgecolor=\"black\", linewidth=0.6, s=35, zorder=3)\n",
    "                else:\n",
    "                    ax.plot(x, y, marker=\"o\", linewidth=2, label=label, color=color, zorder=3)\n",
    "\n",
    "            ax.set_title(\"SSP2-4.5 — AB1 vs AB2\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Mês\")\n",
    "            ax.set_ylabel(\"Q média mensal (m³/s)\")\n",
    "            ax.set_xticks(MONTH_ORDER)\n",
    "            ax.set_xticklabels(MONTH_LABELS_PT)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "\n",
    "            # (4) SSP5-8.5: abordagens\n",
    "            ax = axs[3]\n",
    "            _plot_ref(ax)\n",
    "\n",
    "            for ab in [\"AB1\",\"AB2\"]:\n",
    "                gg = gh[(gh[\"Approach\"]==ab) & (gh[\"Scenario\"]==\"SSP5-8.5\")].sort_values(\"mes\")\n",
    "                if gg.empty:\n",
    "                    continue\n",
    "                x = gg[\"mes\"].to_numpy()\n",
    "                y = gg[\"Q_medio\"].to_numpy()\n",
    "                label = f\"SSP5-8.5 — {ab}\"\n",
    "                color = COLOR_PALETTE[label]\n",
    "\n",
    "                if USE_PCHIP and len(x) >= 4:\n",
    "                    x_dense = np.linspace(1, 12, 200)\n",
    "                    y_dense = PchipInterpolator(x, y)(x_dense)\n",
    "                    ax.plot(x_dense, y_dense, linewidth=2, label=label, color=color, zorder=3)\n",
    "                    ax.scatter(x, y, color=color, edgecolor=\"black\", linewidth=0.6, s=35, zorder=3)\n",
    "                else:\n",
    "                    ax.plot(x, y, marker=\"o\", linewidth=2, label=label, color=color, zorder=3)\n",
    "\n",
    "            ax.set_title(\"SSP5-8.5 — AB1 vs AB2\", fontweight='bold')\n",
    "            ax.set_xlabel(\"Mês\")\n",
    "            ax.set_ylabel(\"Q média mensal (m³/s)\")\n",
    "            ax.set_xticks(MONTH_ORDER)\n",
    "            ax.set_xticklabels(MONTH_LABELS_PT)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Vazão média mensal (Ensemble) — Estação {nome_est} | {est} | Horizonte {format_horizonte(hz)}\",\n",
    "                y=0.98, fontsize=14, fontweight='bold'\n",
    "            )\n",
    "            fig.tight_layout(rect=[0, 0, 1, 0.965])\n",
    "\n",
    "            fn = out_dir / f\"SAZ_COMP_{est}_{mini}_{hz}.png\"\n",
    "            fig.savefig(fn, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARATIVO FDC + SAZONALIDADE - LEGENDAS PADRONIZADAS\")\n",
    "    print(\"Formato: SSP2-4.5 — AB1, SSP2-4.5 — AB2, SSP5-8.5 — AB1, SSP5-8.5 — AB2\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    fdc, saz = build_master_frames()\n",
    "\n",
    "    print(f\"\\n[INFO] FDC carregado: {len(fdc)} linhas\")\n",
    "    print(f\"[INFO] SAZ carregado: {len(saz)} linhas\")\n",
    "\n",
    "    # Verificar dados antes de processar\n",
    "    print(\"\\n[INFO] Combinações FDC disponíveis:\")\n",
    "    if \"Approach\" in fdc.columns and \"Scenario\" in fdc.columns:\n",
    "        print(fdc.groupby([\"Approach\",\"Scenario\"]).size())\n",
    "    else:\n",
    "        print(\"  (colunas Approach/Scenario ausentes)\")\n",
    "\n",
    "    print(\"\\n[INFO] Combinações SAZ disponíveis:\")\n",
    "    if \"Approach\" in saz.columns and \"Scenario\" in saz.columns:\n",
    "        print(saz.groupby([\"Approach\",\"Scenario\"]).size())\n",
    "    else:\n",
    "        print(\"  (colunas Approach/Scenario ausentes)\")\n",
    "\n",
    "    # tabelas\n",
    "    print(\"\\n[INFO] Gerando tabelas resumo...\")\n",
    "    fdc_sum = summarize_fdc_pkeys(fdc)\n",
    "    saz_sum = summarize_saz_monthly(saz)\n",
    "\n",
    "    fdc_sum.to_csv(OUT_DIR / \"tables\" / \"fdc_pkeys_summary.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    saz_sum.to_csv(OUT_DIR / \"tables\" / \"saz_monthly_summary.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    fdc_sum.to_excel(OUT_DIR / \"tables\" / \"fdc_pkeys_summary.xlsx\", index=False)\n",
    "    saz_sum.to_excel(OUT_DIR / \"tables\" / \"saz_monthly_summary.xlsx\", index=False)\n",
    "    print(f\"  -> Tabelas salvas em {OUT_DIR / 'tables'}\")\n",
    "\n",
    "    # figuras\n",
    "    print(\"\\n[INFO] Gerando figuras FDC...\")\n",
    "    plot_fdc_compare(fdc)\n",
    "\n",
    "    print(\"\\n[INFO] Gerando figuras Sazonalidade...\")\n",
    "    plot_saz_compare(saz)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ CONCLUÍDO — Todas as saídas em: {OUT_DIR}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
