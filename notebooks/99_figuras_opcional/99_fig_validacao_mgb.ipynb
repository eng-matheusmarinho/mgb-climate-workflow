{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d0dd09",
   "metadata": {},
   "source": [
    "# Graficos Validaco MGB\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a c√©lula **CONFIGURA√á√ïES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURA√á√ïES (edite se necess√°rio)\n",
    "# A pasta raiz do projeto (por padr√£o, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea90a0-588d-4096-802b-11f3450e9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Script: Avalia√ß√£o de Desempenho do MGB com Vaz√µes Observadas\n",
    "# ------------------------------------------------------------\n",
    "# Objetivo:\n",
    "# Ler s√©ries temporais de vaz√µes observadas e simuladas pelo modelo MGB,\n",
    "# calcular m√©tricas de desempenho e gerar dois gr√°ficos:\n",
    "# (1) Compara√ß√£o temporal das s√©ries;\n",
    "# (2) Curva de perman√™ncia em escala logar√≠tmica.\n",
    "#\n",
    "# M√©tricas calculadas:\n",
    "# - NSE (Nash-Sutcliffe Efficiency)\n",
    "# - NSE Logar√≠tmico\n",
    "# - RMSE (Erro Quadr√°tico M√©dio)\n",
    "# - BIAS (%)\n",
    "# - Erro relativo no Q90 (%)\n",
    "# - Erro relativo no Q95 (%)\n",
    "#\n",
    "# Entradas:\n",
    "# - Arquivo de vaz√£o observada (.txt, com colunas dia, m√™s, ano, valor)\n",
    "# - Arquivo de vaz√£o simulada do MGB (.txt, formato SIM_MC_XXXX.TXT)\n",
    "#\n",
    "# Sa√≠das:\n",
    "# - Arquivo PNG com gr√°fico de s√©ries temporais\n",
    "# - Arquivo PNG com gr√°fico da curva de perman√™ncia\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir per√≠odo de an√°lise \"aaaa-mm-dd\"\n",
    "data_inicio = \"1980-01-01\"\n",
    "data_fim = \"1990-12-31\"\n",
    "\n",
    "# Definir nomes dos arquivos de entrada e sa√≠da\n",
    "codigo_estacao = \"65035000\"\n",
    "codigo_mini = \"832\"\n",
    "grafico_saida = \"Porto Amazonas_calib\"\n",
    "grafico_curva_saida = \"Porto Amazonas_curva_perm\"\n",
    "\n",
    "# Caminhos completos\n",
    "caminho_input_obs = r\"C:\\Users\\Matheus Marinho\\Desktop\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Input\\ascii_mgb/\"\n",
    "caminho_input_sim = r\"C:\\Users\\Matheus Marinho\\Desktop\\IGUA√áU_OTTO\\6_Calibra√ß√£o\\2_Projeto\\Output/\"\n",
    "caminho_output = r\"C:\\Users\\Matheus Marinho\\Desktop\\IGUA√áU_OTTO\\8_Resultados\\Calibra√ß√£o_MGB/\"\n",
    "\n",
    "caminho_obs = f\"{caminho_input_obs}{codigo_estacao}.txt\"\n",
    "caminho_sim = f\"{caminho_input_sim}SIM_MC_{codigo_mini}.txt\"\n",
    "caminho_saida = f\"{caminho_output}{grafico_saida}.png\"\n",
    "caminho_curva_saida = f\"{caminho_output}{grafico_curva_saida}.png\"\n",
    "\n",
    "def ler_arquivo_txt(caminho, tipo=\"observado\"):\n",
    "    try:\n",
    "        df = pd.read_csv(caminho, sep=r'\\s+', engine='python', header=None)\n",
    "        df.columns = [\"dia\", \"mes\", \"ano\", \"valor\"]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o arquivo {caminho}: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüìÇ Lendo arquivo ({tipo}): {caminho}\")\n",
    "    print(\"üîç Pr√©-visualiza√ß√£o do conte√∫do lido:\")\n",
    "    #print(df.head())\n",
    "\n",
    "    # Verifica√ß√£o expl√≠cita\n",
    "    if not all(col in df.columns for col in [\"dia\", \"mes\", \"ano\", \"valor\"]):\n",
    "        print(\"‚ùå As colunas esperadas n√£o foram encontradas.\")\n",
    "        return None\n",
    "\n",
    "    # Convers√µes\n",
    "    for col in [\"dia\", \"mes\", \"ano\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[\"valor\"] = pd.to_numeric(df[\"valor\"], errors=\"coerce\")\n",
    "\n",
    "    df.loc[df[\"valor\"] == -1, \"valor\"] = np.nan\n",
    "\n",
    "    if df[[\"ano\", \"mes\", \"dia\"]].isna().any().any():\n",
    "        print(f\"\\n‚ùå Erro: Algumas datas est√£o incompletas no arquivo ({tipo})!\")\n",
    "        #print(df[df[[\"ano\", \"mes\", \"dia\"]].isna().any(axis=1)].head())\n",
    "        return None\n",
    "\n",
    "    # Agora cria coluna de data com nomes que o pandas espera\n",
    "    df[\"data\"] = pd.to_datetime(\n",
    "    df.rename(columns={\"ano\": \"year\", \"mes\": \"month\", \"dia\": \"day\"})[[\"year\", \"month\", \"day\"]],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "    df.set_index(\"data\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calcular_metricas(obs, sim):\n",
    "    df = pd.DataFrame({\"obs\": obs, \"sim\": sim}).dropna()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"‚ùå Erro: Nenhuma observa√ß√£o v√°lida ap√≥s limpeza.\")\n",
    "        return None\n",
    "\n",
    "    nse = 1 - (np.sum((df[\"obs\"] - df[\"sim\"]) ** 2) / np.sum((df[\"obs\"] - df[\"obs\"].mean()) ** 2))\n",
    "    nse_log = 1 - (np.sum((np.log(df[\"obs\"].replace(0, np.nan)) - np.log(df[\"sim\"].replace(0, np.nan))) ** 2) /\n",
    "                    np.sum((np.log(df[\"obs\"].replace(0, np.nan)) - np.log(df[\"obs\"].replace(0, np.nan)).mean()) ** 2))\n",
    "    rmse = np.sqrt(np.mean((df[\"obs\"] - df[\"sim\"]) ** 2))\n",
    "    bias = np.mean(df[\"obs\"] - df[\"sim\"]) / np.mean(df[\"obs\"]) * 100\n",
    "\n",
    "    q90_obs = np.percentile(df[\"obs\"].dropna(), 10)\n",
    "    q90_sim = np.percentile(df[\"sim\"].dropna(), 10)\n",
    "    erro_q90 = ((q90_sim - q90_obs) / q90_obs) * 100\n",
    "\n",
    "    q95_obs = np.percentile(df[\"obs\"].dropna(), 5)\n",
    "    q95_sim = np.percentile(df[\"sim\"].dropna(), 5)\n",
    "    erro_q95 = ((q95_sim - q95_obs) / q95_obs) * 100\n",
    "\n",
    "    return {\"NSE\": nse, \"NSE Log\": nse_log, \"RMSE\": rmse, \"BIAS (%)\": bias, \"Œî Q90 (%)\": erro_q90, \"Œî Q95 (%)\": erro_q95}\n",
    "\n",
    "def plotar_series(df_obs, df_sim, metricas, caminho_saida=None):\n",
    "    df_merged = df_obs.join(df_sim, lsuffix=\"_obs\", rsuffix=\"_sim\", how=\"inner\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_merged.index, df_merged[\"valor_obs\"], label=\"Observado\", color=\"black\", linewidth=1.5)\n",
    "    plt.plot(df_merged.index, df_merged[\"valor_sim\"], label=\"Simulado\", color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    plt.title(\"Verifica√ß√£o entre as Vaz√µes observadas e simuladas\")\n",
    "    plt.legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.2), ncol=2, frameon=False)\n",
    "    plt.grid()\n",
    "\n",
    "    texto_metricas = \"\\n\".join([f\"{k}: {v:.3f}\" for k, v in metricas.items()])\n",
    "    plt.text(0.02, 0.98, texto_metricas, transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if caminho_saida:\n",
    "        plt.savefig(caminho_saida, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"üìÅ Gr√°fico salvo em: {caminho_saida}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plotar_curva_permanencia(df_obs, df_sim, caminho_saida=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for df, label, color in zip([df_obs, df_sim], [\"Observado\", \"Simulado\"], [\"black\", \"red\"]):\n",
    "        valores_ordenados = np.sort(df[\"valor\"].dropna())[::-1]\n",
    "        excedencia = np.linspace(0, 100, len(valores_ordenados))\n",
    "        plt.plot(excedencia, valores_ordenados, label=label, color=color)\n",
    "\n",
    "    q90_obs = np.percentile(df_obs[\"valor\"].dropna(), 10)\n",
    "    q90_sim = np.percentile(df_sim[\"valor\"].dropna(), 10)\n",
    "    plt.plot([], [], color=\"black\", linestyle=\"dashed\", label=f\"Q90 Obs: {q90_obs:.2f}\")\n",
    "    plt.plot([], [], color=\"red\", linestyle=\"dashed\", label=f\"Q90 Sim: {q90_sim:.2f}\")\n",
    "\n",
    "    plt.xlabel(\"Exced√™ncia (%)\")\n",
    "    plt.ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Curva de Perman√™ncia\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    if caminho_saida:\n",
    "        plt.savefig(caminho_saida, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"üìÅ Curva de perman√™ncia salva em: {caminho_saida}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Processamento principal\n",
    "df_obs = ler_arquivo_txt(caminho_obs, tipo=\"observado\")\n",
    "df_sim = ler_arquivo_txt(caminho_sim, tipo=\"simulado\")\n",
    "\n",
    "if df_obs is not None and df_sim is not None:\n",
    "    print(\"\\n‚úÖ Arquivos lidos com sucesso!\")\n",
    "    df_obs_filtrado = df_obs.loc[data_inicio:data_fim]\n",
    "    df_sim_filtrado = df_sim.loc[data_inicio:data_fim]\n",
    "\n",
    "    df_obs_filtrado[\"valor\"] = df_obs_filtrado[\"valor\"].replace(0, 1e-2)\n",
    "    df_sim_filtrado[\"valor\"] = df_sim_filtrado[\"valor\"].replace(0, 1e-2)\n",
    "\n",
    "    metricas = calcular_metricas(df_obs_filtrado[\"valor\"], df_sim_filtrado[\"valor\"])\n",
    "\n",
    "    print(\"\\nüìä M√©tricas de desempenho:\")\n",
    "    for chave, valor in metricas.items():\n",
    "        print(f\"   {chave}: {valor:.4f}\")\n",
    "\n",
    "    plotar_series(df_obs_filtrado, df_sim_filtrado, metricas, caminho_saida=caminho_saida)\n",
    "    plotar_curva_permanencia(df_obs_filtrado, df_sim_filtrado, caminho_saida=caminho_curva_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092af74-e40c-4cd1-8ca8-24cd0d0bdbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Script: Gera√ß√£o Autom√°tica de Gr√°ficos de Calibra√ß√£o do MGB\n",
    "# ------------------------------------------------------------\n",
    "# sub-bacias, calcular m√©tricas de desempenho e gerar:\n",
    "# (1) Gr√°fico de compara√ß√£o temporal\n",
    "# (2) Curva de perman√™ncia\n",
    "#\n",
    "# Entradas:\n",
    "# - Um CSV de mapeamento com as colunas:\n",
    "#   estacao_obs;codigo_mini;nome_estacao\n",
    "# - Arquivos de vaz√£o observada (.txt): ascii_mgb/<estacao_obs>.txt\n",
    "# - Arquivos de vaz√£o simulada do MGB: Output/SIM_MC_<codigo_mini>.TXT\n",
    "#\n",
    "# Sa√≠das:\n",
    "# - PNG com gr√°fico de s√©ries temporais\n",
    "# - PNG com curva de perman√™ncia\n",
    "# - CSV com m√©tricas por esta√ß√£o\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# === Par√¢metros gerais ===\n",
    "data_inicio     = \"1980-01-01\"\n",
    "data_fim        = \"1990-12-31\"\n",
    "\n",
    "# === Caminhos principais ===\n",
    "caminho_input_obs = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Input\\ascii_mgb\")\n",
    "caminho_input_sim = Path(r\"E:\\IGUA√áU_OTTO\\6_Calibra√ß√£o\\2_Projeto\\Output\")\n",
    "caminho_output    = Path(r\"E:\\IGUA√áU_OTTO\\6_Calibra√ß√£o\\Calibra√ß√£o_MGB\")\n",
    "mapeamento_csv    = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Esta√ß√µes_mini.csv\")\n",
    "\n",
    "# === Fun√ß√£o de leitura ===\n",
    "def ler_arquivo_txt(caminho, tipo=\"observado\"):\n",
    "    try:\n",
    "        df = pd.read_csv(caminho, sep=r'\\s+', header=None, names=[\"dia\", \"mes\", \"ano\", \"valor\"], dtype=str)\n",
    "\n",
    "        # Remove v√≠rgulas como separador de milhar\n",
    "        df[\"valor\"] = (\n",
    "            df[\"valor\"]\n",
    "            .str.replace(\",\", \"\", regex=False)  # remove separador de milhar\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "        # Substitui -1 por NaN\n",
    "        df.loc[df[\"valor\"] == -1, \"valor\"] = np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler {tipo} em {caminho}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Converte data\n",
    "    df[\"data\"] = pd.to_datetime(\n",
    "        df.rename(columns={\"ano\": \"year\", \"mes\": \"month\", \"dia\": \"day\"})[[\"year\", \"month\", \"day\"]],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df.set_index(\"data\", inplace=True)\n",
    "\n",
    "    if df.index.isna().any():\n",
    "        print(f\"‚ùå {tipo.capitalize()} possui datas inv√°lidas.\")\n",
    "        return None\n",
    "\n",
    "    return dfObjetivo:\n",
    "# Automatizar a leitura das s√©ries observadas e simuladas de m√∫ltiplas\n",
    "# \n",
    "\n",
    "# === Fun√ß√£o para calcular m√©tricas ===\n",
    "def calcular_metricas(obs, sim):\n",
    "    df = pd.DataFrame({\"obs\": obs, \"sim\": sim}).dropna()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    nse = 1 - ((df[\"obs\"] - df[\"sim\"])**2).sum() / ((df[\"obs\"] - df[\"obs\"].mean())**2).sum()\n",
    "    nse_log = 1 - ((np.log(df[\"obs\"]) - np.log(df[\"sim\"]))**2).sum() / ((np.log(df[\"obs\"]) - np.log(df[\"obs\"]).mean())**2).sum()\n",
    "    #rmse = np.sqrt(((df[\"obs\"] - df[\"sim\"])**2).mean())\n",
    "    bias = ((df[\"sim\"] - df[\"obs\"]).mean() / df[\"obs\"].mean()) * 100\n",
    "    q90_obs, q90_sim = np.percentile(df[\"obs\"], 10), np.percentile(df[\"sim\"], 10)\n",
    "    q95_obs, q95_sim = np.percentile(df[\"obs\"], 5),  np.percentile(df[\"sim\"], 5)\n",
    "\n",
    "    return {\n",
    "        \"NSE\": nse,\n",
    "        \"NSE Log\": nse_log,\n",
    "        #\"RMSE\": rmse,\n",
    "        \"BIAS (%)\": bias,\n",
    "        \"Œî Q90 (%)\": (q90_sim - q90_obs) / q90_obs * 100,\n",
    "        \"Œî Q95 (%)\": (q95_sim - q95_obs) / q95_obs * 100,\n",
    "    }\n",
    "\n",
    "# === Plot de s√©ries temporais ===\n",
    "def plotar_series(df_obs, df_sim, metricas, caminho_saida):\n",
    "    df_merged = df_obs.join(df_sim, lsuffix=\"_obs\", rsuffix=\"_sim\", how=\"inner\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_merged.index, df_merged[\"valor_obs\"], label=\"Observado\", color=\"black\")\n",
    "    plt.plot(df_merged.index, df_merged[\"valor_sim\"], label=\"Simulado\", color=\"red\", linestyle=\"--\")\n",
    "    plt.ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    plt.title(\"S√©ries Temporais Observada vs Simulada\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    texto = \"\\n\".join([f\"{k}: {v:.2f}\" for k, v in metricas.items()])\n",
    "    plt.text(0.01, 0.95, texto, transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor=\"white\", alpha=0.8), verticalalignment='top')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(caminho_saida, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === Plot da curva de perman√™ncia ===\n",
    "def plotar_curva_permanencia(df_obs, df_sim, caminho_saida):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for df, label, color in zip([df_obs, df_sim], [\"Observado\", \"Simulado\"], [\"black\", \"red\"]):\n",
    "        dados = np.sort(df[\"valor\"].dropna())[::-1]\n",
    "        excedencia = np.linspace(0, 100, len(dados))\n",
    "        plt.plot(excedencia, dados, label=label, color=color)\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Exced√™ncia (%)\")\n",
    "    plt.ylabel(\"Vaz√£o (m¬≥/s)\")\n",
    "    plt.title(\"Curva de Perman√™ncia\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(caminho_saida, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === Execu√ß√£o principal ===\n",
    "df_map = pd.read_csv(mapeamento_csv, sep=\";\", dtype=str)\n",
    "todas_metricas = []\n",
    "\n",
    "for _, row in df_map.iterrows():\n",
    "    estacao_obs = row['estacao_obs']\n",
    "    codigo_mini = row['codigo_mini']\n",
    "    nome_estacao = row['nome_estacao'].replace(\" \", \"_\")\n",
    "\n",
    "    caminho_obs = caminho_input_obs / f\"{estacao_obs}.txt\"\n",
    "    caminho_sim = caminho_input_sim / f\"SIM_MC_{codigo_mini}.TXT\"\n",
    "    periodo_str = f\"{data_inicio[:4]}_{data_fim[:4]}\"\n",
    "    saida_grafico = caminho_output / f\"{nome_estacao}_calib_{periodo_str}.png\"\n",
    "    saida_curva   = caminho_output / f\"{nome_estacao}_curva_perm_{periodo_str}.png\"\n",
    "\n",
    "\n",
    "    print(f\"\\nüìÇ Processando esta√ß√£o: {nome_estacao}\")\n",
    "\n",
    "    df_obs = ler_arquivo_txt(caminho_obs, tipo=\"observado\")\n",
    "    df_sim = ler_arquivo_txt(caminho_sim, tipo=\"simulado\")\n",
    "\n",
    "    if df_obs is None or df_sim is None:\n",
    "        print(f\"‚ö†Ô∏è Pulando {nome_estacao} por erro de leitura.\")\n",
    "        continue\n",
    "\n",
    "    df_obs = df_obs.loc[data_inicio:data_fim]\n",
    "    df_sim = df_sim.loc[data_inicio:data_fim]\n",
    "\n",
    "    df_obs[\"valor\"] = df_obs[\"valor\"].replace(0, 1e-2)\n",
    "    df_sim[\"valor\"] = df_sim[\"valor\"].replace(0, 1e-2)\n",
    "\n",
    "    metricas = calcular_metricas(df_obs[\"valor\"], df_sim[\"valor\"])\n",
    "    if metricas is None:\n",
    "        print(f\"‚ö†Ô∏è Sem dados v√°lidos em {nome_estacao}\")\n",
    "        continue\n",
    "\n",
    "    print(\"üìä M√©tricas:\")\n",
    "    for k, v in metricas.items():\n",
    "        print(f\"   {k}: {v:.2f}\")\n",
    "\n",
    "    # Armazena m√©tricas\n",
    "    linha = {\"estacao_obs\": estacao_obs, \"codigo_mini\": codigo_mini, \"nome_estacao\": nome_estacao}\n",
    "    linha.update(metricas)\n",
    "    todas_metricas.append(linha)\n",
    "\n",
    "    plotar_series(df_obs, df_sim, metricas, saida_grafico)\n",
    "    plotar_curva_permanencia(df_obs, df_sim, saida_curva)\n",
    "    print(f\"‚úÖ Gr√°ficos salvos para: {nome_estacao}\")\n",
    "\n",
    "# === Salvamento final das m√©tricas ===\n",
    "df_metricas = pd.DataFrame(todas_metricas)\n",
    "periodo_str = f\"{data_inicio[:4]}_{data_fim[:4]}\"\n",
    "arquivo_metricas = caminho_output / f\"metricas_calibracao_{periodo_str}.csv\"\n",
    "df_metricas.to_csv(arquivo_metricas, sep=\";\", index=False)\n",
    "print(f\"\\nüìÅ Arquivo de m√©tricas salvo em: {arquivo_metricas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52c2a6-1d73-468f-aa0c-fc163e6a0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "periodos = {\"Valida√ß√£o\": (\"1980-01-01\", \"1990-12-31\")}\n",
    "\n",
    "inp_obs = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Input\\ascii_mgb\")\n",
    "inp_sim = Path(r\"E:\\IGUA√áU_OTTO\\6_Calibra√ß√£o\\2_Projeto\\Output\")\n",
    "outdir  = Path(r\"E:\\IGUA√áU_OTTO\\6_Calibra√ß√£o\\Calibra√ß√£o_MGB\")\n",
    "map_csv = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Esta√ß√µes_mini.csv\")\n",
    "map_img = Path(r\"E:\\IGUA√áU_OTTO\\Mapa 05 - Minibacias.png\")\n",
    "\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tamanho f√≠sico do painel\n",
    "W_CM, H_CM = 25.0, 5.0\n",
    "DPI = 400\n",
    "\n",
    "# fontes\n",
    "FS_TITLE, FS_LAB, FS_TICK, FS_STAT = 9.0, 7.0, 6.0, 6.0\n",
    "\n",
    "cm2in = lambda cm: cm/2.54\n",
    "\n",
    "def read_txt(path):\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, names=[\"d\",\"m\",\"y\",\"q\"], dtype=str)\n",
    "    df[\"q\"] = df[\"q\"].str.replace(\",\", \"\", regex=False).astype(float)\n",
    "    df.loc[df[\"q\"] == -1, \"q\"] = np.nan\n",
    "    dt = pd.to_datetime(df.rename(columns={\"y\":\"year\",\"m\":\"month\",\"d\":\"day\"})[[\"year\",\"month\",\"day\"]], errors=\"coerce\")\n",
    "    return df.assign(date=dt).set_index(\"date\")[[\"q\"]].sort_index()\n",
    "\n",
    "def metrics(obs, sim):\n",
    "    df = pd.DataFrame({\"obs\": obs, \"sim\": sim}).dropna()\n",
    "    df = df[(df.obs > 0) & (df.sim > 0)]\n",
    "    if df.empty: return None\n",
    "    nse = 1 - ((df.obs-df.sim)**2).sum() / ((df.obs-df.obs.mean())**2).sum()\n",
    "    nseL = 1 - ((np.log(df.obs)-np.log(df.sim))**2).sum() / ((np.log(df.obs)-np.log(df.obs).mean())**2).sum()\n",
    "    bias = (df.sim.mean()-df.obs.mean())/df.obs.mean()*100\n",
    "    q90o,q90s = np.percentile(df.obs,10), np.percentile(df.sim,10)\n",
    "    q95o,q95s = np.percentile(df.obs, 5), np.percentile(df.sim, 5)\n",
    "    return {\"NSE\":float(nse), \"NSE Log\":float(nseL), \"BIAS (%)\":float(bias),\n",
    "            \"Œî Q90 (%)\":float((q90s-q90o)/q90o*100), \"Œî Q95 (%)\":float((q95s-q95o)/q95o*100)}\n",
    "\n",
    "def fdc(x):\n",
    "    v = np.sort(x.dropna().values)[::-1]\n",
    "    p = np.linspace(0, 100, len(v))\n",
    "    return p, v\n",
    "\n",
    "# ================== RUN ==================\n",
    "img = mpimg.imread(map_img)\n",
    "df_map = pd.read_csv(map_csv, sep=\";\", dtype=str)\n",
    "\n",
    "for _, r in df_map.iterrows():\n",
    "    est = r[\"estacao_obs\"]\n",
    "    cod = r[\"codigo_mini\"]\n",
    "    sub_bacia = r[\"Sub-bacia\"]\n",
    "\n",
    "    # >>> AJUSTE PEDIDO:\n",
    "    # - nome_arquivo: usa _ (seguro p/ salvar arquivo)\n",
    "    # - nome_titulo: sem _ (bonito p/ t√≠tulo da figura)\n",
    "    nome_raw     = r[\"nome_estacao\"]\n",
    "    nome_arquivo = nome_raw.replace(\" \", \"_\")\n",
    "    nome_titulo  = nome_raw.replace(\"_\", \" \")\n",
    "\n",
    "    obs = read_txt(inp_obs / f\"{est}.txt\")\n",
    "    sim = read_txt(inp_sim / f\"SIM_MC_{cod}.TXT\")\n",
    "\n",
    "    obs[\"q\"] = obs[\"q\"].replace(0, 1e-2)\n",
    "    sim[\"q\"] = sim[\"q\"].replace(0, 1e-2)\n",
    "\n",
    "    for rot, (ini, fim) in periodos.items():\n",
    "        periodo_str = f\"{ini[:4]}-{fim[:4]}\"\n",
    "        obs_p = obs.loc[ini:fim]\n",
    "        sim_p = sim.loc[ini:fim]\n",
    "        m = metrics(obs_p[\"q\"], sim_p[\"q\"])\n",
    "        if m is None:\n",
    "            print(f\"‚ö†Ô∏è sem dados: {nome_arquivo} ({rot})\")\n",
    "            continue\n",
    "\n",
    "        # ===== FIG =====\n",
    "        fig = plt.figure(figsize=(cm2in(W_CM), cm2in(H_CM)))\n",
    "\n",
    "        gs = fig.add_gridspec(1, 3, width_ratios=[3.3, 5.3, 4.4], wspace=0.2)\n",
    "\n",
    "        ax0 = fig.add_subplot(gs[0,0])\n",
    "        ax1 = fig.add_subplot(gs[0,1])\n",
    "        ax2 = fig.add_subplot(gs[0,2])\n",
    "\n",
    "        # mapa\n",
    "        ax0.imshow(img, aspect=\"equal\")\n",
    "        ax0.set_axis_off()\n",
    "        ax0.set_title(f\"Sub-bacia {sub_bacia}\", fontsize=FS_LAB, pad=2)\n",
    "\n",
    "        # hidrograma\n",
    "        ax1.plot(obs_p.index, obs_p[\"q\"], color=\"black\", lw=0.85)\n",
    "        ax1.plot(sim_p.index, sim_p[\"q\"], color=\"red\", ls=\"--\", lw=0.85)\n",
    "        ax1.set_ylabel(\"Vaz√£o (m¬≥/s)\", fontsize=FS_LAB, labelpad=4)\n",
    "        ax1.grid(alpha=0.25)\n",
    "        ax1.tick_params(labelsize=FS_TICK)\n",
    "\n",
    "        stat_txt = \"\\n\".join([f\"{k}: {v:.2f}\" for k,v in m.items()])\n",
    "        ax1.text(0.01, 0.98, stat_txt, transform=ax1.transAxes, va=\"top\", ha=\"left\",\n",
    "                 fontsize=FS_STAT, bbox=dict(facecolor=\"white\", alpha=0.85, edgecolor=\"none\", pad=2))\n",
    "\n",
    "        # FDC\n",
    "        p1,v1 = fdc(obs_p[\"q\"]); p2,v2 = fdc(sim_p[\"q\"])\n",
    "        ax2.plot(p1, v1, color=\"black\", lw=0.85)\n",
    "        ax2.plot(p2, v2, color=\"red\", lw=0.85)\n",
    "        ax2.set_yscale(\"log\")\n",
    "        ax2.set_xlabel(\"Exced√™ncia (%)\", fontsize=FS_LAB, labelpad=2)\n",
    "\n",
    "        # ylabel do FDC √† direita\n",
    "        ax2.set_ylabel(\"Vaz√£o (m¬≥/s)\", fontsize=FS_LAB, labelpad=4)\n",
    "        ax2.yaxis.set_label_position(\"left\")\n",
    "        ax2.yaxis.tick_left()\n",
    "\n",
    "        ax2.grid(alpha=0.25)\n",
    "        ax2.tick_params(labelsize=FS_TICK)\n",
    "\n",
    "        # >>> t√≠tulo √∫nico (agora sem _)\n",
    "        fig.suptitle(f\"{nome_titulo} ‚Äì {est} ‚Äì ({periodo_str})\",fontsize=FS_TITLE,y=0.995)\n",
    "\n",
    "\n",
    "        # legenda √∫nica embaixo\n",
    "        h_obs = plt.Line2D([0],[0], color=\"black\", lw=1.3)\n",
    "        h_sim = plt.Line2D([0],[0], color=\"red\", ls=\"--\", lw=1.3)\n",
    "\n",
    "        fig.subplots_adjust(left=0.02, right=0.98, top=0.92, bottom=0.26)\n",
    "\n",
    "        fig.legend([h_obs, h_sim], [\"Observado\", \"Simulado\"], loc=\"lower center\",\n",
    "                   ncol=2, frameon=False, fontsize=FS_LAB, bbox_to_anchor=(0.5, 0.05),\n",
    "                   handlelength=2.5, columnspacing=1.6)\n",
    "\n",
    "        # >>> arquivo segue com _\n",
    "        out_png = outdir / f\"{nome_arquivo}_{rot}_painel_{periodo_str}.png\"\n",
    "        fig.savefig(out_png, dpi=DPI, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"‚úÖ {out_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c7592-3f65-4065-ae83-71657063fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "Estat√≠sticas Descritivas de Vaz√£o ‚Äì Esta√ß√£o Uni√£o da Vit√≥ria (65310000)\n",
    "===============================================================================\n",
    "\n",
    "Objetivo\n",
    "--------\n",
    "Calcular estat√≠sticas descritivas das vaz√µes observadas para dois per√≠odos\n",
    "hist√≥ricos distintos (1931‚Äì2023 e 1980‚Äì2023), permitindo compara√ß√£o direta\n",
    "entre um per√≠odo longo e um per√≠odo recente.\n",
    "\n",
    "Arquivos de entrada\n",
    "-------------------\n",
    "- 65310000_1931-2023.csv\n",
    "- 65310000_1980_2023.csv\n",
    "\n",
    "Formato esperado\n",
    "----------------\n",
    "CSV com separador \";\" e sem cabe√ßalho, contendo:\n",
    "dia;mes;ano;vazao_m3s\n",
    "\n",
    "Sa√≠da\n",
    "-----\n",
    "Arquivo CSV √∫nico com tabela comparativa, pronto para inser√ß√£o na disserta√ß√£o.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ======================================================\n",
    "# CAMINHOS DE ENTRADA\n",
    "# ======================================================\n",
    "\n",
    "file_1931_2023 = Path(\n",
    "    r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Estatisticas\\65310000_1931-2023.csv\"\n",
    ")\n",
    "\n",
    "file_1980_2023 = Path(\n",
    "    r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Estatisticas\\65310000_1980_2023.csv\"\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# LEITURA DOS DADOS (SEM HEADER)\n",
    "# ======================================================\n",
    "\n",
    "cols = [\"dia\", \"mes\", \"ano\", \"vazao_m3s\"]\n",
    "\n",
    "df_1931 = pd.read_csv(file_1931_2023, sep=\";\", header=None, names=cols)\n",
    "df_1980 = pd.read_csv(file_1980_2023, sep=\";\", header=None, names=cols)\n",
    "\n",
    "# Garante vaz√£o num√©rica\n",
    "df_1931[\"vazao_m3s\"] = pd.to_numeric(df_1931[\"vazao_m3s\"], errors=\"coerce\")\n",
    "df_1980[\"vazao_m3s\"] = pd.to_numeric(df_1980[\"vazao_m3s\"], errors=\"coerce\")\n",
    "\n",
    "# ======================================================\n",
    "# FUN√á√ÉO DE ESTAT√çSTICAS DESCRITIVAS\n",
    "# ======================================================\n",
    "\n",
    "def estatisticas_descritivas(serie):\n",
    "    serie = serie.dropna()\n",
    "\n",
    "    return {\n",
    "        \"M√≠nimo (m¬≥/s)\": serie.min(),\n",
    "        \"P5 (m¬≥/s)\": serie.quantile(0.05),\n",
    "        \"Q1 (m¬≥/s)\": serie.quantile(0.25),\n",
    "        \"Mediana (m¬≥/s)\": serie.median(),\n",
    "        \"M√©dia (m¬≥/s)\": serie.mean(),\n",
    "        \"Q3 (m¬≥/s)\": serie.quantile(0.75),\n",
    "        \"P95 (m¬≥/s)\": serie.quantile(0.95),\n",
    "        \"M√°ximo (m¬≥/s)\": serie.max(),\n",
    "        \"Amplitude (m¬≥/s)\": serie.max() - serie.min(),\n",
    "        \"Desvio-padr√£o (m¬≥/s)\": serie.std(),\n",
    "        \"Coef. de varia√ß√£o (%)\": (serie.std() / serie.mean()) * 100,\n",
    "        \"IQR (m¬≥/s)\": serie.quantile(0.75) - serie.quantile(0.25),\n",
    "        \"Assimetria (-)\": serie.skew(),\n",
    "        \"Curtose (-)\": serie.kurtosis()\n",
    "    }\n",
    "\n",
    "# ======================================================\n",
    "# C√ÅLCULO DAS ESTAT√çSTICAS\n",
    "# ======================================================\n",
    "\n",
    "stats_1931 = estatisticas_descritivas(df_1931[\"vazao_m3s\"])\n",
    "stats_1980 = estatisticas_descritivas(df_1980[\"vazao_m3s\"])\n",
    "\n",
    "# ======================================================\n",
    "# TABELA COMPARATIVA FINAL\n",
    "# ======================================================\n",
    "\n",
    "tabela_final = pd.DataFrame({\n",
    "    \"Estat√≠stica\": stats_1931.keys(),\n",
    "    \"1931‚Äì2023\": stats_1931.values(),\n",
    "    \"1980‚Äì2023\": stats_1980.values()\n",
    "})\n",
    "\n",
    "# ======================================================\n",
    "# EXPORTA√á√ÉO\n",
    "# ======================================================\n",
    "\n",
    "output_path = Path(\n",
    "    r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\Estatisticas\\65310000_Estatisticas_Comparativas.csv\"\n",
    ")\n",
    "\n",
    "tabela_final.to_csv(output_path, index=False, sep=\";\")\n",
    "\n",
    "print(\"Arquivo gerado com sucesso:\")\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415daa6-5fd3-4d58-b121-a9afa7c9b80b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "Disponibilidade de dados - Precipita√ß√£o (formato MGB) | PDF A4 paisagem\n",
    "VERS√ÉO MELHORADA - Visualiza√ß√£o aprimorada\n",
    "+ Remove esta√ß√µes sem dados (0% disponibilidade)\n",
    "+ Cores por faixa de disponibilidade anual\n",
    "+ Linhas separadoras entre esta√ß√µes\n",
    "+ Exporta√ß√£o PNG autom√°tica\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURA√á√ïES\n",
    "# =============================================================================\n",
    "\n",
    "INPUT_DIR = Path(r\"E:\\IGUA√áU_OTTO\\3_Esta√ß√µes FLU\\IAT\\ascii_mgb\")\n",
    "OUTPUT_DIR = INPUT_DIR / \"_disponibilidade\"\n",
    "\n",
    "FILE_GLOB = \"*.txt\"\n",
    "STATIONS_PER_PAGE = 45\n",
    "DPI = 300\n",
    "\n",
    "# --- Remo√ß√£o/Separa√ß√£o de esta√ß√µes sem dados ---\n",
    "EMPTY_DIR = INPUT_DIR / \"_sem_dados\"      # destino\n",
    "ACTION_EMPTY = \"move\"                     # \"move\" ou \"copy\"\n",
    "EMPTY_THRESHOLD_PCT = 0.0                 # remove apenas 0% (nenhum dado v√°lido)\n",
    "\n",
    "# --- Exporta√ß√£o PNG ---\n",
    "SAVE_PNG = True  # ‚úì Habilitado por padr√£o\n",
    "PNG_PREFIX = \"disp_precip\"\n",
    "\n",
    "# --- Cores por faixa de disponibilidade ---\n",
    "# Esquema: vermelho (0-25%), laranja (25-50%), amarelo (50-75%), verde (75-100%)\n",
    "COLOR_SCHEME = {\n",
    "    'no_data': '#FFFFFF',      # Branco para sem dados\n",
    "    'very_low': '#D73027',     # Vermelho escuro (0-25%)\n",
    "    'low': '#FC8D59',          # Laranja (25-50%)\n",
    "    'medium': '#FEE090',       # Amarelo claro (50-75%)\n",
    "    'high': '#91CF60',         # Verde claro (75-90%)\n",
    "    'very_high': '#1A9850',    # Verde escuro (90-100%)\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# LEITOR ROBUSTO\n",
    "# =============================================================================\n",
    "\n",
    "_NUM_RE = re.compile(r\"[-+]?\\d+(?:[.,]\\d+)?\")\n",
    "\n",
    "def _to_float_token(tok: str) -> float:\n",
    "    tok = tok.strip()\n",
    "    if \",\" in tok and \".\" in tok:\n",
    "        if tok.rfind(\".\") > tok.rfind(\",\"):\n",
    "            tok = tok.replace(\",\", \"\")\n",
    "        else:\n",
    "            tok = tok.replace(\".\", \"\").replace(\",\", \".\")\n",
    "        return float(tok)\n",
    "    if \",\" in tok:\n",
    "        return float(tok.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "    return float(tok)\n",
    "\n",
    "def read_mgb_precip_file(fp: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with fp.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            nums = _NUM_RE.findall(line)\n",
    "            if len(nums) < 4:\n",
    "                continue\n",
    "            try:\n",
    "                day = int(float(nums[0].replace(\",\", \".\")))\n",
    "                month = int(float(nums[1].replace(\",\", \".\")))\n",
    "                year = int(float(nums[2].replace(\",\", \".\")))\n",
    "                value = _to_float_token(nums[-1])\n",
    "                rows.append((day, month, year, value))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"day\", \"month\", \"year\", \"value\"])\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        dict(year=df[\"year\"], month=df[\"month\"], day=df[\"day\"]),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    df = df.dropna(subset=[\"date\"]).copy().sort_values(\"date\")\n",
    "    df[\"is_valid\"] = df[\"value\"].ge(0.0)  # 0 √© v√°lido; negativo √© faltante\n",
    "    return df[[\"date\", \"value\", \"is_valid\"]]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UTILIT√ÅRIOS\n",
    "# =============================================================================\n",
    "\n",
    "def station_id_from_filename(fp: Path) -> str:\n",
    "    return fp.stem\n",
    "\n",
    "def chunk_list(items: List[str], chunk_size: int) -> List[List[str]]:\n",
    "    return [items[i:i + chunk_size] for i in range(0, len(items), chunk_size)]\n",
    "\n",
    "def format_period(dmin: pd.Timestamp, dmax: pd.Timestamp) -> str:\n",
    "    return f\"{dmin.strftime('%Y-%m-%d')}‚Äì{dmax.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "def build_availability_matrix(\n",
    "    series_by_station: Dict[str, pd.Series],\n",
    "    global_dates: pd.DatetimeIndex\n",
    ") -> Tuple[np.ndarray, List[str], np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Retorna:\n",
    "        mat: matriz de disponibilidade di√°ria (0/1)\n",
    "        station_ids: lista de IDs das esta√ß√µes\n",
    "        pct_valid: % de disponibilidade total\n",
    "        annual_pct: matriz de % de disponibilidade anual (esta√ß√µes x anos)\n",
    "    \"\"\"\n",
    "    station_ids = sorted(series_by_station.keys())\n",
    "    mat = np.zeros((len(station_ids), len(global_dates)), dtype=np.uint8)\n",
    "    pct_valid = np.zeros(len(station_ids), dtype=float)\n",
    "    \n",
    "    # Calcular disponibilidade anual\n",
    "    years = global_dates.year.unique()\n",
    "    annual_pct = np.full((len(station_ids), len(global_dates)), np.nan, dtype=float)\n",
    "\n",
    "    for i, sid in enumerate(station_ids):\n",
    "        s = series_by_station[sid].reindex(global_dates, fill_value=False)\n",
    "        a = s.astype(np.uint8).to_numpy()\n",
    "        mat[i, :] = a\n",
    "        pct_valid[i] = 100.0 * a.mean() if len(a) else 0.0\n",
    "        \n",
    "        # Calcular % por ano para cada data\n",
    "        for j, date in enumerate(global_dates):\n",
    "            year = date.year\n",
    "            year_mask = global_dates.year == year\n",
    "            year_data = a[year_mask]\n",
    "            if len(year_data) > 0:\n",
    "                annual_pct[i, j] = 100.0 * year_data.mean()\n",
    "\n",
    "    return mat, station_ids, pct_valid, annual_pct\n",
    "\n",
    "def get_color_for_availability(pct: float) -> str:\n",
    "    \"\"\"Retorna cor baseada na % de disponibilidade\"\"\"\n",
    "    if np.isnan(pct) or pct == 0:\n",
    "        return COLOR_SCHEME['no_data']\n",
    "    elif pct < 25:\n",
    "        return COLOR_SCHEME['very_low']\n",
    "    elif pct < 50:\n",
    "        return COLOR_SCHEME['low']\n",
    "    elif pct < 75:\n",
    "        return COLOR_SCHEME['medium']\n",
    "    elif pct < 90:\n",
    "        return COLOR_SCHEME['high']\n",
    "    else:\n",
    "        return COLOR_SCHEME['very_high']\n",
    "\n",
    "def plot_page(\n",
    "    mat: np.ndarray,\n",
    "    station_ids: List[str],\n",
    "    pct_valid: np.ndarray,\n",
    "    annual_pct: np.ndarray,\n",
    "    global_dates: pd.DatetimeIndex,\n",
    "    title: str,\n",
    "    subtitle: str,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plota uma p√°gina com visualiza√ß√£o melhorada\"\"\"\n",
    "    \n",
    "    # Tamanho A4 paisagem em polegadas (297mm x 210mm)\n",
    "    fig = plt.figure(figsize=(11.69, 8.27), dpi=DPI)\n",
    "\n",
    "    # Layout com 3 colunas: principal, barra %, legenda\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=1, ncols=3,\n",
    "        width_ratios=[15, 2.5, 2],\n",
    "        left=0.05, right=0.98, top=0.88, bottom=0.12,\n",
    "        wspace=0.15\n",
    "    )\n",
    "    \n",
    "    ax_main = fig.add_subplot(gs[0, 0])\n",
    "    ax_bar = fig.add_subplot(gs[0, 1], sharey=ax_main)\n",
    "    ax_legend = fig.add_subplot(gs[0, 2])\n",
    "    ax_legend.axis('off')\n",
    "\n",
    "    # === PLOT PRINCIPAL com cores por disponibilidade anual ===\n",
    "    x0 = mdates.date2num(global_dates[0].to_pydatetime())\n",
    "    x1 = mdates.date2num(global_dates[-1].to_pydatetime())\n",
    "    \n",
    "    # Criar imagem RGB colorida baseada na disponibilidade anual\n",
    "    img_rgb = np.ones((len(station_ids), len(global_dates), 3))\n",
    "    \n",
    "    for i in range(len(station_ids)):\n",
    "        for j in range(len(global_dates)):\n",
    "            if mat[i, j] == 0:\n",
    "                # Sem dado: branco\n",
    "                color_hex = COLOR_SCHEME['no_data']\n",
    "            else:\n",
    "                # Com dado: cor baseada na disponibilidade anual\n",
    "                pct = annual_pct[i, j]\n",
    "                color_hex = get_color_for_availability(pct)\n",
    "            \n",
    "            # Converter hex para RGB normalizado\n",
    "            color_hex = color_hex.lstrip('#')\n",
    "            rgb = tuple(int(color_hex[k:k+2], 16) / 255.0 for k in (0, 2, 4))\n",
    "            img_rgb[i, j, :] = rgb\n",
    "\n",
    "    ax_main.imshow(\n",
    "        img_rgb,\n",
    "        aspect=\"auto\",\n",
    "        interpolation=\"none\",\n",
    "        extent=(x0, x1, 0, len(station_ids)),\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "\n",
    "    # === LINHAS HORIZONTAIS separando esta√ß√µes ===\n",
    "    for i in range(len(station_ids) + 1):\n",
    "        ax_main.axhline(y=i, color='0.7', linewidth=0.3, alpha=0.5, zorder=10)\n",
    "\n",
    "    # === T√çTULOS E LABELS ===\n",
    "    fig.suptitle(title, fontsize=13, fontweight='bold', y=0.955)\n",
    "    fig.text(0.05, 0.905, subtitle, fontsize=9, style='italic')\n",
    "\n",
    "    # Eixo X - Anos\n",
    "    ax_main.xaxis_date()\n",
    "    ax_main.xaxis.set_major_locator(mdates.YearLocator(base=5))\n",
    "    ax_main.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    ax_main.xaxis.set_minor_locator(mdates.YearLocator(base=1))\n",
    "    ax_main.set_xlabel(\"Ano\", fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Eixo Y - Esta√ß√µes\n",
    "    ax_main.set_ylabel(\"C√≥digo da Esta√ß√£o\", fontsize=10, fontweight='bold')\n",
    "    ax_main.set_yticks(np.arange(len(station_ids)) + 0.5)\n",
    "    ax_main.set_yticklabels(station_ids, fontsize=6, family='monospace')\n",
    "\n",
    "    # Grid vertical leve\n",
    "    ax_main.grid(which=\"major\", axis=\"x\", linewidth=0.4, alpha=0.3, color='0.4')\n",
    "    ax_main.grid(which=\"minor\", axis=\"x\", linewidth=0.2, alpha=0.2, color='0.6')\n",
    "\n",
    "    # === BARRA DE DISPONIBILIDADE TOTAL ===\n",
    "    y = np.arange(len(station_ids)) + 0.5\n",
    "    colors_bar = [get_color_for_availability(p) for p in pct_valid]\n",
    "    \n",
    "    bars = ax_bar.barh(y=y, width=pct_valid, height=0.85, \n",
    "                       color=colors_bar, edgecolor='0.3', linewidth=0.5)\n",
    "    \n",
    "    ax_bar.set_xlim(0, 100)\n",
    "    ax_bar.set_xlabel(\"Disponibilidade\\nTotal (%)\", fontsize=9, fontweight='bold')\n",
    "    ax_bar.set_xticks([0, 25, 50, 75, 100])\n",
    "    ax_bar.tick_params(axis=\"x\", labelsize=8)\n",
    "    ax_bar.tick_params(axis=\"y\", left=False, labelleft=False)\n",
    "    ax_bar.grid(axis='x', alpha=0.3, linewidth=0.3)\n",
    "    \n",
    "    # Adicionar valores de % nas barras (para valores > 15%)\n",
    "    for i, (bar, pct) in enumerate(zip(bars, pct_valid)):\n",
    "        if pct > 15:\n",
    "            ax_bar.text(pct - 2, y[i], f'{pct:.0f}', \n",
    "                       ha='right', va='center', fontsize=5, \n",
    "                       color='white', fontweight='bold')\n",
    "\n",
    "    # === LEGENDA DE CORES ===\n",
    "    ax_legend.set_xlim(0, 1)\n",
    "    ax_legend.set_ylim(0, 1)\n",
    "    \n",
    "    legend_items = [\n",
    "        (COLOR_SCHEME['very_high'], '90-100%', 0.85),\n",
    "        (COLOR_SCHEME['high'], '75-90%', 0.70),\n",
    "        (COLOR_SCHEME['medium'], '50-75%', 0.55),\n",
    "        (COLOR_SCHEME['low'], '25-50%', 0.40),\n",
    "        (COLOR_SCHEME['very_low'], '0-25%', 0.25),\n",
    "        (COLOR_SCHEME['no_data'], 'Sem dado', 0.08),\n",
    "    ]\n",
    "    \n",
    "    ax_legend.text(0.5, 0.98, 'Disponibilidade\\nAnual', \n",
    "                  ha='center', va='top', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    for color, label, y_pos in legend_items:\n",
    "        rect = Rectangle((0.1, y_pos - 0.04), 0.25, 0.06, \n",
    "                        facecolor=color, edgecolor='0.3', linewidth=0.8)\n",
    "        ax_legend.add_patch(rect)\n",
    "        ax_legend.text(0.4, y_pos, label, va='center', fontsize=8)\n",
    "\n",
    "    # === BORDAS ===\n",
    "    for a in [ax_main, ax_bar]:\n",
    "        a.spines['top'].set_linewidth(1.2)\n",
    "        a.spines['right'].set_linewidth(1.2)\n",
    "        a.spines['bottom'].set_linewidth(1.2)\n",
    "        a.spines['left'].set_linewidth(1.2)\n",
    "\n",
    "    # === NOTA DE RODAP√â ===\n",
    "    fig.text(\n",
    "        0.05, 0.06,\n",
    "        \"Nota: As cores representam a disponibilidade de dados v√°lidos (‚â• 0 mm) em cada ano. \"\n",
    "        \"Valores negativos s√£o considerados aus√™ncia de dado.\",\n",
    "        fontsize=7, style='italic', color='0.3'\n",
    "    )\n",
    "    \n",
    "    fig.text(\n",
    "        0.05, 0.03,\n",
    "        f\"Gerado em: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "        fontsize=6, color='0.5'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def relocate_empty_file(src: Path, dest_dir: Path, action: str = \"move\") -> Path:\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dst = dest_dir / src.name\n",
    "    if action == \"move\":\n",
    "        shutil.move(str(src), str(dst))\n",
    "    elif action == \"copy\":\n",
    "        shutil.copy2(str(src), str(dst))\n",
    "    else:\n",
    "        raise ValueError(\"ACTION_EMPTY deve ser 'move' ou 'copy'\")\n",
    "    return dst\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main() -> None:\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = sorted(INPUT_DIR.glob(FILE_GLOB))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Nenhum arquivo encontrado em {INPUT_DIR} com padr√£o {FILE_GLOB}\")\n",
    "\n",
    "    # Separar esta√ß√µes sem dado\n",
    "    series_by_station: Dict[str, pd.Series] = {}\n",
    "    kept_files = []\n",
    "    moved = []\n",
    "    summary_rows = []\n",
    "\n",
    "    print(\"Processando arquivos...\")\n",
    "    for fp in files:\n",
    "        sid = station_id_from_filename(fp)\n",
    "        df = read_mgb_precip_file(fp)\n",
    "\n",
    "        # Caso 1: arquivo sem linhas √∫teis\n",
    "        if df.empty:\n",
    "            reason = \"arquivo sem linhas √∫teis\"\n",
    "            moved.append((fp.name, reason))\n",
    "            relocate_empty_file(fp, EMPTY_DIR, ACTION_EMPTY)\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"station_id\": sid,\n",
    "                \"arquivo\": fp.name,\n",
    "                \"status\": \"sem_dados\",\n",
    "                \"motivo\": reason,\n",
    "                \"data_inicio\": \"\",\n",
    "                \"data_fim\": \"\",\n",
    "                \"n_dias_total\": 0,\n",
    "                \"n_dias_validos\": 0,\n",
    "                \"pct_dias_validos\": 0.0,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Agrega por dia: v√°lido se existir ao menos um registro >=0 no dia\n",
    "        daily_valid = df.groupby(\"date\")[\"is_valid\"].any()\n",
    "\n",
    "        # m√©tricas no per√≠odo do pr√≥prio arquivo\n",
    "        dmin = daily_valid.index.min()\n",
    "        dmax = daily_valid.index.max()\n",
    "        n_total = int(daily_valid.shape[0])\n",
    "        n_valid = int(daily_valid.sum())\n",
    "        pct_here = (100.0 * (n_valid / n_total)) if n_total > 0 else 0.0\n",
    "\n",
    "        # Caso 2: 0 dias v√°lidos\n",
    "        if daily_valid.any() is False:\n",
    "            reason = \"0 dias v√°lidos (>=0)\"\n",
    "            moved.append((fp.name, reason))\n",
    "            relocate_empty_file(fp, EMPTY_DIR, ACTION_EMPTY)\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"station_id\": sid,\n",
    "                \"arquivo\": fp.name,\n",
    "                \"status\": \"sem_dados\",\n",
    "                \"motivo\": reason,\n",
    "                \"data_inicio\": dmin.date().isoformat() if pd.notna(dmin) else \"\",\n",
    "                \"data_fim\": dmax.date().isoformat() if pd.notna(dmax) else \"\",\n",
    "                \"n_dias_total\": n_total,\n",
    "                \"n_dias_validos\": n_valid,\n",
    "                \"pct_dias_validos\": round(pct_here, 4),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Caso 3: abaixo do limiar\n",
    "        if pct_here <= EMPTY_THRESHOLD_PCT:\n",
    "            reason = f\"pct={pct_here:.2f}% <= limiar\"\n",
    "            moved.append((fp.name, reason))\n",
    "            relocate_empty_file(fp, EMPTY_DIR, ACTION_EMPTY)\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"station_id\": sid,\n",
    "                \"arquivo\": fp.name,\n",
    "                \"status\": \"sem_dados\",\n",
    "                \"motivo\": reason,\n",
    "                \"data_inicio\": dmin.date().isoformat() if pd.notna(dmin) else \"\",\n",
    "                \"data_fim\": dmax.date().isoformat() if pd.notna(dmax) else \"\",\n",
    "                \"n_dias_total\": n_total,\n",
    "                \"n_dias_validos\": n_valid,\n",
    "                \"pct_dias_validos\": round(pct_here, 4),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Caso 4: esta√ß√£o plotada (mantida)\n",
    "        series_by_station[sid] = daily_valid\n",
    "        kept_files.append(fp)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"station_id\": sid,\n",
    "            \"arquivo\": fp.name,\n",
    "            \"status\": \"plotada\",\n",
    "            \"motivo\": \"\",\n",
    "            \"data_inicio\": dmin.date().isoformat() if pd.notna(dmin) else \"\",\n",
    "            \"data_fim\": dmax.date().isoformat() if pd.notna(dmax) else \"\",\n",
    "            \"n_dias_total\": n_total,\n",
    "            \"n_dias_validos\": n_valid,\n",
    "            \"pct_dias_validos\": round(pct_here, 4),\n",
    "        })\n",
    "\n",
    "    # Salvar CSV resumo\n",
    "    print(\"Gerando CSV resumo...\")\n",
    "    summary_csv_path = OUTPUT_DIR / \"resumo_disponibilidade_estacoes.csv\"\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "    if not df_summary.empty:\n",
    "        df_summary[\"status_ord\"] = df_summary[\"status\"].map({\"plotada\": 0, \"sem_dados\": 1}).fillna(9)\n",
    "        df_summary = df_summary.sort_values(\n",
    "            by=[\"status_ord\", \"pct_dias_validos\", \"station_id\"],\n",
    "            ascending=[True, False, True]\n",
    "        ).drop(columns=[\"status_ord\"])\n",
    "\n",
    "    df_summary.to_csv(summary_csv_path, index=False, encoding=\"utf-8-sig\", sep=\";\")\n",
    "    print(f\"‚úì CSV resumo: {summary_csv_path}\")\n",
    "\n",
    "    if not series_by_station:\n",
    "        raise RuntimeError(\"Ap√≥s filtrar esta√ß√µes sem dados, n√£o restou nenhuma esta√ß√£o para plotar.\")\n",
    "\n",
    "    # Per√≠odo global\n",
    "    min_date = min(s.index.min() for s in series_by_station.values())\n",
    "    max_date = max(s.index.max() for s in series_by_station.values())\n",
    "    global_dates = pd.date_range(min_date, max_date, freq=\"D\")\n",
    "\n",
    "    all_station_ids = sorted(series_by_station.keys())\n",
    "    pages = chunk_list(all_station_ids, STATIONS_PER_PAGE)\n",
    "\n",
    "    # Gerar PDF e PNG\n",
    "    print(f\"Gerando visualiza√ß√µes ({len(pages)} p√°ginas)...\")\n",
    "    pdf_path = OUTPUT_DIR / \"disponibilidade_precipitacao_MGB_A4_paisagem.pdf\"\n",
    "    \n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        for p, station_chunk in enumerate(pages, start=1):\n",
    "            print(f\"  P√°gina {p}/{len(pages)}...\", end=\" \")\n",
    "            \n",
    "            subdict = {sid: series_by_station[sid] for sid in station_chunk}\n",
    "            mat, station_ids, pct_valid, annual_pct = build_availability_matrix(subdict, global_dates)\n",
    "\n",
    "            title = \"Disponibilidade de Dados de Precipita√ß√£o (Formato MGB)\"\n",
    "            subtitle = (\n",
    "                f\"P√°gina {p}/{len(pages)} | Esta√ß√µes {((p-1)*STATIONS_PER_PAGE)+1}\"\n",
    "                f\"‚Äì{((p-1)*STATIONS_PER_PAGE)+len(station_ids)} de {len(all_station_ids)} | \"\n",
    "                f\"Per√≠odo: {format_period(min_date, max_date)}\"\n",
    "            )\n",
    "\n",
    "            fig = plot_page(mat, station_ids, pct_valid, annual_pct, \n",
    "                          global_dates, title, subtitle)\n",
    "            \n",
    "            # Salvar no PDF\n",
    "            pdf.savefig(fig, dpi=DPI, bbox_inches='tight')\n",
    "            \n",
    "            # Salvar PNG\n",
    "            if SAVE_PNG:\n",
    "                png_path = OUTPUT_DIR / f\"{PNG_PREFIX}_p{p:03d}.png\"\n",
    "                fig.savefig(png_path, dpi=DPI, bbox_inches='tight')\n",
    "                print(f\"‚úì PNG salvo\")\n",
    "            else:\n",
    "                print(\"‚úì\")\n",
    "            \n",
    "            plt.close(fig)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úì PDF gerado: {pdf_path}\")\n",
    "    print(f\"‚úì Esta√ß√µes plotadas: {len(all_station_ids)}\")\n",
    "    print(f\"‚úì Esta√ß√µes sem dados relocadas: {len(moved)} ‚Üí {EMPTY_DIR}\")\n",
    "    \n",
    "    if SAVE_PNG:\n",
    "        print(f\"‚úì Arquivos PNG salvos em: {OUTPUT_DIR}\")\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    if moved and len(moved) <= 10:\n",
    "        print(\"\\nArquivos relocados (sem dados):\")\n",
    "        for name, reason in moved:\n",
    "            print(f\"  ‚Ä¢ {name} | {reason}\")\n",
    "    elif moved:\n",
    "        print(f\"\\n{len(moved)} arquivos relocados. Veja detalhes no CSV resumo.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
