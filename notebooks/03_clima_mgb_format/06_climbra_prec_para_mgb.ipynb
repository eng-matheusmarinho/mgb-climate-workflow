{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70547762",
   "metadata": {},
   "source": [
    "# CLIMBRA PREC\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a célula **CONFIGURAÇÕES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37680fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURAÇÕES (edite se necessário)\n",
    "# A pasta raiz do projeto (por padrão, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce82dc6-fc51-4f26-8839-488d81871677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Extrair e Recortar Dados Climáticos de Arquivos NetCDF (.nc)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descrição:\n",
    "# Este script realiza a leitura de arquivos NetCDF contendo dados climáticos\n",
    "# (por exemplo, precipitação, temperatura, etc.), aplica um recorte espacial \n",
    "# com base em um shapefile (ex: bacia hidrográfica) e exporta os dados \n",
    "# espacialmente recortados para arquivos CSV individuais.\n",
    "#\n",
    "# Etapas:\n",
    "# 1. Define caminhos de entrada e saída, e variável de interesse (ex: 'pr').\n",
    "# 2. Garante que o shapefile esteja no mesmo sistema de coordenadas (WGS84).\n",
    "# 3. Lê cada arquivo NetCDF da pasta e aplica o recorte espacial.\n",
    "# 4. Converte os dados recortados para DataFrame e remove valores nulos.\n",
    "# 5. Salva um arquivo CSV por ponto do grid com nome <modelo>_<lat>_<lon>.csv\n",
    "#\n",
    "# Requisitos:\n",
    "# - Pacotes: xarray, rioxarray, geopandas, pandas, tqdm\n",
    "# - Sistema de coordenadas: EPSG:4326 (WGS84) no shapefile e nos NetCDFs\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrológica e Projeções CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURAÇÕES ===\n",
    "pasta_nc = r\"D:\\SSP5_85\\pr\"\n",
    "caminho_saida = r\"D:\\Intermediario\"\n",
    "shapefile = r\"C:\\Users\\Matheus Marinho\\Desktop\\IGUAÇU_OTTO\\Shp\\Buffer.shp\"\n",
    "variavel = \"pr\"\n",
    "\n",
    "# === Ler shapefile ===\n",
    "bacia = gpd.read_file(shapefile)\n",
    "bacia = bacia.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# === Lista de arquivos ===\n",
    "arquivos_nc = [os.path.join(pasta_nc, f) for f in os.listdir(pasta_nc) if f.endswith(\".nc\")]\n",
    "\n",
    "# === Processamento ===\n",
    "for caminho_nc in tqdm(arquivos_nc, desc=\"Processando arquivos\"):\n",
    "\n",
    "    try:\n",
    "        nome_modelo = os.path.basename(caminho_nc).replace(\".nc\", \"\")\n",
    "        pasta_modelo = os.path.join(caminho_saida, nome_modelo)\n",
    "        os.makedirs(pasta_modelo, exist_ok=True)\n",
    "\n",
    "        ds = xr.open_dataset(caminho_nc)\n",
    "        dados = ds[variavel]\n",
    "        dados.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "        dados.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "        dados_recorte = dados.rio.clip(bacia.geometry, bacia.crs, drop=True)\n",
    "\n",
    "        for lat in dados_recorte.lat.values:\n",
    "            for lon in dados_recorte.lon.values:\n",
    "                try:\n",
    "                    ponto = dados_recorte.sel(lat=lat, lon=lon, method=\"nearest\")\n",
    "                    df_ponto = ponto.to_dataframe().reset_index().dropna(subset=[variavel])\n",
    "\n",
    "                    if df_ponto.empty:\n",
    "                        continue\n",
    "\n",
    "                    nome_ponto = f\"{nome_modelo}_{round(lat, 4)}_{round(lon, 4)}.csv\"\n",
    "                    caminho_csv = os.path.join(pasta_modelo, nome_ponto)\n",
    "                    df_ponto.to_csv(caminho_csv, index=False)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro no ponto lat={lat}, lon={lon}: {e}\")\n",
    "\n",
    "        print(f\">>> Finalizado: {nome_modelo}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {caminho_nc}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e5efb-23f4-4b52-a0d9-88998a430800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Padronizar Séries Temporais Extraídas de Arquivos NetCDF (.nc)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descrição:\n",
    "# Este script processa arquivos CSV gerados a partir de extrações de dados \n",
    "# climáticos (ex: precipitação, temperatura) contidos em arquivos NetCDF.\n",
    "# Ele reorganiza os dados no formato padrão: Dia;Mes;Ano;Valor.\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Detecta automaticamente o separador do CSV.\n",
    "# - Identifica a coluna de tempo e a coluna da variável (ex: 'pr').\n",
    "# - Extrai Dia, Mês, Ano da coluna de tempo.\n",
    "# - Regride 80 anos nos dados (ex: 2015 → 1935).\n",
    "# - Salva os arquivos formatados em uma nova subpasta chamada \"input\", \n",
    "#   espelhando a estrutura de pastas original.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Pacotes: pandas, pathlib, os\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrológica com o MGB e Projeções CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURAÇÃO ===\n",
    "BASE_DIR   = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\")\n",
    "OUTPUT_DIR = BASE_DIR / \"input\"\n",
    "\n",
    "def verificar_csv(path: Path) -> bool:\n",
    "    if path.stat().st_size == 0:\n",
    "        print(f\"Aviso: {path} está vazio.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def process_csv(path: Path):\n",
    "    if not verificar_csv(path):\n",
    "        return\n",
    "\n",
    "    # Tenta detectar separador automaticamente\n",
    "    df = None\n",
    "    for sep in [',',';','\\t']:\n",
    "        try:\n",
    "            tmp = pd.read_csv(path, sep=sep)\n",
    "            if tmp.shape[1] >= 2:\n",
    "                df = tmp\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if df is None:\n",
    "        print(f\"Falha ao ler {path} com delimitadores padrão.\")\n",
    "        return\n",
    "\n",
    "    # Detecta a coluna de tempo e a de valor\n",
    "    col_time = next((col for col in df.columns if \"time\" in col.lower()), df.columns[0])\n",
    "    col_valor = next((col for col in df.columns if col.lower() in [\"pr\", \"valor\", \"value\"]), df.columns[-1])\n",
    "\n",
    "    # Converter datas\n",
    "    df[col_time] = pd.to_datetime(df[col_time], errors='coerce')\n",
    "    df_out = pd.DataFrame({\n",
    "        'Dia':   df[col_time].dt.day,\n",
    "        'Mes':   df[col_time].dt.month,\n",
    "        'Ano':   df[col_time].dt.year,\n",
    "        'Valor': df[col_valor]\n",
    "    })\n",
    "\n",
    "    # Regridar 80 anos\n",
    "    df_out['Ano'] = df_out['Ano'] - 80\n",
    "\n",
    "    # Caminho de saída\n",
    "    rel    = path.relative_to(BASE_DIR)\n",
    "    target = OUTPUT_DIR / rel\n",
    "    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salvar CSV\n",
    "    df_out.to_csv(target, sep=';', index=False)\n",
    "    print(f\"✔️ Salvo: {target}\")\n",
    "\n",
    "def processar_todos():\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    for root, _, files in os.walk(BASE_DIR):\n",
    "        root_path = Path(root)\n",
    "        if OUTPUT_DIR == root_path or OUTPUT_DIR in root_path.parents:\n",
    "            continue\n",
    "        for fname in files:\n",
    "            if fname.lower().endswith('.csv'):\n",
    "                process_csv(root_path / fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processar_todos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12ae94-7a06-44c6-89f8-17558656b4c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Ajustar Datas Incompletas em Séries Temporais (Anos Bissextos + Dia 31)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descrição:\n",
    "# Este script percorre arquivos CSV contendo séries temporais no formato \n",
    "# Dia;Mes;Ano;Valor e insere automaticamente valores faltantes para:\n",
    "# - 29 de fevereiro em anos bissextos, caso não esteja presente;\n",
    "# - Dias 31 nos meses que possuem 31 dias, caso ausentes.\n",
    "#\n",
    "# A linha inserida recebe o valor 0.0 e a posição correta na sequência temporal.\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Lê os arquivos CSV a partir de um diretório de entrada (INPUT_DIR).\n",
    "# - Detecta e preenche datas faltantes com zero.\n",
    "# - Recria a estrutura de subpastas no diretório de saída (OUTPUT_DIR).\n",
    "# - Salva os arquivos corrigidos mantendo o nome original.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Python 3.7+\n",
    "# - Pacotes: pandas, calendar, pathlib\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrológica com o MGB e Projeções CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from pathlib import Path\n",
    "\n",
    "# ——————————————————————————————\n",
    "# Ajuste estes paths\n",
    "INPUT_DIR  = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\\input\")\n",
    "OUTPUT_DIR = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\\input_corrigido\")\n",
    "#————————————————————————————————————————\n",
    "\n",
    "# lista de meses com 31 dias\n",
    "meses_31 = [1, 3, 5, 7, 8, 10, 12]\n",
    "\n",
    "# percorre todos os CSVs dentro de INPUT_DIR (incluindo subpastas)\n",
    "for arquivo in INPUT_DIR.rglob(\"*.csv\"):\n",
    "    # lê o CSV, pulando o header original\n",
    "    df = pd.read_csv(\n",
    "        arquivo,\n",
    "        sep=';',\n",
    "        skiprows=1,\n",
    "        names=['dia','mes','ano','valor'],\n",
    "        dtype={'dia':int, 'mes':int, 'ano':int, 'valor':float}\n",
    "    )\n",
    "    # monta coluna datetime\n",
    "    df['data'] = pd.to_datetime({\n",
    "        'year':  df['ano'],\n",
    "        'month': df['mes'],\n",
    "        'day':   df['dia']\n",
    "    })\n",
    "\n",
    "    insercoes = []\n",
    "    for ano in sorted(df['ano'].unique()):\n",
    "        # 29/02 em ano bissexto\n",
    "        if calendar.isleap(ano) and not ((df['ano']==ano)&(df['mes']==2)&(df['dia']==29)).any():\n",
    "            insercoes.append({\n",
    "                'dia': 29, 'mes': 2, 'ano': ano,\n",
    "                'valor': 0.0,\n",
    "                'data': pd.Timestamp(year=ano, month=2, day=29)\n",
    "            })\n",
    "        # dia 31 nos meses de 31 dias\n",
    "        for mes in meses_31:\n",
    "            if not ((df['ano']==ano)&(df['mes']==mes)&(df['dia']==31)).any():\n",
    "                insercoes.append({\n",
    "                    'dia': 31, 'mes': mes, 'ano': ano,\n",
    "                    'valor': 0.0,\n",
    "                    'data': pd.Timestamp(year=ano, month=mes, day=31)\n",
    "                })\n",
    "\n",
    "    # concatena e ordena\n",
    "    if insercoes:\n",
    "        df = pd.concat([df, pd.DataFrame(insercoes)], ignore_index=True)\n",
    "    df = df.sort_values('data').reset_index(drop=True)\n",
    "\n",
    "    # determina onde salvar, recriando a estrutura de pastas\n",
    "    rel_path = arquivo.relative_to(INPUT_DIR)            # ex: \"ACCESS-…/file.csv\"\n",
    "    out_dir  = OUTPUT_DIR / rel_path.parent              # mantém subpasta\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)           # cria, se necessário\n",
    "\n",
    "    # salva apenas as colunas originais\n",
    "    df[['dia','mes','ano','valor']].to_csv(\n",
    "        out_dir / arquivo.name,\n",
    "        sep=';', index=False, float_format=\"%.1f\"\n",
    "    )\n",
    "\n",
    "    print(f\"Processado: {rel_path} → inseridas {len(insercoes)} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754faf72-5006-47f8-80b8-b20e134befc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Gerar Arquivos ASCII Formatados para Entrada no Modelo MGB\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descrição:\n",
    "# Este script lê arquivos CSV no formato padronizado Dia;Mes;Ano;Valor, \n",
    "# remove o cabeçalho, alinha as colunas em largura fixa (formato ASCII) e \n",
    "# exporta arquivos `.txt` compatíveis com o modelo hidrológico MGB.\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Lê arquivos CSV organizados em subpastas do diretório de entrada.\n",
    "# - Converte o conteúdo para ASCII com espaçamento fixo por coluna.\n",
    "# - Substitui valores ausentes (NaN) por -1.\n",
    "# - Recria a estrutura de subpastas no diretório de saída.\n",
    "# - Salva arquivos `.txt` prontos para uso no MGB.\n",
    "#\n",
    "# Layout final:\n",
    "# - Colunas: dia (6), mes (5), ano (5), valor (15), todas alinhadas à direita.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Python 3.7+\n",
    "# - Pacotes: pandas, numpy, pathlib, glob, os\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrológica com o MGB e Projeções CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Diretórios de entrada e saída\n",
    "INPUT_DIR  = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\\input_corrigido\")\n",
    "OUTPUT_DIR = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\\Output\")\n",
    "\n",
    "# Verifica/cria pasta de saída\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Padrão de nomes e tipos das colunas\n",
    "_columns_names = ['dia', 'mes', 'ano', 'valor']\n",
    "_dtype = {\n",
    "    'dia':   int,\n",
    "    'mes':   int,\n",
    "    'ano':   int,\n",
    "    'valor': float\n",
    "}\n",
    "# Espaços para alinhamento ASCII\n",
    "col_space = [6, 5, 5, 15]\n",
    "\n",
    "# Encontra todos os .csv sob INPUT_DIR, em qualquer subpasta\n",
    "for csv_path in INPUT_DIR.rglob(\"*.csv\"):\n",
    "    # lê pulando o header original \"Dia;Mes;Ano;Valor\"\n",
    "    df = (\n",
    "        pd.read_csv(\n",
    "            csv_path,\n",
    "            delimiter=';',\n",
    "            names=_columns_names,\n",
    "            dtype=_dtype,\n",
    "            skiprows=1\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # formata coluna 'valor' e garante ordem\n",
    "    df['valor'] = df['valor'].apply('{:,.6f}'.format)\n",
    "    df = df[_columns_names]\n",
    "\n",
    "    # determina pasta de saída mantendo a estrutura relativa\n",
    "    rel = csv_path.relative_to(INPUT_DIR)           # ex: ACCESS-CM2/.../ponto.csv\n",
    "    target_dir = OUTPUT_DIR / rel.parent           # ex: output/ACCESS-CM2/...\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # monta nome .txt\n",
    "    txt_name    = csv_path.with_suffix('.txt').name\n",
    "    output_path = target_dir / txt_name\n",
    "\n",
    "    # escreve o ASCII alinhado, sem cabeçalho e sem índice\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\n",
    "            df.to_string(\n",
    "                col_space=col_space,\n",
    "                justify='right',\n",
    "                max_colwidth=16,\n",
    "                index=False,\n",
    "                header=False\n",
    "            )\n",
    "            .replace(\"NaN\", \"-1\")\n",
    "        )\n",
    "\n",
    "    print(f\"Convertido: {csv_path} → {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dc016-1f4c-4846-bbc2-fa909494371e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Renomear Arquivos ASCII do MGB com Códigos de Grade (Grid.csv)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descrição:\n",
    "# Este script percorre arquivos `.txt` gerados para o modelo MGB, localiza os\n",
    "# nomes que contêm coordenadas geográficas (lat/lon) e renomeia os arquivos\n",
    "# com o código correspondente (campo 'Codigo') de 8 dígitos conforme planilha\n",
    "# de mapeamento fornecida (`Grid.csv`).\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Lê a tabela de mapeamento com latitudes, longitudes e códigos do grid.\n",
    "# - Identifica lat/lon no nome dos arquivos via expressão regular.\n",
    "# - Aplica tolerância para casar coordenadas com diferentes casas decimais.\n",
    "# - Renomeia cada arquivo para o código numérico correspondente (ex: 00012345.txt).\n",
    "# - Mantém a estrutura de diretórios e ignora nomes que não seguem o padrão.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Python 3.7+\n",
    "# - Pacotes: pandas, pathlib, re\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrológica com o MGB e Projeções CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ——— Ajuste estes caminhos ———\n",
    "OUTPUT_DIR   = Path(r\"D:\\CLIMBRA_SSP585\\Intermediario\\Output\")\n",
    "MAPPING_FILE = Path(r\"E:\\CLIMBRA\\Extract\\Grid.csv\")\n",
    "# ——————————————————————————\n",
    "\n",
    "# 1) Carrega o mapeamento (sep=';' e colunas Lat, Long, Codigo)\n",
    "df_map = pd.read_csv(MAPPING_FILE, sep=';')\n",
    "df_map['lat']  = df_map['Lat'].astype(float)\n",
    "df_map['lon']  = df_map['Long'].astype(float)\n",
    "df_map['code'] = df_map['Codigo'].astype(str).str.zfill(8)\n",
    "\n",
    "# 2) Regex para extrair modelo, lat e lon do nome (sem extensão)\n",
    "pattern = re.compile(r\"(?P<model>.+)_(?P<lat>[-\\d\\.]+)_(?P<lon>[-\\d\\.]+)$\")\n",
    "\n",
    "# 3) Tolerância para casar truncamentos (2 casas vs 3 casas decimais)\n",
    "tol = 1e-2\n",
    "\n",
    "# 4) Percorre todos os .txt em OUTPUT_DIR\n",
    "for txt_path in OUTPUT_DIR.rglob(\"*.txt\"):\n",
    "    stem = txt_path.stem\n",
    "    m = pattern.match(stem)\n",
    "    if not m:\n",
    "        print(f\"[AVISO] nome fora do padrão, pulando: {txt_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 5) Extrai lat/lon do nome\n",
    "    lat = float(m.group('lat'))\n",
    "    lon = float(m.group('lon'))\n",
    "\n",
    "    # 6) Busca o código dentro da tolerância definida\n",
    "    cond_lat = (df_map['lat'] - lat).abs() < tol\n",
    "    cond_lon = (df_map['lon'] - lon).abs() < tol\n",
    "    match    = df_map[cond_lat & cond_lon]\n",
    "    if match.empty:\n",
    "        print(f\"[ERRO] sem código para lat={lat}, lon={lon} em {txt_path.name}\")\n",
    "        continue\n",
    "    code = match['code'].iloc[0]\n",
    "\n",
    "    # 7) Renomeia o arquivo\n",
    "    new_name = f\"{code}.txt\"\n",
    "    new_path = txt_path.with_name(new_name)\n",
    "    if new_path != txt_path:\n",
    "        txt_path.rename(new_path)\n",
    "        print(f\"{txt_path.name} → {new_name}\")\n",
    "    else:\n",
    "        print(f\"{txt_path.name} já está com nome correto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fa5a9-c448-400e-8ddc-8d92e7babb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
