{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d834e6b",
   "metadata": {},
   "source": [
    "# CLIMBRA CLIMA\n",
    "\n",
    "> Notebook organizado para reprodutibilidade. Edite apenas a c√©lula **CONFIGURA√á√ïES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# CONFIGURA√á√ïES (edite se necess√°rio)\n",
    "# A pasta raiz do projeto (por padr√£o, a pasta acima de /notebooks)\n",
    "ROOT = Path(os.getenv('CLIMBRA_PROJECT_ROOT', Path.cwd().parent)).resolve()\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR  = DATA_DIR / '00_raw'\n",
    "INT_DIR  = DATA_DIR / '01_intermediate'\n",
    "FINAL_DIR= DATA_DIR / '02_final'\n",
    "OUT_DIR  = ROOT / 'outputs'\n",
    "FIG_DIR  = OUT_DIR / 'figures'\n",
    "TAB_DIR  = OUT_DIR / 'tables'\n",
    "\n",
    "for d in [RAW_DIR, INT_DIR, FINAL_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce82dc6-fc51-4f26-8839-488d81871677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Extrair e Recortar Dados Clim√°ticos de Arquivos NetCDF (.nc)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descri√ß√£o:\n",
    "# Este script realiza a leitura de arquivos NetCDF contendo dados clim√°ticos\n",
    "# (por exemplo, precipita√ß√£o, temperatura, etc.), aplica um recorte espacial \n",
    "# com base em um shapefile (ex: bacia hidrogr√°fica) e exporta os dados \n",
    "# espacialmente recortados para arquivos CSV individuais.\n",
    "#\n",
    "# Etapas:\n",
    "# 1. Define caminhos de entrada e sa√≠da, e vari√°vel de interesse (ex: 'pr').\n",
    "# 2. Garante que o shapefile esteja no mesmo sistema de coordenadas (WGS84).\n",
    "# 3. L√™ cada arquivo NetCDF da pasta e aplica o recorte espacial.\n",
    "# 4. Converte os dados recortados para DataFrame e remove valores nulos.\n",
    "# 5. Salva um arquivo CSV por ponto do grid com nome <modelo>_<lat>_<lon>.csv\n",
    "#\n",
    "# Requisitos:\n",
    "# - Pacotes: xarray, rioxarray, geopandas, pandas, tqdm\n",
    "# - Sistema de coordenadas: EPSG:4326 (WGS84) no shapefile e nos NetCDFs\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrol√≥gica e Proje√ß√µes CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "pasta_nc = r\"E:\\Banco de Dados_CLIMBRA\\SSP5_85\\Tmin\"\n",
    "caminho_saida = r\"E:\\CLIMBRA_SSP585\\Tmin\"\n",
    "shapefile = r\"E:\\IGUA√áU_OTTO\\Shp\\Buffer.shp\"\n",
    "variavel = \"tasmin\"\n",
    "\n",
    "# === Ler shapefile ===\n",
    "bacia = gpd.read_file(shapefile)\n",
    "bacia = bacia.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# === Lista de arquivos ===\n",
    "arquivos_nc = [os.path.join(pasta_nc, f) for f in os.listdir(pasta_nc) if f.endswith(\".nc\")]\n",
    "\n",
    "# === Processamento ===\n",
    "for caminho_nc in tqdm(arquivos_nc, desc=\"Processando arquivos\"):\n",
    "\n",
    "    try:\n",
    "        nome_modelo = os.path.basename(caminho_nc).replace(\".nc\", \"\")\n",
    "        pasta_modelo = os.path.join(caminho_saida, nome_modelo)\n",
    "        os.makedirs(pasta_modelo, exist_ok=True)\n",
    "\n",
    "        ds = xr.open_dataset(caminho_nc)\n",
    "        dados = ds[variavel]\n",
    "        dados.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "        dados.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "        dados_recorte = dados.rio.clip(bacia.geometry, bacia.crs, drop=True)\n",
    "\n",
    "        for lat in dados_recorte.lat.values:\n",
    "            for lon in dados_recorte.lon.values:\n",
    "                try:\n",
    "                    ponto = dados_recorte.sel(lat=lat, lon=lon, method=\"nearest\")\n",
    "                    df_ponto = ponto.to_dataframe().reset_index().dropna(subset=[variavel])\n",
    "\n",
    "                    if df_ponto.empty:\n",
    "                        continue\n",
    "\n",
    "                    nome_ponto = f\"{nome_modelo}_{round(lat, 4)}_{round(lon, 4)}.csv\"\n",
    "                    caminho_csv = os.path.join(pasta_modelo, nome_ponto)\n",
    "                    df_ponto.to_csv(caminho_csv, index=False)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro no ponto lat={lat}, lon={lon}: {e}\")\n",
    "\n",
    "        print(f\">>> Finalizado: {nome_modelo}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {caminho_nc}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e5efb-23f4-4b52-a0d9-88998a430800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Padronizar S√©ries Temporais Extra√≠das de Arquivos NetCDF (.nc)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descri√ß√£o:\n",
    "# Este script processa arquivos CSV gerados a partir de extra√ß√µes de dados \n",
    "# clim√°ticos (ex: precipita√ß√£o, temperatura) contidos em arquivos NetCDF.\n",
    "# Ele reorganiza os dados no formato padr√£o: Dia;Mes;Ano;Valor.\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - Detecta automaticamente o separador do CSV.\n",
    "# - Identifica a coluna de tempo e a coluna da vari√°vel (ex: 'pr').\n",
    "# - Extrai Dia, M√™s, Ano da coluna de tempo.\n",
    "# - Regride 80 anos nos dados (ex: 2015 ‚Üí 1935).\n",
    "# - Salva os arquivos formatados em uma nova subpasta chamada \"input\", \n",
    "#   espelhando a estrutura de pastas original.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Pacotes: pandas, pathlib, os\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrol√≥gica com o MGB e Proje√ß√µes CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURA√á√ÉO ===\n",
    "BASE_DIR   = Path(r\"E:\\CLIMBRA_SSP585\\Tmin\")\n",
    "OUTPUT_DIR = BASE_DIR / \"input\"\n",
    "\n",
    "def verificar_csv(path: Path) -> bool:\n",
    "    if path.stat().st_size == 0:\n",
    "        print(f\"Aviso: {path} est√° vazio.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def process_csv(path: Path):\n",
    "    if not verificar_csv(path):\n",
    "        return\n",
    "\n",
    "    # Tenta detectar separador automaticamente\n",
    "    df = None\n",
    "    for sep in [',',';','\\t']:\n",
    "        try:\n",
    "            tmp = pd.read_csv(path, sep=sep)\n",
    "            if tmp.shape[1] >= 2:\n",
    "                df = tmp\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if df is None:\n",
    "        print(f\"Falha ao ler {path} com delimitadores padr√£o.\")\n",
    "        return\n",
    "\n",
    "    # Detecta a coluna de tempo e a de valor\n",
    "    col_time = next((col for col in df.columns if \"time\" in col.lower()), df.columns[0])\n",
    "    col_valor = next((col for col in df.columns if col.lower() in [\"pr\", \"valor\", \"value\"]), df.columns[-1])\n",
    "\n",
    "    # Converter datas\n",
    "    df[col_time] = pd.to_datetime(df[col_time], errors='coerce')\n",
    "    df_out = pd.DataFrame({\n",
    "        'Dia':   df[col_time].dt.day,\n",
    "        'Mes':   df[col_time].dt.month,\n",
    "        'Ano':   df[col_time].dt.year,\n",
    "        'Valor': df[col_valor]\n",
    "    })\n",
    "\n",
    "    # Regridar 80 anos\n",
    "    df_out['Ano'] = df_out['Ano'] - 80\n",
    "\n",
    "    # Caminho de sa√≠da\n",
    "    rel    = path.relative_to(BASE_DIR)\n",
    "    target = OUTPUT_DIR / rel\n",
    "    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Salvar CSV\n",
    "    df_out.to_csv(target, sep=';', index=False)\n",
    "    print(f\"‚úîÔ∏è Salvo: {target}\")\n",
    "\n",
    "def processar_todos():\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    for root, _, files in os.walk(BASE_DIR):\n",
    "        root_path = Path(root)\n",
    "        if OUTPUT_DIR == root_path or OUTPUT_DIR in root_path.parents:\n",
    "            continue\n",
    "        for fname in files:\n",
    "            if fname.lower().endswith('.csv'):\n",
    "                process_csv(root_path / fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processar_todos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12ae94-7a06-44c6-89f8-17558656b4c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Ajustar Datas Incompletas em S√©ries Temporais (Anos Bissextos + Dia 31)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descri√ß√£o:\n",
    "# Este script percorre arquivos CSV contendo s√©ries temporais no formato \n",
    "# Dia;Mes;Ano;Valor e insere automaticamente valores faltantes para:\n",
    "# - 29 de fevereiro em anos bissextos, caso n√£o esteja presente;\n",
    "# - Dias 31 nos meses que possuem 31 dias, caso ausentes.\n",
    "#\n",
    "# A linha inserida recebe o valor 0.0 e a posi√ß√£o correta na sequ√™ncia temporal.\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - L√™ os arquivos CSV a partir de um diret√≥rio de entrada (INPUT_DIR).\n",
    "# - Detecta e preenche datas faltantes com zero.\n",
    "# - Recria a estrutura de subpastas no diret√≥rio de sa√≠da (OUTPUT_DIR).\n",
    "# - Salva os arquivos corrigidos mantendo o nome original.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Python 3.7+\n",
    "# - Pacotes: pandas, calendar, pathlib\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrol√≥gica com o MGB e Proje√ß√µes CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# Ajuste estes paths\n",
    "INPUT_DIR  = Path(r\"E:\\CLIMBRA_SSP585\\Tmin\\input\")\n",
    "OUTPUT_DIR = Path(r\"E:\\CLIMBRA_SSP585\\Tmin_input\")\n",
    "#‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "# lista de meses com 31 dias\n",
    "meses_31 = [1, 3, 5, 7, 8, 10, 12]\n",
    "\n",
    "# percorre todos os CSVs dentro de INPUT_DIR (incluindo subpastas)\n",
    "for arquivo in INPUT_DIR.rglob(\"*.csv\"):\n",
    "    # l√™ o CSV, pulando o header original\n",
    "    df = pd.read_csv(\n",
    "        arquivo,\n",
    "        sep=';',\n",
    "        skiprows=1,\n",
    "        names=['dia','mes','ano','valor'],\n",
    "        dtype={'dia':int, 'mes':int, 'ano':int, 'valor':float}\n",
    "    )\n",
    "    # monta coluna datetime\n",
    "    df['data'] = pd.to_datetime({\n",
    "        'year':  df['ano'],\n",
    "        'month': df['mes'],\n",
    "        'day':   df['dia']\n",
    "    })\n",
    "\n",
    "    insercoes = []\n",
    "    for ano in sorted(df['ano'].unique()):\n",
    "        # 29/02 em ano bissexto\n",
    "        if calendar.isleap(ano) and not ((df['ano']==ano)&(df['mes']==2)&(df['dia']==29)).any():\n",
    "            insercoes.append({\n",
    "                'dia': 29, 'mes': 2, 'ano': ano,\n",
    "                'valor': 0.0,\n",
    "                'data': pd.Timestamp(year=ano, month=2, day=29)\n",
    "            })\n",
    "        # dia 31 nos meses de 31 dias\n",
    "        for mes in meses_31:\n",
    "            if not ((df['ano']==ano)&(df['mes']==mes)&(df['dia']==31)).any():\n",
    "                insercoes.append({\n",
    "                    'dia': 31, 'mes': mes, 'ano': ano,\n",
    "                    'valor': 0.0,\n",
    "                    'data': pd.Timestamp(year=ano, month=mes, day=31)\n",
    "                })\n",
    "\n",
    "    # concatena e ordena\n",
    "    if insercoes:\n",
    "        df = pd.concat([df, pd.DataFrame(insercoes)], ignore_index=True)\n",
    "    df = df.sort_values('data').reset_index(drop=True)\n",
    "\n",
    "    # determina onde salvar, recriando a estrutura de pastas\n",
    "    rel_path = arquivo.relative_to(INPUT_DIR)            # ex: \"ACCESS-‚Ä¶/file.csv\"\n",
    "    out_dir  = OUTPUT_DIR / rel_path.parent              # mant√©m subpasta\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)           # cria, se necess√°rio\n",
    "\n",
    "    # salva apenas as colunas originais\n",
    "    df[['dia','mes','ano','valor']].to_csv(\n",
    "        out_dir / arquivo.name,\n",
    "        sep=';', index=False, float_format=\"%.1f\"\n",
    "    )\n",
    "\n",
    "    print(f\"Processado: {rel_path} ‚Üí inseridas {len(insercoes)} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754faf72-5006-47f8-80b8-b20e134befc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Gera√ß√£o do arquivo clim√°tico ASCII para o MGB a partir de:\n",
    "Tmed, Umidade Relativa, Horas de Sol, Vento 10m e Press√£o Atmosf√©rica.\n",
    "\n",
    "Entradas:\n",
    "  E:\\CLIMBRA_SSP245\\Tmed_output\n",
    "  E:\\CLIMBRA_SSP245\\hur_input\n",
    "  E:\\CLIMBRA_SSP245\\rss_output\n",
    "  E:\\CLIMBRA_SSP245\\sfc_output\n",
    "\n",
    "Sa√≠da:\n",
    "  E:\\CLIMBRA_SSP245\\clima_ascii\\<MODEL>\\<arquivo>.txt\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# =======================\n",
    "# CONFIGURA√á√ïES\n",
    "# =======================\n",
    "\n",
    "BASE_TMED = Path(r\"E:\\CLIMBRA_SSP585\\Tmed_output\")\n",
    "BASE_HUR  = Path(r\"E:\\CLIMBRA_SSP585\\hur_input\")\n",
    "BASE_SUN  = Path(r\"E:\\CLIMBRA_SSP585\\rss_output\")\n",
    "BASE_WIND = Path(r\"E:\\CLIMBRA_SSP585\\sfc_output\")\n",
    "\n",
    "BASE_OUT  = Path(r\"E:\\CLIMBRA_SSP585\\clima_ascii\")\n",
    "BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Espa√ßamento ASCII\n",
    "COL_SPACE = [6, 5, 5, 11, 11, 11, 11, 11]\n",
    "\n",
    "# Colunas finais\n",
    "COLS = [\"dia\", \"mes\", \"ano\", \"TP2M\", \"UR2M\", \"W10M\", \"SunHours\", \"PSLC\"]\n",
    "\n",
    "# Press√£o fixa\n",
    "PRESSAO_FIXA = 920.0\n",
    "\n",
    "# Regex para extrair modelo, vari√°vel, cen√°rio, lat, lon\n",
    "# Ex.: ACCESS-CM2-tasmax-ssp245_-25.125_-49.125_Tmed.csv\n",
    "NAME_REGEX = re.compile(\n",
    "    r\"^(?P<model>.+?)-(?P<var>[^-]+)-(?P<scen>ssp\\d+)_\"\n",
    "    r\"(?P<lat>-?\\d+(?:\\.\\d+)?)_(?P<lon>-?\\d+(?:\\.\\d+)?).*\\.csv$\"\n",
    ")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# FUN√á√ïES AUXILIARES\n",
    "# =======================\n",
    "\n",
    "def parse_name_info(filename: str):\n",
    "    m = NAME_REGEX.match(filename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Nome n√£o segue padr√£o esperado: {filename}\")\n",
    "    return m.group(\"model\"), m.group(\"var\"), m.group(\"scen\"), m.group(\"lat\"), m.group(\"lon\")\n",
    "\n",
    "\n",
    "def find_matching_file(base_dir: Path, model: str, scen: str, lat: str, lon: str,\n",
    "                       prefer_keyword: str | None = None):\n",
    "    \"\"\"\n",
    "    Procura recursivamente em base_dir um arquivo com:\n",
    "      <model>-QUALQUER-<scen>_<lat>_<lon>.csv\n",
    "    Se prefer_keyword for dado, prioriza arquivos cujo nome contenha essa palavra.\n",
    "    \"\"\"\n",
    "    pattern = f\"{model}-*-{scen}_{lat}_{lon}*.csv\"\n",
    "    candidates = list(base_dir.rglob(pattern))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"Nenhum arquivo encontrado em {base_dir} com padr√£o {pattern}\")\n",
    "\n",
    "    if prefer_keyword:\n",
    "        preferred = [c for c in candidates if prefer_keyword.lower() in c.name.lower()]\n",
    "        if preferred:\n",
    "            return preferred[0]\n",
    "    # Se n√£o houver preferido, devolve o primeiro\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def carregar_csv(path: Path, var_name: str, candidates: list[str]):\n",
    "    \"\"\"\n",
    "    L√™ CSV com separador ';' e renomeia a primeira coluna encontrada em 'candidates'\n",
    "    para var_name.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "\n",
    "    # Ajusta poss√≠veis nomes de mes/ano (mes vs m√™s)\n",
    "    colmap = {}\n",
    "    for c in df.columns:\n",
    "        if c.lower() == \"m√™s\":\n",
    "            colmap[c] = \"mes\"\n",
    "    if colmap:\n",
    "        df = df.rename(columns=colmap)\n",
    "\n",
    "    # Garante que tenhamos dia, mes, ano\n",
    "    for col in [\"dia\", \"mes\", \"ano\"]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Coluna '{col}' n√£o encontrada em {path}\")\n",
    "\n",
    "    col_val = None\n",
    "    for cand in candidates:\n",
    "        for c in df.columns:\n",
    "            if c.lower() == cand.lower():\n",
    "                col_val = c\n",
    "                break\n",
    "        if col_val:\n",
    "            break\n",
    "\n",
    "    if col_val is None:\n",
    "        raise ValueError(f\"N√£o encontrei nenhuma das colunas {candidates} em {path}\")\n",
    "\n",
    "    df = df[[\"dia\", \"mes\", \"ano\", col_val]].copy()\n",
    "    df = df.rename(columns={col_val: var_name})\n",
    "    return df\n",
    "\n",
    "\n",
    "def formatar_ascii(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Formata o DataFrame final para string ASCII com espa√ßamento COL_SPACE e\n",
    "    1 casa decimal nas colunas num√©ricas (exceto dia/mes/ano).\n",
    "    \"\"\"\n",
    "    df_fmt = df.copy()\n",
    "    # Tipos\n",
    "    for col in [\"dia\", \"mes\", \"ano\"]:\n",
    "        df_fmt[col] = df_fmt[col].astype(int)\n",
    "\n",
    "    for col in [\"TP2M\", \"UR2M\", \"W10M\", \"SunHours\", \"PSLC\"]:\n",
    "        df_fmt[col] = df_fmt[col].astype(float).map(lambda x: f\"{x:0.1f}\")\n",
    "\n",
    "    # to_string com espa√ßamento\n",
    "    txt = df_fmt.to_string(\n",
    "        col_space=COL_SPACE,\n",
    "        justify=\"right\",\n",
    "        index=False,\n",
    "        header=False\n",
    "    )\n",
    "    return txt\n",
    "\n",
    "\n",
    "# =======================\n",
    "# PROCESSAMENTO DE UM MODELO\n",
    "# =======================\n",
    "\n",
    "def processar_modelo(model_folder: str):\n",
    "    print(f\"\\nüìå Processando modelo: {model_folder}\")\n",
    "\n",
    "    tmed_dir = BASE_TMED / model_folder\n",
    "    if not tmed_dir.exists():\n",
    "        print(f\"  ‚ö† Pasta Tmed n√£o encontrada para {model_folder}\")\n",
    "        return\n",
    "\n",
    "    tmed_files = sorted(tmed_dir.glob(\"*.csv\"))\n",
    "    if not tmed_files:\n",
    "        print(f\"  ‚ö† Nenhum arquivo Tmed encontrado em {tmed_dir}\")\n",
    "        return\n",
    "\n",
    "    for f_tmed in tmed_files:\n",
    "        fname = f_tmed.name\n",
    "        try:\n",
    "            model, var, scen, lat, lon = parse_name_info(fname)\n",
    "        except ValueError as e:\n",
    "            print(f\"  ‚ö† Pulando arquivo com nome incompat√≠vel: {fname} ({e})\")\n",
    "            continue\n",
    "\n",
    "        # Localiza arquivos das outras vari√°veis\n",
    "        try:\n",
    "            f_hur  = find_matching_file(BASE_HUR,  model, scen, lat, lon, prefer_keyword=\"hur\")\n",
    "            f_sun  = find_matching_file(BASE_SUN,  model, scen, lat, lon, prefer_keyword=\"rss\")\n",
    "            f_wind = find_matching_file(BASE_WIND, model, scen, lat, lon, prefer_keyword=\"sfc\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"  ‚ùå {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Arquivo Tmed : {f_tmed}\")\n",
    "        print(f\"  Arquivo HUR  : {f_hur}\")\n",
    "        print(f\"  Arquivo SUN  : {f_sun}\")\n",
    "        print(f\"  Arquivo WIND : {f_wind}\")\n",
    "\n",
    "        # Carrega as quatro vari√°veis\n",
    "        df_tmed = carregar_csv(f_tmed, \"TP2M\",    [\"tmed\", \"Tmed\", \"tp2m\", \"valor\"])\n",
    "        df_hur  = carregar_csv(f_hur,  \"UR2M\",    [\"hur\", \"hurs\", \"ur2m\", \"valor\"])\n",
    "        df_sun  = carregar_csv(f_sun,  \"SunHours\",[\"n_h_clip\", \"sunhours\", \"n_h\", \"valor\"])\n",
    "        df_wind = carregar_csv(f_wind, \"W10M\",    [\"u10\", \"w10m\", \"vento\", \"sfcwind\", \"valor\"])\n",
    "\n",
    "        # Merge geral\n",
    "        df = df_tmed.merge(df_hur,  on=[\"dia\", \"mes\", \"ano\"]) \\\n",
    "                    .merge(df_sun,  on=[\"dia\", \"mes\", \"ano\"]) \\\n",
    "                    .merge(df_wind, on=[\"dia\", \"mes\", \"ano\"])\n",
    "\n",
    "        # Press√£o fixa\n",
    "        df[\"PSLC\"] = PRESSAO_FIXA\n",
    "\n",
    "        # Ordena\n",
    "        df = df.sort_values(by=[\"ano\", \"mes\", \"dia\"]).reset_index(drop=True)\n",
    "\n",
    "        # Reorganiza colunas\n",
    "        df_final = df[COLS].copy()\n",
    "\n",
    "        # ASCII\n",
    "        ascii_str = formatar_ascii(df_final)\n",
    "\n",
    "        # Sa√≠da\n",
    "        out_dir = BASE_OUT / model_folder\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        out_file = out_dir / fname.replace(\".csv\", \".txt\")\n",
    "        with open(out_file, \"w\") as f_out:\n",
    "            f_out.write(ascii_str)\n",
    "\n",
    "        print(f\"  ‚úî Arquivo gerado: {out_file}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# EXECU√á√ÉO PRINCIPAL\n",
    "# =======================\n",
    "\n",
    "def main():\n",
    "    modelos = [d.name for d in BASE_TMED.iterdir() if d.is_dir()]\n",
    "\n",
    "    if not modelos:\n",
    "        print(f\"‚ö† Nenhuma pasta de modelo encontrada em {BASE_TMED}\")\n",
    "        return\n",
    "\n",
    "    for m in modelos:\n",
    "        processar_modelo(m)\n",
    "\n",
    "    print(\"\\nüéâ Finalizado com sucesso!\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dc016-1f4c-4846-bbc2-fa909494371e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Script: Renomear Arquivos ASCII do MGB com C√≥digos de Grade (Grid.csv)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Descri√ß√£o:\n",
    "# Este script percorre arquivos `.txt` gerados para o modelo MGB, localiza os\n",
    "# nomes que cont√™m coordenadas geogr√°ficas (lat/lon) e renomeia os arquivos\n",
    "# com o c√≥digo correspondente (campo 'Codigo') de 8 d√≠gitos conforme planilha\n",
    "# de mapeamento fornecida (`Grid.csv`).\n",
    "#\n",
    "# Funcionalidades:\n",
    "# - L√™ a tabela de mapeamento com latitudes, longitudes e c√≥digos do grid.\n",
    "# - Identifica lat/lon no nome dos arquivos via express√£o regular.\n",
    "# - Aplica toler√¢ncia para casar coordenadas com diferentes casas decimais.\n",
    "# - Renomeia cada arquivo para o c√≥digo num√©rico correspondente (ex: 00012345.txt).\n",
    "# - Mant√©m a estrutura de diret√≥rios e ignora nomes que n√£o seguem o padr√£o.\n",
    "#\n",
    "# Requisitos:\n",
    "# - Python 3.7+\n",
    "# - Pacotes: pandas, pathlib, re\n",
    "#\n",
    "# Autor: Matheus Marinho\n",
    "# Projeto: Mestrado - Modelagem Hidrol√≥gica com o MGB e Proje√ß√µes CLIMBra\n",
    "# Data: Junho/2025\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ‚Äî‚Äî‚Äî Ajuste estes caminhos ‚Äî‚Äî‚Äî\n",
    "OUTPUT_DIR   = Path(r\"E:\\CLIMBRA_SSP585\\clima_ascii\")\n",
    "MAPPING_FILE = Path(r\"E:\\IGUA√áU_OTTO\\Grid.csv\")\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "# 1) Carrega o mapeamento (sep=';' e colunas Lat, Long, Codigo)\n",
    "df_map = pd.read_csv(MAPPING_FILE, sep=';')\n",
    "df_map['lat']  = df_map['Lat'].astype(float)\n",
    "df_map['lon']  = df_map['Long'].astype(float)\n",
    "df_map['code'] = df_map['Codigo'].astype(str).str.zfill(8)\n",
    "\n",
    "# 2) Regex para extrair modelo, lat e lon do nome (sem extens√£o)\n",
    "pattern = re.compile(r\"(?P<model>.+)_(?P<lat>[-\\d\\.]+)_(?P<lon>[-\\d\\.]+)(?:_.*)?$\")\n",
    "\n",
    "\n",
    "# 3) Toler√¢ncia para casar truncamentos (2 casas vs 3 casas decimais)\n",
    "tol = 1e-2\n",
    "\n",
    "# 4) Percorre todos os .txt em OUTPUT_DIR\n",
    "for txt_path in OUTPUT_DIR.rglob(\"*.txt\"):\n",
    "    stem = txt_path.stem\n",
    "    m = pattern.match(stem)\n",
    "    if not m:\n",
    "        print(f\"[AVISO] nome fora do padr√£o, pulando: {txt_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 5) Extrai lat/lon do nome\n",
    "    lat = float(m.group('lat'))\n",
    "    lon = float(m.group('lon'))\n",
    "\n",
    "    # 6) Busca o c√≥digo dentro da toler√¢ncia definida\n",
    "    cond_lat = (df_map['lat'] - lat).abs() < tol\n",
    "    cond_lon = (df_map['lon'] - lon).abs() < tol\n",
    "    match    = df_map[cond_lat & cond_lon]\n",
    "    if match.empty:\n",
    "        print(f\"[ERRO] sem c√≥digo para lat={lat}, lon={lon} em {txt_path.name}\")\n",
    "        continue\n",
    "    code = match['code'].iloc[0]\n",
    "\n",
    "    # 7) Renomeia o arquivo\n",
    "    new_name = f\"{code}.txt\"\n",
    "    new_path = txt_path.with_name(new_name)\n",
    "    if new_path != txt_path:\n",
    "        txt_path.rename(new_path)\n",
    "        print(f\"{txt_path.name} ‚Üí {new_name}\")\n",
    "    else:\n",
    "        print(f\"{txt_path.name} j√° est√° com nome correto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fa5a9-c448-400e-8ddc-8d92e7babb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
